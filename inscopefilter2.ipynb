{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:45:00] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:03, 508932.08it/s]\n",
      "inscopedata: 1789651it [00:04, 413748.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      "  27/5831 [..............................] - ETA: 10:10:25 - loss: 0.6935 - binary_accuracy: 0.4766 - auc2: 0.4899 - auc1: 0.4718 - TPR: 0.0000e+00 - FPR: 0.0000e+0 - ETA: 5:12:22 - loss: 0.6812 - binary_accuracy: 0.6035 - auc2: 0.5711 - auc1: 0.6237 - TPR: 0.0000e+00 - FPR: 0.0000e+0 - ETA: 3:32:22 - loss: 0.6712 - binary_accuracy: 0.6484 - auc2: 0.6186 - auc1: 0.6825 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 2:43:41 - loss: 0.6653 - binary_accuracy: 0.6694 - auc2: 0.6460 - auc1: 0.7034 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 2:12:56 - loss: 0.6597 - binary_accuracy: 0.6797 - auc2: 0.6646 - auc1: 0.7192 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:52:24 - loss: 0.6549 - binary_accuracy: 0.6924 - auc2: 0.6786 - auc1: 0.7307 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:37:46 - loss: 0.6489 - binary_accuracy: 0.7056 - auc2: 0.6907 - auc1: 0.7454 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:27:58 - loss: 0.6445 - binary_accuracy: 0.7129 - auc2: 0.7006 - auc1: 0.7527 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:19:16 - loss: 0.6409 - binary_accuracy: 0.7166 - auc2: 0.7085 - auc1: 0.7581 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:12:21 - loss: 0.6377 - binary_accuracy: 0.7197 - auc2: 0.7151 - auc1: 0.7615 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:11:24 - loss: 0.6347 - binary_accuracy: 0.7221 - auc2: 0.7206 - auc1: 0.7649 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:11:39 - loss: 0.6329 - binary_accuracy: 0.7209 - auc2: 0.7249 - auc1: 0.7648 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:09:48 - loss: 0.6301 - binary_accuracy: 0.7222 - auc2: 0.7286 - auc1: 0.7674 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:08:13 - loss: 0.6269 - binary_accuracy: 0.7267 - auc2: 0.7321 - auc1: 0.7717 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:06:52 - loss: 0.6239 - binary_accuracy: 0.7301 - auc2: 0.7353 - auc1: 0.7745 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:05:39 - loss: 0.6214 - binary_accuracy: 0.7328 - auc2: 0.7382 - auc1: 0.7780 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:04:37 - loss: 0.6193 - binary_accuracy: 0.7330 - auc2: 0.7409 - auc1: 0.7797 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:03:44 - loss: 0.6167 - binary_accuracy: 0.7349 - auc2: 0.7433 - auc1: 0.7819 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:02:57 - loss: 0.6138 - binary_accuracy: 0.7380 - auc2: 0.7457 - auc1: 0.7855 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:02:06 - loss: 0.6122 - binary_accuracy: 0.7382 - auc2: 0.7478 - auc1: 0.7856 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:01:25 - loss: 0.6097 - binary_accuracy: 0.7401 - auc2: 0.7498 - auc1: 0.7880 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:00:52 - loss: 0.6078 - binary_accuracy: 0.7417 - auc2: 0.7516 - auc1: 0.7883 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:00:20 - loss: 0.6064 - binary_accuracy: 0.7419 - auc2: 0.7533 - auc1: 0.7891 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 59:50 - loss: 0.6038 - binary_accuracy: 0.7445 - auc2: 0.7549 - auc1: 0.7921 - TPR: 0.0000e+00 - FPR: 0.0000e+00 - ETA: 59:20 - loss: 0.6017 - binary_accuracy: 0.7462 - auc2: 0.7565 - auc1: 0.7938 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 58:53 - loss: 0.6000 - binary_accuracy: 0.7473 - auc2: 0.7580 - auc1: 0.7949 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 58:28 - loss: 0.5983 - binary_accuracy: 0.7478 - auc2: 0.7594 - auc1: 0.7970 - TPR: 0.0000e+00 - FPR: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "#Inscope改善方案:Learning rate, batch size1024 , 檔案先shuttle好不要放在porgram裡， fold重啟，+dropout，增worker降quene,改善FP反應物字典給值做法，改用簡單的reaction rules FP(rdkit內建版)\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from tqdm import tqdm, trange\n",
    "from collections import defaultdict\n",
    "from highway_layer import Highway\n",
    "#匯入深度學習的框架函式庫：keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.initializers import Constant\n",
    "from keras.utils import plot_model\n",
    "#keras用以建立模型架構的函數\n",
    "from keras.models import Sequential, load_model, Model\n",
    "\n",
    "#keras中建立深度學習layer的函數\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Multiply, Add, Lambda, Input\n",
    "from keras import metrics\n",
    "#keras訓練演算法函數\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#keras提早判停的函數\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#it's hard to reproduce results, so close all seeds\n",
    "#os.environ['PYTHONHASHSEED'] = '0'\n",
    "#np.random.seed(0)\n",
    "#tf.set_random_seed(0)\n",
    "#random.seed(0)\n",
    "\n",
    "#to solve problem:Blas GEMM launch failed\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config)) \n",
    "\n",
    "\n",
    "def fps_to_arr(fps):\n",
    "    \"\"\"Faster conversion to ndarray\"\"\"\n",
    "    arrs = []\n",
    "    for fp, info in zip(fps[0],fps[1]):\n",
    "        onbits = list(fp.GetOnBits())\n",
    "        arr = np.zeros(fp.GetNumBits())\n",
    "        for onbit in onbits:\n",
    "            arr[onbit] = len(info[onbit])\n",
    "        arrs.append(arr)\n",
    "    arrs = np.array(arrs)\n",
    "    return arrs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fingerprint_mols(mols, fp_dim):\n",
    "    fps = []\n",
    "    infos = []\n",
    "    for mol in mols:\n",
    "        mol = Chem.MolFromSmiles(mol)\n",
    "        info={}\n",
    "        # Necessary for fingerprinting\n",
    "        # Chem.GetSymmSSSR(mol)\n",
    "\n",
    "        # \"When comparing the ECFP/FCFP fingerprints and\n",
    "        # the Morgan fingerprints generated by the RDKit,\n",
    "        # remember that the 4 in ECFP4 corresponds to the\n",
    "        # diameter of the atom environments considered,\n",
    "        # while the Morgan fingerprints take a radius parameter.\n",
    "        # So the examples above, with radius=2, are roughly\n",
    "        # equivalent to ECFP4 and FCFP4.\"\n",
    "        # <http://www.rdkit.org/docs/GettingStartedInPython.html>\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=int(fp_dim), useChirality=1, bitInfo=info)\n",
    "        # fold_factor = fp.GetNumBits()//fp_dim\n",
    "        # fp = DataStructs.FoldFingerprint(fp, fold_factor)\n",
    "        fps.append(fp)\n",
    "        infos.append(info)\n",
    "    return fps, infos\n",
    "\n",
    "def preprocess(X, fp_dim):\n",
    "    # Compute fingerprints\n",
    "    FPs = fps_to_arr(fingerprint_mols(X, fp_dim))\n",
    "    # Apply variance threshold\n",
    "    # return np.log(X[:,self.idx] + 1) \n",
    "    #FPs = np.log(dataX[:,idx]+1)\n",
    "#    FPs = np.log(dataX+1)\n",
    "    return FPs\n",
    "def smi_list_from_str(inchis):\n",
    "    '''string separated by ++ to list of RDKit molecules'''\n",
    "    return [inchi.strip() for inchi in inchis.split('++')]\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, X, y, z, batch_size=1, shuffle=True, fp_dim=16384, recfp_dim=2048):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        self.shuffle = shuffle\n",
    "        self.fp_dim = fp_dim\n",
    "        self.recfp_dim = recfp_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        #计算每一个epoch的迭代次数\n",
    "        return int(np.floor(len(self.X) / int(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #生成每个batch数据，这里就根据自己对数据的读取方式进行发挥了\n",
    "        # 生成batch_size个索引\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # 根据索引获取datas集合中的数据\n",
    "        batch_datasX = [self.X[k] for k in batch_indexs]\n",
    "        batch_datasy = [self.y[k] for k in batch_indexs]\n",
    "        batch_datasz = [self.z[k] for k in batch_indexs]\n",
    "        # 生成数据\n",
    "        X = preprocess(batch_datasX, self.fp_dim)\n",
    "        y = np.zeros((len(batch_datasy),self.recfp_dim))\n",
    "        for i,a in enumerate(batch_datasy):\n",
    "            n = np.zeros((1,self.recfp_dim))\n",
    "            for b in smi_list_from_str(a):\n",
    "                n += preprocess([b], self.recfp_dim)\n",
    "            p = X[i].reshape((-1,self.recfp_dim))    \n",
    "            y[i] = np.sum(p, 0, keepdims=True)- n\n",
    "        z = np.array(batch_datasz)\n",
    "#        y = y.astype(np.int64)\n",
    "        return [X, y], [z]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        #在每一次epoch结束是否需要进行一次随机，重新随机一下index\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "def fold(x):\n",
    "    z=tf.subtract(x[0], x[1])\n",
    "#    z_shape=tf.Tensor.shape(z)\n",
    "\n",
    "#    z_shape=z.get_shape().as_list()\n",
    "    zv=tf.reshape(z,[-1,8,2048])\n",
    "    return tf.reduce_sum(zv, 1) \n",
    "\n",
    "def cosine(x):\n",
    "    prod_net = x[0]\n",
    "    react_net = x[1]\n",
    "#    prod_norm = tf.nn.l2_normalize(prod_net, axis=-1)\n",
    "#    react_norm = tf.nn.l2_normalize(react_net, axis=-1)\n",
    "    cosine_sim = tf.reduce_sum(tf.multiply(prod_net, react_net), axis=-1,keepdims=True)\n",
    "#    cosine_sim = tf.squeeze(cosine_sim,[1])\n",
    "#    return tf.nn.sigmoid(cosine_sim)\n",
    "    return tf.nn.sigmoid(cosine_sim)\n",
    "# get average auc between different batches over the epoch, so don't use. otherwise validation process always get wrong results\n",
    "def auc2(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "# AUC for a binary classifier, this AUC is a little underestimated due to minimum areas.\n",
    "def auc1(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# PFA, prob false alert for binary classifier(FPR)\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# P_TA prob true alerts for binary classifier(TPR)\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "# PFA, prob false alert for binary classifier(FPR)\n",
    "def FPR(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred >= 0.9, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# P_TA prob true alerts for binary classifier(TPR)\n",
    "def TPR(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred >= 0.9, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "# ACC= (TP + TN) / (P + N)\n",
    "def ACCR(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred >= 0.9, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)    \n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    # TN = total number of correct alerts, alerts from the negtive class labels\n",
    "    TN = K.sum((1-y_pred) * (1-y_true))    \n",
    "    return (TP+TN)/(P+N)\n",
    "\n",
    "\n",
    "            #設定訓練參數和訓練模型存放路徑\n",
    "#batch_size = 3\n",
    "batch_size = 512\n",
    "#num_classes = 6\n",
    "epochs = 2000\n",
    "#epochs = 100\n",
    "seed=0\n",
    "#validation spilt\n",
    "spilt=0.1\n",
    "#for variance threshold\n",
    "#fp_dim=1e6\n",
    "fp_dim=16384\n",
    "recfp_dim=2048\n",
    "model_name = 'trained_model_inscope_'+str(seed)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Loading data...')\n",
    "tem_simp = set()\n",
    "prods = []\n",
    "reacs = []\n",
    "labels = []\n",
    "with open('data/inscopedata.dat', 'r') as f:\n",
    "    for l in tqdm(f, desc='inscopedata'):\n",
    "        tem_simp.add(l.strip())\n",
    "\n",
    "with open('data/inscopedata2.dat', 'r') as f:\n",
    "    for l in tqdm(f, desc='inscopedata'):\n",
    "        tem_simp.add(l.strip()) \n",
    "\n",
    "#with open('data/inscopedata4.dat', 'r') as f:\n",
    "#    for l in tqdm(f, desc='inscopedata'):\n",
    "#        tem_simp.add(l.strip()) \n",
    "        \n",
    "for item in tem_simp:\n",
    "    prod,reac,label = item.split('\\t')\n",
    "    prods.append(prod)\n",
    "    reacs.append(reac)\n",
    "    labels.append(float(label))\n",
    "\n",
    "print('total samples:', len(tem_simp))    \n",
    "# Shuffle\n",
    "xyz = list(zip(prods, reacs, labels))\n",
    "xyz.sort()\n",
    "random.seed(seed)\n",
    "random.shuffle(xyz)\n",
    "prods, reacs, labels = zip(*xyz)\n",
    "data_spilt= round(len(prods)*(1-spilt))\n",
    "x_train = prods[:data_spilt]\n",
    "x_test = prods[data_spilt:]\n",
    "y_train = reacs[:data_spilt]\n",
    "y_test = reacs[data_spilt:]\n",
    "z_train = labels[:data_spilt]\n",
    "z_test = labels[data_spilt:]\n",
    "\n",
    "#print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "#print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "\n",
    "print('shuffle is over...')\n",
    "\n",
    "#build model\n",
    "visible = Input(shape=(fp_dim,))\n",
    "hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "hidden = Dense(1024, activation='elu')(hidden)\n",
    "hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "# only for expansion rule policynet\n",
    "for _ in range(5):\n",
    "    hidden = Highway()(hidden)\n",
    "#    hidden = Dropout(0.4)(hidden)\n",
    "#another branch\n",
    "#visible1 = Input(shape=(fp_dim,))\n",
    "visible2 = Input(shape=(recfp_dim,))\n",
    "#hidden1 = Lambda(fold)([visible, visible2])\n",
    "hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "output = Lambda(cosine)([hidden, hidden1])\n",
    "#,output_shape=(1,)\n",
    "    \n",
    "model = Model(inputs=[visible,visible2], outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "#plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "# 初始化Adam optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# 設定訓練方式，包含loss、optimizer..)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[ACCR, auc1, TPR, FPR])\n",
    "#metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "# early stop存放模型設置\n",
    "\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_ACCR', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "# early stop參數設定\n",
    "earlystop = EarlyStopping(monitor='val_ACCR', patience=6, verbose=1, mode='max')\n",
    "\n",
    "#continue training\n",
    "#del model  # 删掉存在的模型\n",
    "\n",
    "#返回一个编译好的模型\n",
    "#与删掉的模型相同\n",
    "#model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine})\n",
    "##model.compile(loss='binary_crossentropy',\n",
    "##              optimizer=opt,\n",
    "##              metrics=['binary_accuracy',ACCR, auc, auc1, TPR, FPR])\n",
    "\n",
    "# 開始訓練\n",
    "training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=1,\n",
    "                    initial_epoch=0,\n",
    "#                    workers=0, \n",
    "#                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 10, \n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [13:15:59] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:02, 523834.25it/s]\n",
      "inscopedata: 1789651it [00:04, 424214.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 1299s - loss: 0.2831 - binary_accuracy: 0.9151 - ACCR: 0.8791 - auc2: 0.9544 - auc1: 0.9605 - TPR: 0.7102 - FPR: 0.0309 - val_loss: 0.2301 - val_binary_accuracy: 0.9334 - val_ACCR: 0.9163 - val_auc2: 0.9637 - val_auc1: 0.9674 - val_TPR: 0.8188 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.91626, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 1175s - loss: 0.2465 - binary_accuracy: 0.9472 - ACCR: 0.9373 - auc2: 0.9691 - auc1: 0.9725 - TPR: 0.8689 - FPR: 0.0263 - val_loss: 0.2333 - val_binary_accuracy: 0.9398 - val_ACCR: 0.9342 - val_auc2: 0.9708 - val_auc1: 0.9603 - val_TPR: 0.8780 - val_FPR: 0.0359\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.91626 to 0.93422, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 1182s - loss: 0.2217 - binary_accuracy: 0.9590 - ACCR: 0.9537 - auc2: 0.9731 - auc1: 0.9762 - TPR: 0.9083 - FPR: 0.0221 - val_loss: 0.4314 - val_binary_accuracy: 0.9437 - val_ACCR: 0.9390 - val_auc2: 0.9743 - val_auc1: 0.9569 - val_TPR: 0.8878 - val_FPR: 0.0338\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.93422 to 0.93898, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 1181s - loss: 0.1949 - binary_accuracy: 0.9660 - ACCR: 0.9622 - auc2: 0.9757 - auc1: 0.9795 - TPR: 0.9262 - FPR: 0.0186 - val_loss: 0.4132 - val_binary_accuracy: 0.9460 - val_ACCR: 0.9409 - val_auc2: 0.9765 - val_auc1: 0.9530 - val_TPR: 0.8868 - val_FPR: 0.0302\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.93898 to 0.94094, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 1194s - loss: 0.1688 - binary_accuracy: 0.9712 - ACCR: 0.9680 - auc2: 0.9776 - auc1: 0.9826 - TPR: 0.9376 - FPR: 0.0158 - val_loss: 0.5030 - val_binary_accuracy: 0.9468 - val_ACCR: 0.9426 - val_auc2: 0.9783 - val_auc1: 0.9537 - val_TPR: 0.8964 - val_FPR: 0.0328\n",
      "\n",
      "Epoch 00005: val_ACCR improved from 0.94094 to 0.94261, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter2 import*\n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=4, \n",
    "                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 10, \n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:33:27] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:02, 518897.55it/s]\n",
      "inscopedata: 1789651it [00:04, 423115.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 1618s - loss: 0.1497 - binary_accuracy: 0.9751 - ACCR: 0.9723 - auc2: 0.9888 - auc1: 0.9847 - TPR: 0.9459 - FPR: 0.0137 - val_loss: 0.3823 - val_binary_accuracy: 0.9483 - val_ACCR: 0.9442 - val_auc2: 0.9866 - val_auc1: 0.9528 - val_TPR: 0.8980 - val_FPR: 0.0311\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.94424, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 1493s - loss: 0.1351 - binary_accuracy: 0.9777 - ACCR: 0.9752 - auc2: 0.9868 - auc1: 0.9863 - TPR: 0.9516 - FPR: 0.0122 - val_loss: 0.4189 - val_binary_accuracy: 0.9487 - val_ACCR: 0.9444 - val_auc2: 0.9867 - val_auc1: 0.9503 - val_TPR: 0.8954 - val_FPR: 0.0295\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.94424 to 0.94439, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 1507s - loss: 0.1230 - binary_accuracy: 0.9800 - ACCR: 0.9780 - auc2: 0.9870 - auc1: 0.9875 - TPR: 0.9570 - FPR: 0.0109 - val_loss: 0.3510 - val_binary_accuracy: 0.9502 - val_ACCR: 0.9479 - val_auc2: 0.9870 - val_auc1: 0.9511 - val_TPR: 0.9084 - val_FPR: 0.0311\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.94439 to 0.94785, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 1504s - loss: 0.1141 - binary_accuracy: 0.9818 - ACCR: 0.9800 - auc2: 0.9873 - auc1: 0.9884 - TPR: 0.9611 - FPR: 0.0100 - val_loss: 0.3546 - val_binary_accuracy: 0.9505 - val_ACCR: 0.9492 - val_auc2: 0.9874 - val_auc1: 0.9514 - val_TPR: 0.9169 - val_FPR: 0.0336\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.94785 to 0.94919, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 1489s - loss: 0.1074 - binary_accuracy: 0.9833 - ACCR: 0.9816 - auc2: 0.9876 - auc1: 0.9891 - TPR: 0.9645 - FPR: 0.0092 - val_loss: 0.5364 - val_binary_accuracy: 0.9518 - val_ACCR: 0.9508 - val_auc2: 0.9877 - val_auc1: 0.9515 - val_TPR: 0.9228 - val_FPR: 0.0343\n",
      "\n",
      "Epoch 00005: val_ACCR improved from 0.94919 to 0.95082, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/2000\n",
      " - 1488s - loss: 0.1024 - binary_accuracy: 0.9845 - ACCR: 0.9831 - auc2: 0.9879 - auc1: 0.9895 - TPR: 0.9674 - FPR: 0.0086 - val_loss: 0.3747 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9515 - val_auc2: 0.9880 - val_auc1: 0.9529 - val_TPR: 0.9294 - val_FPR: 0.0368\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.95082 to 0.95146, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 1494s - loss: 0.0975 - binary_accuracy: 0.9855 - ACCR: 0.9842 - auc2: 0.9881 - auc1: 0.9900 - TPR: 0.9697 - FPR: 0.0081 - val_loss: 0.4690 - val_binary_accuracy: 0.9518 - val_ACCR: 0.9500 - val_auc2: 0.9882 - val_auc1: 0.9488 - val_TPR: 0.9183 - val_FPR: 0.0331\n",
      "\n",
      "Epoch 00007: val_ACCR did not improve from 0.95146\n",
      "Epoch 8/2000\n",
      " - 1489s - loss: 0.0928 - binary_accuracy: 0.9863 - ACCR: 0.9852 - auc2: 0.9884 - auc1: 0.9904 - TPR: 0.9717 - FPR: 0.0077 - val_loss: 0.4811 - val_binary_accuracy: 0.9529 - val_ACCR: 0.9520 - val_auc2: 0.9885 - val_auc1: 0.9510 - val_TPR: 0.9285 - val_FPR: 0.0354\n",
      "\n",
      "Epoch 00008: val_ACCR improved from 0.95146 to 0.95204, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/2000\n",
      " - 1497s - loss: 0.0895 - binary_accuracy: 0.9872 - ACCR: 0.9862 - auc2: 0.9886 - auc1: 0.9907 - TPR: 0.9737 - FPR: 0.0072 - val_loss: 0.4445 - val_binary_accuracy: 0.9528 - val_ACCR: 0.9515 - val_auc2: 0.9887 - val_auc1: 0.9481 - val_TPR: 0.9215 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00009: val_ACCR did not improve from 0.95204\n",
      "Epoch 10/2000\n",
      " - 1488s - loss: 0.0855 - binary_accuracy: 0.9879 - ACCR: 0.9871 - auc2: 0.9887 - auc1: 0.9910 - TPR: 0.9755 - FPR: 0.0068 - val_loss: 0.3758 - val_binary_accuracy: 0.9532 - val_ACCR: 0.9522 - val_auc2: 0.9889 - val_auc1: 0.9475 - val_TPR: 0.9269 - val_FPR: 0.0343\n",
      "\n",
      "Epoch 00010: val_ACCR improved from 0.95204 to 0.95225, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 11/2000\n",
      " - 1490s - loss: 0.0823 - binary_accuracy: 0.9885 - ACCR: 0.9877 - auc2: 0.9890 - auc1: 0.9913 - TPR: 0.9769 - FPR: 0.0065 - val_loss: 0.3104 - val_binary_accuracy: 0.9534 - val_ACCR: 0.9525 - val_auc2: 0.9890 - val_auc1: 0.9459 - val_TPR: 0.9246 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00011: val_ACCR improved from 0.95225 to 0.95245, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 12/2000\n",
      " - 1479s - loss: 0.0810 - binary_accuracy: 0.9890 - ACCR: 0.9882 - auc2: 0.9891 - auc1: 0.9915 - TPR: 0.9778 - FPR: 0.0063 - val_loss: 0.4641 - val_binary_accuracy: 0.9537 - val_ACCR: 0.9523 - val_auc2: 0.9892 - val_auc1: 0.9442 - val_TPR: 0.9234 - val_FPR: 0.0324\n",
      "\n",
      "Epoch 00012: val_ACCR did not improve from 0.95245\n",
      "Epoch 13/2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 917, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\threading.py\", line 865, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 572, in _run\n",
      "    with closing(self.executor_fn(_SHARED_SEQUENCES)) as executor:\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\utils\\data_utils.py\", line 554, in <lambda>\n",
      "    initargs=(seqs,))\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 119, in Pool\n",
      "    context=self.get_context())\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\", line 176, in __init__\n",
      "    self._repopulate_pool()\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\pool.py\", line 241, in _repopulate_pool\n",
      "    w.start()\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\process.py\", line 112, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\context.py\", line 322, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\popen_spawn_win32.py\", line 89, in __init__\n",
      "    reduction.dump(process_obj, to_child)\n",
      "  File \"C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\multiprocessing\\reduction.py\", line 60, in dump\n",
      "    ForkingPickler(file, protocol).dump(obj)\n",
      "BrokenPipeError: [Errno 32] Broken pipe\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter2 import*\n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 5, \n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [19:18:31] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:02, 517845.02it/s]\n",
      "inscopedata: 1789651it [00:04, 421725.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           highway_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           dropout_6[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 1307s - loss: 0.2702 - binary_accuracy: 0.8869 - ACCR: 0.7694 - auc2: 0.9209 - auc1: 0.9474 - TPR: 0.3641 - FPR: 0.0147 - val_loss: 0.1701 - val_binary_accuracy: 0.9239 - val_ACCR: 0.8237 - val_auc2: 0.9525 - val_auc1: 0.9735 - val_TPR: 0.5165 - val_FPR: 0.0126\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.82372, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 1177s - loss: 0.1939 - binary_accuracy: 0.9253 - ACCR: 0.8432 - auc2: 0.9600 - auc1: 0.9740 - TPR: 0.5766 - FPR: 0.0148 - val_loss: 0.1701 - val_binary_accuracy: 0.9355 - val_ACCR: 0.8638 - val_auc2: 0.9647 - val_auc1: 0.9792 - val_TPR: 0.6342 - val_FPR: 0.0138\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.82372 to 0.86379, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 1196s - loss: 0.1679 - binary_accuracy: 0.9363 - ACCR: 0.8702 - auc2: 0.9681 - auc1: 0.9801 - TPR: 0.6527 - FPR: 0.0139 - val_loss: 0.2193 - val_binary_accuracy: 0.9406 - val_ACCR: 0.8873 - val_auc2: 0.9705 - val_auc1: 0.9813 - val_TPR: 0.7060 - val_FPR: 0.0161\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.86379 to 0.88730, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 1186s - loss: 0.1514 - binary_accuracy: 0.9433 - ACCR: 0.8866 - auc2: 0.9726 - auc1: 0.9836 - TPR: 0.6982 - FPR: 0.0130 - val_loss: 0.1243 - val_binary_accuracy: 0.9433 - val_ACCR: 0.8971 - val_auc2: 0.9742 - val_auc1: 0.9822 - val_TPR: 0.7348 - val_FPR: 0.0163\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.88730 to 0.89713, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 1183s - loss: 0.1394 - binary_accuracy: 0.9481 - ACCR: 0.8980 - auc2: 0.9757 - auc1: 0.9859 - TPR: 0.7299 - FPR: 0.0124 - val_loss: 0.1583 - val_binary_accuracy: 0.9448 - val_ACCR: 0.9072 - val_auc2: 0.9768 - val_auc1: 0.9828 - val_TPR: 0.7663 - val_FPR: 0.0177\n",
      "\n",
      "Epoch 00005: val_ACCR improved from 0.89713 to 0.90719, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/2000\n",
      " - 1201s - loss: 0.1307 - binary_accuracy: 0.9515 - ACCR: 0.9065 - auc2: 0.9779 - auc1: 0.9875 - TPR: 0.7532 - FPR: 0.0118 - val_loss: 0.1333 - val_binary_accuracy: 0.9463 - val_ACCR: 0.9087 - val_auc2: 0.9788 - val_auc1: 0.9830 - val_TPR: 0.7692 - val_FPR: 0.0170\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.90719 to 0.90867, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 1221s - loss: 0.1225 - binary_accuracy: 0.9548 - ACCR: 0.9138 - auc2: 0.9797 - auc1: 0.9889 - TPR: 0.7730 - FPR: 0.0112 - val_loss: 0.1158 - val_binary_accuracy: 0.9470 - val_ACCR: 0.9101 - val_auc2: 0.9804 - val_auc1: 0.9828 - val_TPR: 0.7734 - val_FPR: 0.0171\n",
      "\n",
      "Epoch 00007: val_ACCR improved from 0.90867 to 0.91006, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/2000\n",
      " - 1201s - loss: 0.1160 - binary_accuracy: 0.9574 - ACCR: 0.9193 - auc2: 0.9811 - auc1: 0.9900 - TPR: 0.7879 - FPR: 0.0107 - val_loss: 0.1414 - val_binary_accuracy: 0.9473 - val_ACCR: 0.9156 - val_auc2: 0.9817 - val_auc1: 0.9827 - val_TPR: 0.7912 - val_FPR: 0.0181\n",
      "\n",
      "Epoch 00008: val_ACCR improved from 0.91006 to 0.91559, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/2000\n",
      " - 1197s - loss: 0.1104 - binary_accuracy: 0.9595 - ACCR: 0.9245 - auc2: 0.9823 - auc1: 0.9909 - TPR: 0.8023 - FPR: 0.0103 - val_loss: 0.1233 - val_binary_accuracy: 0.9476 - val_ACCR: 0.9199 - val_auc2: 0.9828 - val_auc1: 0.9826 - val_TPR: 0.8042 - val_FPR: 0.0185\n",
      "\n",
      "Epoch 00009: val_ACCR improved from 0.91559 to 0.91987, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 10/2000\n",
      " - 1188s - loss: 0.1053 - binary_accuracy: 0.9614 - ACCR: 0.9285 - auc2: 0.9833 - auc1: 0.9916 - TPR: 0.8131 - FPR: 0.0099 - val_loss: 0.1507 - val_binary_accuracy: 0.9483 - val_ACCR: 0.9234 - val_auc2: 0.9837 - val_auc1: 0.9827 - val_TPR: 0.8176 - val_FPR: 0.0203\n",
      "\n",
      "Epoch 00010: val_ACCR improved from 0.91987 to 0.92335, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 11/2000\n",
      " - 1184s - loss: 0.1012 - binary_accuracy: 0.9630 - ACCR: 0.9322 - auc2: 0.9841 - auc1: 0.9922 - TPR: 0.8229 - FPR: 0.0096 - val_loss: 0.1267 - val_binary_accuracy: 0.9487 - val_ACCR: 0.9231 - val_auc2: 0.9845 - val_auc1: 0.9824 - val_TPR: 0.8167 - val_FPR: 0.0201\n",
      "\n",
      "Epoch 00011: val_ACCR did not improve from 0.92335\n",
      "Epoch 12/2000\n",
      " - 1201s - loss: 0.0969 - binary_accuracy: 0.9646 - ACCR: 0.9357 - auc2: 0.9850 - auc1: 0.9928 - TPR: 0.8325 - FPR: 0.0092 - val_loss: 0.1429 - val_binary_accuracy: 0.9487 - val_ACCR: 0.9261 - val_auc2: 0.9852 - val_auc1: 0.9820 - val_TPR: 0.8264 - val_FPR: 0.0208\n",
      "\n",
      "Epoch 00012: val_ACCR improved from 0.92335 to 0.92605, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 13/2000\n",
      " - 1199s - loss: 0.0936 - binary_accuracy: 0.9659 - ACCR: 0.9387 - auc2: 0.9856 - auc1: 0.9932 - TPR: 0.8405 - FPR: 0.0090 - val_loss: 0.1733 - val_binary_accuracy: 0.9487 - val_ACCR: 0.9297 - val_auc2: 0.9859 - val_auc1: 0.9818 - val_TPR: 0.8376 - val_FPR: 0.0213\n",
      "\n",
      "Epoch 00013: val_ACCR improved from 0.92605 to 0.92967, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 14/2000\n",
      " - 1188s - loss: 0.0905 - binary_accuracy: 0.9672 - ACCR: 0.9412 - auc2: 0.9862 - auc1: 0.9936 - TPR: 0.8471 - FPR: 0.0087 - val_loss: 0.1745 - val_binary_accuracy: 0.9492 - val_ACCR: 0.9292 - val_auc2: 0.9864 - val_auc1: 0.9815 - val_TPR: 0.8359 - val_FPR: 0.0210\n",
      "\n",
      "Epoch 00014: val_ACCR did not improve from 0.92967\n",
      "Epoch 15/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter2 import*\n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=4, \n",
    "                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 10, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:55:55] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:02, 519593.77it/s]\n",
      "inscopedata: 1789651it [00:04, 421425.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           highway_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           dropout_6[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 1619s - loss: 0.0297 - binary_accuracy: 0.9906 - ACCR: 0.9859 - auc2: 0.9987 - auc1: 0.9986 - TPR: 0.9652 - FPR: 0.0031 - val_loss: 0.2175 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9494 - val_auc2: 0.9974 - val_auc1: 0.9677 - val_TPR: 0.9128 - val_FPR: 0.0311\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.94940, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 1494s - loss: 0.0298 - binary_accuracy: 0.9905 - ACCR: 0.9859 - auc2: 0.9970 - auc1: 0.9986 - TPR: 0.9654 - FPR: 0.0031 - val_loss: 0.3252 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9494 - val_auc2: 0.9968 - val_auc1: 0.9678 - val_TPR: 0.9135 - val_FPR: 0.0314\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.94940 to 0.94943, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 1511s - loss: 0.0292 - binary_accuracy: 0.9907 - ACCR: 0.9861 - auc2: 0.9968 - auc1: 0.9986 - TPR: 0.9656 - FPR: 0.0030 - val_loss: 0.3829 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9494 - val_auc2: 0.9967 - val_auc1: 0.9670 - val_TPR: 0.9116 - val_FPR: 0.0304\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.94943 to 0.94943, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 1534s - loss: 0.0292 - binary_accuracy: 0.9907 - ACCR: 0.9861 - auc2: 0.9966 - auc1: 0.9986 - TPR: 0.9657 - FPR: 0.0030 - val_loss: 0.2577 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9499 - val_auc2: 0.9966 - val_auc1: 0.9676 - val_TPR: 0.9152 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.94943 to 0.94987, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 1501s - loss: 0.0292 - binary_accuracy: 0.9908 - ACCR: 0.9863 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9663 - FPR: 0.0030 - val_loss: 0.2736 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9496 - val_auc2: 0.9965 - val_auc1: 0.9673 - val_TPR: 0.9141 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00005: val_ACCR did not improve from 0.94987\n",
      "Epoch 6/2000\n",
      " - 1507s - loss: 0.0288 - binary_accuracy: 0.9909 - ACCR: 0.9864 - auc2: 0.9965 - auc1: 0.9987 - TPR: 0.9666 - FPR: 0.0030 - val_loss: 0.2290 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9499 - val_auc2: 0.9965 - val_auc1: 0.9674 - val_TPR: 0.9155 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.94987 to 0.94988, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 1508s - loss: 0.0292 - binary_accuracy: 0.9908 - ACCR: 0.9863 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9662 - FPR: 0.0030 - val_loss: 0.2289 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9493 - val_auc2: 0.9965 - val_auc1: 0.9672 - val_TPR: 0.9141 - val_FPR: 0.0319\n",
      "\n",
      "Epoch 00007: val_ACCR did not improve from 0.94988\n",
      "Epoch 8/2000\n",
      " - 1497s - loss: 0.0287 - binary_accuracy: 0.9909 - ACCR: 0.9865 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9666 - FPR: 0.0029 - val_loss: 0.2584 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9501 - val_auc2: 0.9965 - val_auc1: 0.9675 - val_TPR: 0.9171 - val_FPR: 0.0323\n",
      "\n",
      "Epoch 00008: val_ACCR improved from 0.94988 to 0.95011, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/2000\n",
      " - 1503s - loss: 0.0289 - binary_accuracy: 0.9908 - ACCR: 0.9865 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9667 - FPR: 0.0030 - val_loss: 0.3492 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9498 - val_auc2: 0.9965 - val_auc1: 0.9678 - val_TPR: 0.9162 - val_FPR: 0.0323\n",
      "\n",
      "Epoch 00009: val_ACCR did not improve from 0.95011\n",
      "Epoch 10/2000\n",
      " - 1504s - loss: 0.0285 - binary_accuracy: 0.9910 - ACCR: 0.9866 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9669 - FPR: 0.0029 - val_loss: 0.3947 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9494 - val_auc2: 0.9964 - val_auc1: 0.9669 - val_TPR: 0.9127 - val_FPR: 0.0310\n",
      "\n",
      "Epoch 00010: val_ACCR did not improve from 0.95011\n",
      "Epoch 11/2000\n",
      " - 1505s - loss: 0.0288 - binary_accuracy: 0.9909 - ACCR: 0.9866 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9672 - FPR: 0.0030 - val_loss: 0.2928 - val_binary_accuracy: 0.9520 - val_ACCR: 0.9496 - val_auc2: 0.9964 - val_auc1: 0.9670 - val_TPR: 0.9163 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00011: val_ACCR did not improve from 0.95011\n",
      "Epoch 12/2000\n",
      " - 1517s - loss: 0.0285 - binary_accuracy: 0.9910 - ACCR: 0.9867 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9671 - FPR: 0.0029 - val_loss: 0.2833 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9492 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9126 - val_FPR: 0.0313\n",
      "\n",
      "Epoch 00012: val_ACCR did not improve from 0.95011\n",
      "Epoch 13/2000\n",
      " - 1507s - loss: 0.0284 - binary_accuracy: 0.9911 - ACCR: 0.9868 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9675 - FPR: 0.0029 - val_loss: 0.3295 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9495 - val_auc2: 0.9964 - val_auc1: 0.9669 - val_TPR: 0.9147 - val_FPR: 0.0319\n",
      "\n",
      "Epoch 00013: val_ACCR did not improve from 0.95011\n",
      "Epoch 14/2000\n",
      " - 1522s - loss: 0.0281 - binary_accuracy: 0.9911 - ACCR: 0.9868 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9674 - FPR: 0.0029 - val_loss: 0.2168 - val_binary_accuracy: 0.9520 - val_ACCR: 0.9491 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9127 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00014: val_ACCR did not improve from 0.95011\n",
      "Epoch 15/2000\n",
      " - 1507s - loss: 0.0282 - binary_accuracy: 0.9912 - ACCR: 0.9870 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9679 - FPR: 0.0029 - val_loss: 0.3462 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9157 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00015: val_ACCR did not improve from 0.95011\n",
      "Epoch 16/2000\n",
      " - 1503s - loss: 0.0283 - binary_accuracy: 0.9912 - ACCR: 0.9870 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9682 - FPR: 0.0029 - val_loss: 0.3216 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9498 - val_auc2: 0.9964 - val_auc1: 0.9665 - val_TPR: 0.9138 - val_FPR: 0.0310\n",
      "\n",
      "Epoch 00016: val_ACCR did not improve from 0.95011\n",
      "Epoch 17/2000\n",
      " - 1509s - loss: 0.0281 - binary_accuracy: 0.9912 - ACCR: 0.9869 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9679 - FPR: 0.0029 - val_loss: 0.3370 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9496 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9146 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00017: val_ACCR did not improve from 0.95011\n",
      "Epoch 18/2000\n",
      " - 1506s - loss: 0.0276 - binary_accuracy: 0.9913 - ACCR: 0.9872 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9685 - FPR: 0.0028 - val_loss: 0.2889 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9497 - val_auc2: 0.9964 - val_auc1: 0.9664 - val_TPR: 0.9138 - val_FPR: 0.0312\n",
      "\n",
      "Epoch 00018: val_ACCR did not improve from 0.95011\n",
      "Epoch 19/2000\n",
      " - 1497s - loss: 0.0278 - binary_accuracy: 0.9913 - ACCR: 0.9872 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9685 - FPR: 0.0028 - val_loss: 0.2105 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9498 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9154 - val_FPR: 0.0319\n",
      "\n",
      "Epoch 00019: val_ACCR did not improve from 0.95011\n",
      "Epoch 20/2000\n",
      " - 1503s - loss: 0.0278 - binary_accuracy: 0.9913 - ACCR: 0.9872 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9687 - FPR: 0.0029 - val_loss: 0.2570 - val_binary_accuracy: 0.9520 - val_ACCR: 0.9495 - val_auc2: 0.9964 - val_auc1: 0.9665 - val_TPR: 0.9141 - val_FPR: 0.0316\n",
      "\n",
      "Epoch 00020: val_ACCR did not improve from 0.95011\n",
      "Epoch 21/2000\n",
      " - 1488s - loss: 0.0280 - binary_accuracy: 0.9913 - ACCR: 0.9873 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9688 - FPR: 0.0029 - val_loss: 0.4030 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9155 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00021: val_ACCR did not improve from 0.95011\n",
      "Epoch 22/2000\n",
      " - 1488s - loss: 0.0277 - binary_accuracy: 0.9914 - ACCR: 0.9874 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9691 - FPR: 0.0029 - val_loss: 0.3428 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9495 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9143 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00022: val_ACCR did not improve from 0.95011\n",
      "Epoch 23/2000\n",
      " - 1502s - loss: 0.0279 - binary_accuracy: 0.9914 - ACCR: 0.9874 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9690 - FPR: 0.0028 - val_loss: 0.2698 - val_binary_accuracy: 0.9516 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9668 - val_TPR: 0.9174 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00023: val_ACCR did not improve from 0.95011\n",
      "Epoch 24/2000\n",
      " - 1512s - loss: 0.0277 - binary_accuracy: 0.9913 - ACCR: 0.9874 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9691 - FPR: 0.0029 - val_loss: 0.2875 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9669 - val_TPR: 0.9174 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00024: val_ACCR did not improve from 0.95011\n",
      "Epoch 25/2000\n",
      " - 1504s - loss: 0.0273 - binary_accuracy: 0.9915 - ACCR: 0.9876 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9695 - FPR: 0.0028 - val_loss: 0.2754 - val_binary_accuracy: 0.9527 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9661 - val_TPR: 0.9167 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00025: val_ACCR improved from 0.95011 to 0.95037, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 26/2000\n",
      " - 1529s - loss: 0.0273 - binary_accuracy: 0.9915 - ACCR: 0.9875 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9695 - FPR: 0.0028 - val_loss: 0.4317 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9660 - val_TPR: 0.9172 - val_FPR: 0.0320\n",
      "\n",
      "Epoch 00026: val_ACCR did not improve from 0.95037\n",
      "Epoch 27/2000\n",
      " - 1512s - loss: 0.0272 - binary_accuracy: 0.9916 - ACCR: 0.9876 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9696 - FPR: 0.0028 - val_loss: 0.2681 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9667 - val_TPR: 0.9179 - val_FPR: 0.0324\n",
      "\n",
      "Epoch 00027: val_ACCR did not improve from 0.95037\n",
      "Epoch 28/2000\n",
      " - 1501s - loss: 0.0274 - binary_accuracy: 0.9915 - ACCR: 0.9875 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9695 - FPR: 0.0029 - val_loss: 0.3566 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9664 - val_TPR: 0.9157 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00028: val_ACCR did not improve from 0.95037\n",
      "Epoch 29/2000\n",
      " - 1510s - loss: 0.0273 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9698 - FPR: 0.0028 - val_loss: 0.3408 - val_binary_accuracy: 0.9527 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9658 - val_TPR: 0.9157 - val_FPR: 0.0313\n",
      "\n",
      "Epoch 00029: val_ACCR did not improve from 0.95037\n",
      "Epoch 30/2000\n",
      " - 1511s - loss: 0.0272 - binary_accuracy: 0.9915 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9698 - FPR: 0.0028 - val_loss: 0.2747 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9183 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00030: val_ACCR improved from 0.95037 to 0.95042, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 31/2000\n",
      " - 1495s - loss: 0.0273 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9699 - FPR: 0.0028 - val_loss: 0.2884 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9509 - val_auc2: 0.9964 - val_auc1: 0.9667 - val_TPR: 0.9199 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00031: val_ACCR improved from 0.95042 to 0.95091, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 32/2000\n",
      " - 1513s - loss: 0.0270 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9699 - FPR: 0.0028 - val_loss: 0.2848 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9662 - val_TPR: 0.9169 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00032: val_ACCR did not improve from 0.95091\n",
      "Epoch 33/2000\n",
      " - 1500s - loss: 0.0269 - binary_accuracy: 0.9917 - ACCR: 0.9879 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9705 - FPR: 0.0028 - val_loss: 0.3061 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9661 - val_TPR: 0.9151 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00033: val_ACCR did not improve from 0.95091\n",
      "Epoch 34/2000\n",
      " - 1497s - loss: 0.0269 - binary_accuracy: 0.9917 - ACCR: 0.9878 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9703 - FPR: 0.0028 - val_loss: 0.2738 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9509 - val_auc2: 0.9964 - val_auc1: 0.9664 - val_TPR: 0.9203 - val_FPR: 0.0329\n",
      "\n",
      "Epoch 00034: val_ACCR did not improve from 0.95091\n",
      "Epoch 35/2000\n",
      " - 1507s - loss: 0.0273 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9700 - FPR: 0.0028 - val_loss: 0.2818 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9658 - val_TPR: 0.9155 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00035: val_ACCR did not improve from 0.95091\n",
      "Epoch 36/2000\n",
      " - 1517s - loss: 0.0270 - binary_accuracy: 0.9917 - ACCR: 0.9879 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9704 - FPR: 0.0028 - val_loss: 0.2688 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9177 - val_FPR: 0.0323\n",
      "\n",
      "Epoch 00036: val_ACCR did not improve from 0.95091\n",
      "Epoch 37/2000\n",
      " - 1499s - loss: 0.0268 - binary_accuracy: 0.9918 - ACCR: 0.9881 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9708 - FPR: 0.0027 - val_loss: 0.2949 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9502 - val_auc2: 0.9964 - val_auc1: 0.9660 - val_TPR: 0.9169 - val_FPR: 0.0321\n",
      "\n",
      "Epoch 00037: val_ACCR did not improve from 0.95091\n",
      "Epoch 38/2000\n",
      " - 1513s - loss: 0.0271 - binary_accuracy: 0.9917 - ACCR: 0.9880 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9707 - FPR: 0.0028 - val_loss: 0.2737 - val_binary_accuracy: 0.9526 - val_ACCR: 0.9506 - val_auc2: 0.9964 - val_auc1: 0.9662 - val_TPR: 0.9187 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00038: val_ACCR did not improve from 0.95091\n",
      "Epoch 39/2000\n",
      " - 1491s - loss: 0.0270 - binary_accuracy: 0.9918 - ACCR: 0.9881 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9710 - FPR: 0.0028 - val_loss: 0.3109 - val_binary_accuracy: 0.9530 - val_ACCR: 0.9505 - val_auc2: 0.9964 - val_auc1: 0.9659 - val_TPR: 0.9159 - val_FPR: 0.0311\n",
      "\n",
      "Epoch 00039: val_ACCR did not improve from 0.95091\n",
      "Epoch 40/2000\n",
      " - 1514s - loss: 0.0268 - binary_accuracy: 0.9918 - ACCR: 0.9880 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9708 - FPR: 0.0028 - val_loss: 0.2341 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9502 - val_auc2: 0.9964 - val_auc1: 0.9661 - val_TPR: 0.9166 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00040: val_ACCR did not improve from 0.95091\n",
      "Epoch 41/2000\n",
      " - 1504s - loss: 0.0266 - binary_accuracy: 0.9918 - ACCR: 0.9882 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9710 - FPR: 0.0027 - val_loss: 0.2302 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9658 - val_TPR: 0.9176 - val_FPR: 0.0322\n",
      "\n",
      "Epoch 00041: val_ACCR did not improve from 0.95091\n",
      "Epoch 42/2000\n",
      " - 1489s - loss: 0.0267 - binary_accuracy: 0.9918 - ACCR: 0.9881 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9711 - FPR: 0.0028 - val_loss: 0.3438 - val_binary_accuracy: 0.9526 - val_ACCR: 0.9506 - val_auc2: 0.9964 - val_auc1: 0.9654 - val_TPR: 0.9174 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00042: val_ACCR did not improve from 0.95091\n",
      "Epoch 43/2000\n",
      " - 1500s - loss: 0.0265 - binary_accuracy: 0.9918 - ACCR: 0.9882 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9711 - FPR: 0.0028 - val_loss: 0.2689 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9502 - val_auc2: 0.9964 - val_auc1: 0.9657 - val_TPR: 0.9154 - val_FPR: 0.0313\n",
      "\n",
      "Epoch 00043: val_ACCR did not improve from 0.95091\n",
      "Epoch 44/2000\n",
      " - 1545s - loss: 0.0264 - binary_accuracy: 0.9919 - ACCR: 0.9883 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9714 - FPR: 0.0027 - val_loss: 0.3232 - val_binary_accuracy: 0.9528 - val_ACCR: 0.9506 - val_auc2: 0.9964 - val_auc1: 0.9656 - val_TPR: 0.9190 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00044: val_ACCR did not improve from 0.95091\n",
      "Epoch 45/2000\n",
      " - 1499s - loss: 0.0263 - binary_accuracy: 0.9920 - ACCR: 0.9884 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9716 - FPR: 0.0027 - val_loss: 0.3446 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9654 - val_TPR: 0.9170 - val_FPR: 0.0322\n",
      "\n",
      "Epoch 00045: val_ACCR did not improve from 0.95091\n",
      "Epoch 46/2000\n",
      " - 1507s - loss: 0.0263 - binary_accuracy: 0.9919 - ACCR: 0.9884 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9717 - FPR: 0.0028 - val_loss: 0.1883 - val_binary_accuracy: 0.9526 - val_ACCR: 0.9512 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9208 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00046: val_ACCR improved from 0.95091 to 0.95119, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 47/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter2 import*\n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 10, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [18:42:39] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:02, 518369.47it/s]\n",
      "inscopedata: 1789651it [00:04, 418969.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 1527s - loss: 0.2822 - binary_accuracy: 0.9154 - ACCR: 0.8798 - auc1: 0.9608 - TPR: 0.7117 - FPR: 0.0307 - binary_crossentropy: 0.2822 - val_loss: 0.2393 - val_binary_accuracy: 0.9341 - val_ACCR: 0.9147 - val_auc1: 0.9680 - val_TPR: 0.8088 - val_FPR: 0.0289 - val_binary_crossentropy: 0.2628\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.91468, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 1397s - loss: 0.2457 - binary_accuracy: 0.9476 - ACCR: 0.9378 - auc1: 0.9725 - TPR: 0.8701 - FPR: 0.0261 - binary_crossentropy: 0.2457 - val_loss: 0.3048 - val_binary_accuracy: 0.9397 - val_ACCR: 0.9315 - val_auc1: 0.9555 - val_TPR: 0.8614 - val_FPR: 0.0312 - val_binary_crossentropy: 0.3569\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.91468 to 0.93147, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter2 import*\n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 5, \n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
