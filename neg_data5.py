import os
import numpy as np
import tensorflow as tf
import re
from tqdm import tqdm
from rdkit.Chem import AllChem
from rdkit import Chem, RDLogger
from itertools import chain, permutations
from multiprocessing import Pool, freeze_support
from collections import defaultdict
import random
from functools import partial
from highway_layer import Highway
#匯入深度學習的框架函式庫：keras
import keras
from keras import backend as K
from keras.initializers import Constant
from keras.utils import plot_model
#keras用以建立模型架構的函數
from keras.models import Sequential, load_model, Model

#keras中建立深度學習layer的函數

from keras.layers import Dense, Dropout, BatchNormalization, Activation, Multiply, Add, Lambda, Input

#keras訓練演算法函數
from keras import regularizers
from keras.optimizers import Adam

#keras提早判停的函數
from keras.callbacks import EarlyStopping, ModelCheckpoint

#it's hard to reproduce results, so close all seeds
#os.environ['PYTHONHASHSEED'] = '0'
#np.random.seed(0)
#tf.set_random_seed(0)
#random.seed(0)

#to solve problem:Blas GEMM launch failed
from keras.backend.tensorflow_backend import set_session
config = tf.ConfigProto()
#config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)
config.gpu_options.allocator_type = 'BFC' #A "Best-fit with coalescing" algorithm, simplified from a version of dlmalloc.
config.gpu_options.per_process_gpu_memory_fraction = 0.95
config.gpu_options.allow_growth = True
set_session(tf.Session(config=config)) 

def fps_to_arr(fps):
    """Faster conversion to ndarray"""
    arrs = []
    for fp, info in zip(fps[0],fps[1]):
        onbits = list(fp.GetOnBits())
        arr = np.zeros(fp.GetNumBits())
        for onbit in onbits:
            arr[onbit] = len(info[onbit])
        arrs.append(arr)
    arrs = np.array(arrs)
    return arrs




def fingerprint_mols(mols, fp_dim):
    fps = []
    infos = []
    for mol in mols:
        mol = Chem.MolFromSmiles(mol)
        info={}
        # Necessary for fingerprinting
        # Chem.GetSymmSSSR(mol)

        # "When comparing the ECFP/FCFP fingerprints and
        # the Morgan fingerprints generated by the RDKit,
        # remember that the 4 in ECFP4 corresponds to the
        # diameter of the atom environments considered,
        # while the Morgan fingerprints take a radius parameter.
        # So the examples above, with radius=2, are roughly
        # equivalent to ECFP4 and FCFP4."
        # <http://www.rdkit.org/docs/GettingStartedInPython.html>
        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=int(fp_dim), useChirality=1, bitInfo=info)
        # fold_factor = fp.GetNumBits()//fp_dim
        # fp = DataStructs.FoldFingerprint(fp, fold_factor)
        fps.append(fp)
        infos.append(info)
    return fps, infos

def preprocess(X, fp_dim, idx):
    # Compute fingerprints
    dataX = fps_to_arr(fingerprint_mols(X, fp_dim))
    # Apply variance threshold
    # return np.log(X[:,self.idx] + 1) 
    #FPs = np.log(dataX[:,idx]+1)
    #FPs = np.log(dataX+1)
    FPs = dataX
    return FPs
# 設定訓練方式，包含loss、optimizer..)
def acc_top50(y_true, y_pred):
    return keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=50)

def acc_top10(y_true, y_pred):
    return keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=10)

def mol_list_to_str(mols):
    '''List of RDKit molecules to string separated by ++'''
    inchis = [Chem.MolToSmiles(mol, allHsExplicit=True,allBondsExplicit=True) for mol in mols]
    return ' ++ '.join(inchis)
def mol_list_from_str(inchis):
    '''string separated by ++ to list of RDKit molecules'''
    return [Chem.MolFromSmiles(inchi.strip()) for inchi in inchis.split('++')]

def smi_list_from_str(inchis):
    '''string separated by ++ to list of RDKit molecules'''
    return [inchi.strip() for inchi in inchis.split('++')]

def convert_to_retro(transform):
    '''This function takes a forward synthesis and converts it to a
    retrosynthesis. Only transforms with a single product are kept, since
    retrosyntheses should have a single reactant (and split it up accordingly).'''    

    # Split up original transform
    reactants = transform.split('>>')[0]
    products  = transform.split('>>')[1]

    # Don't force products to be from different molecules (?)
    # -> any reaction template can be intramolecular (might remove later)
    #products = products[1:-1].replace(').(', '.')

    # Don't force the "products" of a retrosynthesis to be two different molecules!
    #reactants = reactants[1:-1].replace(').(', '.')

    return '>>'.join([products, reactants])


        
def seedgen(batch_size):
    save_dir = os.path.join(os.getcwd(), 'saved_models')
    if not os.path.isdir(save_dir):
        os.makedirs(save_dir)
    
    model_path_e = os.path.join(save_dir, 'trained_model_negative_all') #negative_1
    #fp_dim=23086
    fp_dim=16384
    idx = np.load(os.path.join(save_dir, 'expansion5e-5.idx.npy'))   

    
    negative_net = load_model(model_path_e, custom_objects={'acc_top10': acc_top10,'acc_top50': acc_top50, 'Highway': Highway})   
    
    reactant = []

    with open('data/templates_expansion3.dat', 'r') as f:
        for l in f:
            reactant.append(l.strip().split('\t')[2])
#            rule_ans.append(l.strip().split('\t')[0])
#            prod_ans.append(l.strip().split('\t')[1])
#    batch_datasX = reactant[:batch_size]
#    batch_datasY = rule_ans[:10]
#    batch_datasZ = prod_ans[:10]    
    count = -1
    index = 0
    while True:
        count += 1
        if count % batch_size == 0:
            batch_datasX = reactant[batch_size*(index):batch_size*(index+1)]
            X = np.zeros((len(batch_datasX),fp_dim)) 
            for i,a in enumerate(batch_datasX):
                n = np.zeros((1,fp_dim))        
                for b in smi_list_from_str(a):
                    n += preprocess([b], fp_dim, idx) 
                X[i] = n
            X = np.log(X+1)
            # Predict applicable rules
            predict = negative_net.predict_on_batch(X)
            # get the rules index from high probability to low probability
            # avoid special molecule and special rules due to rdkit bug(will shut down program)
            if count ==271842 or count ==790483:
                preds =np.argsort(-predict, axis=1)[:,:50]
            else:
                preds =np.argsort(-predict, axis=1)[:,:200]
            index += 1
#        random.seed(seed)
##        random.shuffle(expansion_rules)
#        rules=random.sample(expansion_rules, 500)
#        seed +=1
##        yield expansion_rules[:500]
        recount = (count) % batch_size
        yield preds[recount]

expansion_rules = []
with open('data/expansion_expansion1.dat', 'r') as f:
    for i, l in tqdm(enumerate(f), desc='expansion'):
        rule = l.strip()
        expansion_rules.append(rule)    
    
def read(combo, rules = expansion_rules):

    line = combo[0]
    seed = combo[1]
#    expansion_rules = []
#    with open('data/expansion_expansion.dat', 'r') as f:
#        for i, l in tqdm(enumerate(f), desc='expansion'):
#            rule = l.strip()
#            expansion_rules.append(rule)
#    rules = expansion_rules       
    prod_to_reacs = defaultdict(set)
    prod_to_noreacs = defaultdict(set)
# rule, prod, reac are strings not lists
    rule, prod, reac = line.strip().split('\t')
#    prod_to_reacs[prod].add(reac)
    #   print(rule)
#    seed = rule+prod+reac
#    random.seed(seed)
#    rulesrad=random.sample(rules, 500)
#    random.shuffle(rules)
    
    rulesrad=[rules[k] for k in seed]
    for r in rulesrad:
        if r== rule: continue
        retro_canonical = convert_to_retro(r)
        #   print(retro_canonical)
        rxn = AllChem.ReactionFromSmarts(retro_canonical)
        rcts= mol_list_from_str(reac)
        if len(rcts) != rxn.GetNumReactantTemplates(): continue
        combinations = permutations(rcts, rxn.GetNumReactantTemplates())
        for rcts in combinations:
        
            try:
                outcomes = rxn.RunReactants(list(rcts))
                if not outcomes: continue
                for outcome in outcomes:
                    for product in outcome:
                    
                        try:
                            Chem.SanitizeMol(product)
                            product.UpdatePropertyCache()
                            #create product or reactant using molfromsmarts+sanitizemol is sometimes better than molfromsmiles, but still using molfromsmiles as possible as you can
                            product=Chem.MolFromSmiles(Chem.MolToSmiles(product,allHsExplicit=True,allBondsExplicit=True))
                        except Exception as e:
        #                   print('warning1: {}'.format(e))
                            #use pass is not good behavior, however i have validation finally
                            continue
                        if not product:
                            continue
                        prodsmi=Chem.MolToSmiles(product,allHsExplicit=True,allBondsExplicit=True)
                        if  prodsmi != prod:
                            prod_to_noreacs[prodsmi].add(reac)
                            continue
                        if  prodsmi == prod:
                            prod_to_reacs[prodsmi].add(reac)
                        #tolri doesnt work well due to repeated same prodsmi but different product   
            #               Tolri+=1
                 
            except Exception as e:
                print('error: {}'.format(e))
                print('rxn: {}'.format(reac))
    
    return prod_to_reacs,prod_to_noreacs

if __name__ == '__main__':
    print('Loading data...')
    prod_to_reacs = defaultdict(set)
    prod_to_noreacs = defaultdict(set)
    Tolri=0
    Tolpos=0
    Tolneg=0
    batch_size = 1
#    reactant = []
#    rule_ans = []
#    prod_ans = []

#    expansion_rules = []
    tem_simp = set()
#    seed =0
#    random.seed(seed)
#    with open('data/templates_expansion3.dat', 'r') as f:
#        for l in f:
#            reactant.append(l.strip().split('\t')[2])
#            rule_ans.append(l.strip().split('\t')[0])
#            prod_ans.append(l.strip().split('\t')[1])
#    batch_datasX = reactant[:10]
#    batch_datasY = rule_ans[:10]
#    batch_datasZ = prod_ans[:10]
#    with open('data/expansion_expansion.dat', 'r') as f:
#        for i, l in tqdm(enumerate(f), desc='expansion'):
#            rule = l.strip()
#            expansion_rules.append(rule)

#    with open('data/templates_expansion1.dat', 'r') as f:
#        for l in tqdm(f, desc='products'):
#                tem_simp.add(l.strip())
#    with open('data/templates_expansion3.dat', 'w') as f:
#        f.write('\n'.join(tem_simp))                           

    with open('data/templates_expansion3.dat', 'r') as f:
    #    for l in tqdm(f, desc='products'):
#        seeds=[a for a in range(len(f.readlines()))]
#        combo[0]=f
#        combo[1]=seeds
    

    
        with Pool() as p:
#            for reacs,noreacs in tqdm(p.imap(partial(read, rules=expansion_rules), f)):
            for reacs,noreacs in tqdm(p.imap(read, zip(f, seedgen(batch_size)))):  
                for reac, values in reacs.items():
                    for value in values:
                        prod_to_reacs[reac].add(value)
                
                for reac, values in noreacs.items():
                    for value in values:
                        prod_to_noreacs[reac].add(value)
                    
    transforms=[]  
    for prod, reacs in prod_to_reacs.items():
        for reac in reacs:
            transforms.append((prod, reac, '1'))
            Tolpos+=1

    for prod, noreacs in prod_to_noreacs.items():
        for noreac in noreacs:
            transforms.append((prod, noreac, '0'))             
            Tolneg+=1
    with open('data/inscopedata4all.dat', 'w') as f:
        f.write('\n'.join(['\t'.join(rxn_prod) for rxn_prod in transforms]))

    print('total positive Expansion rules examples:',Tolpos) 
    print('total negative Expansion rules examples:',Tolneg)