{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [15:45:00] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:03, 508932.08it/s]\n",
      "inscopedata: 1789651it [00:04, 413748.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      "  27/5831 [..............................] - ETA: 10:10:25 - loss: 0.6935 - binary_accuracy: 0.4766 - auc2: 0.4899 - auc1: 0.4718 - TPR: 0.0000e+00 - FPR: 0.0000e+0 - ETA: 5:12:22 - loss: 0.6812 - binary_accuracy: 0.6035 - auc2: 0.5711 - auc1: 0.6237 - TPR: 0.0000e+00 - FPR: 0.0000e+0 - ETA: 3:32:22 - loss: 0.6712 - binary_accuracy: 0.6484 - auc2: 0.6186 - auc1: 0.6825 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 2:43:41 - loss: 0.6653 - binary_accuracy: 0.6694 - auc2: 0.6460 - auc1: 0.7034 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 2:12:56 - loss: 0.6597 - binary_accuracy: 0.6797 - auc2: 0.6646 - auc1: 0.7192 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:52:24 - loss: 0.6549 - binary_accuracy: 0.6924 - auc2: 0.6786 - auc1: 0.7307 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:37:46 - loss: 0.6489 - binary_accuracy: 0.7056 - auc2: 0.6907 - auc1: 0.7454 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:27:58 - loss: 0.6445 - binary_accuracy: 0.7129 - auc2: 0.7006 - auc1: 0.7527 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:19:16 - loss: 0.6409 - binary_accuracy: 0.7166 - auc2: 0.7085 - auc1: 0.7581 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:12:21 - loss: 0.6377 - binary_accuracy: 0.7197 - auc2: 0.7151 - auc1: 0.7615 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:11:24 - loss: 0.6347 - binary_accuracy: 0.7221 - auc2: 0.7206 - auc1: 0.7649 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:11:39 - loss: 0.6329 - binary_accuracy: 0.7209 - auc2: 0.7249 - auc1: 0.7648 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:09:48 - loss: 0.6301 - binary_accuracy: 0.7222 - auc2: 0.7286 - auc1: 0.7674 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:08:13 - loss: 0.6269 - binary_accuracy: 0.7267 - auc2: 0.7321 - auc1: 0.7717 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:06:52 - loss: 0.6239 - binary_accuracy: 0.7301 - auc2: 0.7353 - auc1: 0.7745 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:05:39 - loss: 0.6214 - binary_accuracy: 0.7328 - auc2: 0.7382 - auc1: 0.7780 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:04:37 - loss: 0.6193 - binary_accuracy: 0.7330 - auc2: 0.7409 - auc1: 0.7797 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:03:44 - loss: 0.6167 - binary_accuracy: 0.7349 - auc2: 0.7433 - auc1: 0.7819 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:02:57 - loss: 0.6138 - binary_accuracy: 0.7380 - auc2: 0.7457 - auc1: 0.7855 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:02:06 - loss: 0.6122 - binary_accuracy: 0.7382 - auc2: 0.7478 - auc1: 0.7856 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:01:25 - loss: 0.6097 - binary_accuracy: 0.7401 - auc2: 0.7498 - auc1: 0.7880 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:00:52 - loss: 0.6078 - binary_accuracy: 0.7417 - auc2: 0.7516 - auc1: 0.7883 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 1:00:20 - loss: 0.6064 - binary_accuracy: 0.7419 - auc2: 0.7533 - auc1: 0.7891 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 59:50 - loss: 0.6038 - binary_accuracy: 0.7445 - auc2: 0.7549 - auc1: 0.7921 - TPR: 0.0000e+00 - FPR: 0.0000e+00 - ETA: 59:20 - loss: 0.6017 - binary_accuracy: 0.7462 - auc2: 0.7565 - auc1: 0.7938 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 58:53 - loss: 0.6000 - binary_accuracy: 0.7473 - auc2: 0.7580 - auc1: 0.7949 - TPR: 0.0000e+00 - FPR: 0.0000e+ - ETA: 58:28 - loss: 0.5983 - binary_accuracy: 0.7478 - auc2: 0.7594 - auc1: 0.7970 - TPR: 0.0000e+00 - FPR: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "#Inscope改善方案:Learning rate, batch size1024 , 檔案先shuttle好不要放在porgram裡， fold重啟，+dropout，增worker降quene,改善FP反應物字典給值做法，改用簡單的reaction rules FP(rdkit內建版)\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "from tqdm import tqdm, trange\n",
    "from collections import defaultdict\n",
    "from highway_layer import Highway\n",
    "#匯入深度學習的框架函式庫：keras\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.initializers import Constant\n",
    "from keras.utils import plot_model\n",
    "#keras用以建立模型架構的函數\n",
    "from keras.models import Sequential, load_model, Model\n",
    "\n",
    "#keras中建立深度學習layer的函數\n",
    "\n",
    "from keras.layers import Dense, Dropout, BatchNormalization, Activation, Multiply, Add, Lambda, Input\n",
    "from keras import metrics, losses\n",
    "#keras訓練演算法函數\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#keras提早判停的函數\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#it's hard to reproduce results, so close all seeds\n",
    "#os.environ['PYTHONHASHSEED'] = '0'\n",
    "#np.random.seed(0)\n",
    "#tf.set_random_seed(0)\n",
    "#random.seed(0)\n",
    "\n",
    "#to solve problem:Blas GEMM launch failed\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "#config = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "config.gpu_options.allocator_type = 'BFC' #A \"Best-fit with coalescing\" algorithm, simplified from a version of dlmalloc.\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "config.gpu_options.allow_growth = True\n",
    "set_session(tf.Session(config=config)) \n",
    "\n",
    "\n",
    "def fps_to_arr(fps):\n",
    "    \"\"\"Faster conversion to ndarray\"\"\"\n",
    "    arrs = []\n",
    "    for fp, info in zip(fps[0],fps[1]):\n",
    "        onbits = list(fp.GetOnBits())\n",
    "        arr = np.zeros(fp.GetNumBits())\n",
    "        for onbit in onbits:\n",
    "            arr[onbit] = len(info[onbit])\n",
    "        arrs.append(arr)\n",
    "    arrs = np.array(arrs)\n",
    "    return arrs\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fingerprint_mols(mols, fp_dim):\n",
    "    fps = []\n",
    "    infos = []\n",
    "    for mol in mols:\n",
    "        mol = Chem.MolFromSmiles(mol)\n",
    "        info={}\n",
    "        # Necessary for fingerprinting\n",
    "        # Chem.GetSymmSSSR(mol)\n",
    "\n",
    "        # \"When comparing the ECFP/FCFP fingerprints and\n",
    "        # the Morgan fingerprints generated by the RDKit,\n",
    "        # remember that the 4 in ECFP4 corresponds to the\n",
    "        # diameter of the atom environments considered,\n",
    "        # while the Morgan fingerprints take a radius parameter.\n",
    "        # So the examples above, with radius=2, are roughly\n",
    "        # equivalent to ECFP4 and FCFP4.\"\n",
    "        # <http://www.rdkit.org/docs/GettingStartedInPython.html>\n",
    "        fp = AllChem.GetMorganFingerprintAsBitVect(mol, radius=2, nBits=int(fp_dim), useChirality=1, bitInfo=info)\n",
    "        # fold_factor = fp.GetNumBits()//fp_dim\n",
    "        # fp = DataStructs.FoldFingerprint(fp, fold_factor)\n",
    "        fps.append(fp)\n",
    "        infos.append(info)\n",
    "    return fps, infos\n",
    "\n",
    "def preprocess(X, fp_dim):\n",
    "    # Compute fingerprints\n",
    "    FPs = fps_to_arr(fingerprint_mols(X, fp_dim))\n",
    "    # Apply variance threshold\n",
    "    # return np.log(X[:,self.idx] + 1) \n",
    "    #FPs = np.log(dataX[:,idx]+1)\n",
    "#    FPs = np.log(dataX+1)\n",
    "    return FPs\n",
    "def smi_list_from_str(inchis):\n",
    "    '''string separated by ++ to list of RDKit molecules'''\n",
    "    return [inchi.strip() for inchi in inchis.split('++')]\n",
    "\n",
    "class DataGenerator(keras.utils.Sequence):\n",
    "    \n",
    "    def __init__(self, X, y, z, batch_size=1, shuffle=True, fp_dim=16384, recfp_dim=2048):\n",
    "        self.batch_size = batch_size\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        self.shuffle = shuffle\n",
    "        self.fp_dim = fp_dim\n",
    "        self.recfp_dim = recfp_dim\n",
    "\n",
    "    def __len__(self):\n",
    "        #计算每一个epoch的迭代次数\n",
    "        return int(np.floor(len(self.X) / int(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        #生成每个batch数据，这里就根据自己对数据的读取方式进行发挥了\n",
    "        # 生成batch_size个索引\n",
    "        batch_indexs = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "        # 根据索引获取datas集合中的数据\n",
    "        batch_datasX = [self.X[k] for k in batch_indexs]\n",
    "        batch_datasy = [self.y[k] for k in batch_indexs]\n",
    "        batch_datasz = [self.z[k] for k in batch_indexs]\n",
    "        # 生成数据\n",
    "        X = preprocess(batch_datasX, self.fp_dim)\n",
    "        y = np.zeros((len(batch_datasy),self.recfp_dim))\n",
    "        for i,a in enumerate(batch_datasy):\n",
    "            n = np.zeros((1,self.recfp_dim))\n",
    "            for b in smi_list_from_str(a):\n",
    "                n += preprocess([b], self.recfp_dim)\n",
    "            p = X[i].reshape((-1,self.recfp_dim))    \n",
    "            y[i] = np.sum(p, 0, keepdims=True)- n\n",
    "        z = np.array(batch_datasz)\n",
    "#        y = y.astype(np.int64)\n",
    "        return [X, y], [z]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        #在每一次epoch结束是否需要进行一次随机，重新随机一下index\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "def fold(x):\n",
    "    z=tf.subtract(x[0], x[1])\n",
    "#    z_shape=tf.Tensor.shape(z)\n",
    "\n",
    "#    z_shape=z.get_shape().as_list()\n",
    "    zv=tf.reshape(z,[-1,8,2048])\n",
    "    return tf.reduce_sum(zv, 1) \n",
    "\n",
    "def cosine(x):\n",
    "    prod_net = x[0]\n",
    "    react_net = x[1]\n",
    "#    prod_norm = tf.nn.l2_normalize(prod_net, axis=-1)\n",
    "#    react_norm = tf.nn.l2_normalize(react_net, axis=-1)\n",
    "    cosine_sim = tf.reduce_sum(tf.multiply(prod_net, react_net), axis=-1,keepdims=True)\n",
    "#    cosine_sim = tf.squeeze(cosine_sim,[1])\n",
    "#    return tf.nn.sigmoid(cosine_sim)\n",
    "    return tf.nn.sigmoid(cosine_sim)\n",
    "# get average auc between different batches over the epoch, so don't use. otherwise validation process always get wrong results\n",
    "def auc2(y_true, y_pred):\n",
    "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
    "    K.get_session().run(tf.local_variables_initializer())\n",
    "    return auc\n",
    "\n",
    "# AUC for a binary classifier, this AUC is a little underestimated due to minimum areas.\n",
    "def auc1(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# PFA, prob false alert for binary classifier(FPR)\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# P_TA prob true alerts for binary classifier(TPR)\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "# PFA, prob false alert for binary classifier(FPR)\n",
    "def FPR(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred >= 0.9, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# P_TA prob true alerts for binary classifier(TPR)\n",
    "def TPR(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred >= 0.9, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P\n",
    "\n",
    "# ACC= (TP + TN) / (P + N)\n",
    "def ACCR(y_true, y_pred):\n",
    "    y_pred = K.cast(y_pred >= 0.9, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)    \n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    # TN = total number of correct alerts, alerts from the negtive class labels\n",
    "    TN = K.sum((1-y_pred) * (1-y_true))    \n",
    "    return (TP+TN)/(P+N)\n",
    "\n",
    "\n",
    "            #設定訓練參數和訓練模型存放路徑\n",
    "#batch_size = 3\n",
    "batch_size = 512\n",
    "#num_classes = 6\n",
    "epochs = 2000\n",
    "#epochs = 100\n",
    "seed=0\n",
    "#validation spilt\n",
    "spilt=0.1\n",
    "#for variance threshold\n",
    "#fp_dim=1e6\n",
    "fp_dim=16384\n",
    "recfp_dim=2048\n",
    "model_name = 'trained_model_inscope_'+str(seed)\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "\n",
    "\n",
    "#build model\n",
    "visible = Input(shape=(fp_dim,))\n",
    "hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "hidden = Dense(1024, activation='elu')(hidden)\n",
    "hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "# only for expansion rule policynet\n",
    "for _ in range(5):\n",
    "    hidden = Highway()(hidden)\n",
    "#    hidden = Dropout(0.4)(hidden)\n",
    "#another branch\n",
    "#visible1 = Input(shape=(fp_dim,))\n",
    "visible2 = Input(shape=(recfp_dim,))\n",
    "#hidden1 = Lambda(fold)([visible, visible2])\n",
    "hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "output = Lambda(cosine)([hidden, hidden1])\n",
    "#,output_shape=(1,)\n",
    "    \n",
    "model = Model(inputs=[visible,visible2], outputs=output)\n",
    "# summarize layers\n",
    "print(model.summary())\n",
    "# plot graph\n",
    "#plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "# 初始化Adam optimizer\n",
    "opt = keras.optimizers.Adam(lr=0.001)\n",
    "\n",
    "# 設定訓練方式，包含loss、optimizer..)\n",
    "loss1=losses.binary_crossentropy\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=[ACCR, auc1, TPR, FPR, loss1])\n",
    "#metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "# early stop存放模型設置\n",
    "\n",
    "\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "checkpoint = ModelCheckpoint(model_path, monitor='val_ACCR', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "# early stop參數設定\n",
    "earlystop = EarlyStopping(monitor='val_ACCR', patience=6, verbose=1, mode='max')\n",
    "\n",
    "#continue training\n",
    "#del model  # 删掉存在的模型\n",
    "\n",
    "#返回一个编译好的模型\n",
    "#与删掉的模型相同\n",
    "#model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "##model.compile(loss='binary_crossentropy',\n",
    "##              optimizer=opt,\n",
    "##              metrics=['binary_accuracy',ACCR, auc, auc1, TPR, FPR, loss1])\n",
    "\n",
    "# 開始訓練\n",
    "training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "if __name__ == '__main__':\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=1,\n",
    "                    initial_epoch=0,\n",
    "#                    workers=0, \n",
    "#                    use_multiprocessing=True, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 10, \n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [10:34:41] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           highway_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           dropout_6[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 3/2000\n",
      " - 22245s - loss: 0.1111 - binary_accuracy: 0.9591 - ACCR: 0.9551 - auc1: 0.9331 - TPR: 0.3328 - FPR: 0.0097 - val_loss: 0.1092 - val_binary_accuracy: 0.9675 - val_ACCR: 0.9572 - val_auc1: 0.9654 - val_TPR: 0.4644 - val_FPR: 0.0075\n",
      "\n",
      "Epoch 00003: val_ACCR improved from -inf to 0.95719, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 22961s - loss: 0.0923 - binary_accuracy: 0.9654 - ACCR: 0.9583 - auc1: 0.9573 - TPR: 0.4811 - FPR: 0.0105 - val_loss: 0.0911 - val_binary_accuracy: 0.9703 - val_ACCR: 0.9589 - val_auc1: 0.9691 - val_TPR: 0.5107 - val_FPR: 0.0068\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.95719 to 0.95889, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 23157s - loss: 0.0852 - binary_accuracy: 0.9681 - ACCR: 0.9603 - auc1: 0.9637 - TPR: 0.5345 - FPR: 0.0103 - val_loss: 0.0683 - val_binary_accuracy: 0.9725 - val_ACCR: 0.9608 - val_auc1: 0.9723 - val_TPR: 0.5668 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00005: val_ACCR improved from 0.95889 to 0.96078, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/2000\n",
      " - 22985s - loss: 0.0803 - binary_accuracy: 0.9701 - ACCR: 0.9618 - auc1: 0.9677 - TPR: 0.5700 - FPR: 0.0100 - val_loss: 0.0640 - val_binary_accuracy: 0.9734 - val_ACCR: 0.9619 - val_auc1: 0.9741 - val_TPR: 0.5869 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.96078 to 0.96193, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 22943s - loss: 0.0764 - binary_accuracy: 0.9715 - ACCR: 0.9630 - auc1: 0.9707 - TPR: 0.5950 - FPR: 0.0097 - val_loss: 0.0667 - val_binary_accuracy: 0.9744 - val_ACCR: 0.9630 - val_auc1: 0.9752 - val_TPR: 0.6086 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00007: val_ACCR improved from 0.96193 to 0.96299, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/2000\n",
      " - 23205s - loss: 0.0732 - binary_accuracy: 0.9727 - ACCR: 0.9641 - auc1: 0.9730 - TPR: 0.6163 - FPR: 0.0095 - val_loss: 0.0917 - val_binary_accuracy: 0.9749 - val_ACCR: 0.9632 - val_auc1: 0.9756 - val_TPR: 0.6042 - val_FPR: 0.0066\n",
      "\n",
      "Epoch 00008: val_ACCR improved from 0.96299 to 0.96322, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/2000\n",
      " - 23287s - loss: 0.0706 - binary_accuracy: 0.9737 - ACCR: 0.9650 - auc1: 0.9748 - TPR: 0.6327 - FPR: 0.0093 - val_loss: 0.0735 - val_binary_accuracy: 0.9756 - val_ACCR: 0.9650 - val_auc1: 0.9760 - val_TPR: 0.6366 - val_FPR: 0.0075\n",
      "\n",
      "Epoch 00009: val_ACCR improved from 0.96322 to 0.96495, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 10/2000\n",
      " - 23092s - loss: 0.0682 - binary_accuracy: 0.9746 - ACCR: 0.9658 - auc1: 0.9764 - TPR: 0.6475 - FPR: 0.0091 - val_loss: 0.0387 - val_binary_accuracy: 0.9760 - val_ACCR: 0.9652 - val_auc1: 0.9760 - val_TPR: 0.6324 - val_FPR: 0.0069\n",
      "\n",
      "Epoch 00010: val_ACCR improved from 0.96495 to 0.96522, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 11/2000\n",
      " - 22985s - loss: 0.0661 - binary_accuracy: 0.9754 - ACCR: 0.9666 - auc1: 0.9778 - TPR: 0.6611 - FPR: 0.0089 - val_loss: 0.0896 - val_binary_accuracy: 0.9765 - val_ACCR: 0.9655 - val_auc1: 0.9768 - val_TPR: 0.6477 - val_FPR: 0.0072\n",
      "\n",
      "Epoch 00011: val_ACCR improved from 0.96522 to 0.96553, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 12/2000\n",
      " - 23252s - loss: 0.0644 - binary_accuracy: 0.9761 - ACCR: 0.9673 - auc1: 0.9789 - TPR: 0.6716 - FPR: 0.0088 - val_loss: 0.1001 - val_binary_accuracy: 0.9768 - val_ACCR: 0.9664 - val_auc1: 0.9766 - val_TPR: 0.6587 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00012: val_ACCR improved from 0.96553 to 0.96645, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 13/2000\n",
      " - 23349s - loss: 0.0627 - binary_accuracy: 0.9767 - ACCR: 0.9679 - auc1: 0.9798 - TPR: 0.6820 - FPR: 0.0086 - val_loss: 0.0531 - val_binary_accuracy: 0.9771 - val_ACCR: 0.9681 - val_auc1: 0.9771 - val_TPR: 0.6810 - val_FPR: 0.0082\n",
      "\n",
      "Epoch 00013: val_ACCR improved from 0.96645 to 0.96810, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 14/2000\n",
      " - 23192s - loss: 0.0613 - binary_accuracy: 0.9772 - ACCR: 0.9685 - auc1: 0.9808 - TPR: 0.6912 - FPR: 0.0085 - val_loss: 0.0439 - val_binary_accuracy: 0.9772 - val_ACCR: 0.9673 - val_auc1: 0.9761 - val_TPR: 0.6671 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00014: val_ACCR did not improve from 0.96810\n",
      "Epoch 15/2000\n",
      " - 23051s - loss: 0.0601 - binary_accuracy: 0.9777 - ACCR: 0.9690 - auc1: 0.9813 - TPR: 0.6991 - FPR: 0.0084 - val_loss: 0.0683 - val_binary_accuracy: 0.9775 - val_ACCR: 0.9682 - val_auc1: 0.9768 - val_TPR: 0.6745 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00015: val_ACCR improved from 0.96810 to 0.96816, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 16/2000\n",
      " - 22900s - loss: 0.0589 - binary_accuracy: 0.9782 - ACCR: 0.9695 - auc1: 0.9821 - TPR: 0.7066 - FPR: 0.0083 - val_loss: 0.0467 - val_binary_accuracy: 0.9778 - val_ACCR: 0.9690 - val_auc1: 0.9765 - val_TPR: 0.6893 - val_FPR: 0.0079\n",
      "\n",
      "Epoch 00016: val_ACCR improved from 0.96816 to 0.96899, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 17/2000\n",
      " - 23261s - loss: 0.0579 - binary_accuracy: 0.9786 - ACCR: 0.9699 - auc1: 0.9825 - TPR: 0.7127 - FPR: 0.0082 - val_loss: 0.0830 - val_binary_accuracy: 0.9779 - val_ACCR: 0.9688 - val_auc1: 0.9766 - val_TPR: 0.6881 - val_FPR: 0.0077\n",
      "\n",
      "Epoch 00017: val_ACCR did not improve from 0.96899\n",
      "Epoch 18/2000\n",
      " - 23142s - loss: 0.0568 - binary_accuracy: 0.9790 - ACCR: 0.9704 - auc1: 0.9832 - TPR: 0.7196 - FPR: 0.0081 - val_loss: 0.0280 - val_binary_accuracy: 0.9780 - val_ACCR: 0.9691 - val_auc1: 0.9763 - val_TPR: 0.6867 - val_FPR: 0.0075\n",
      "\n",
      "Epoch 00018: val_ACCR improved from 0.96899 to 0.96908, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 19/2000\n",
      " - 23202s - loss: 0.0560 - binary_accuracy: 0.9793 - ACCR: 0.9708 - auc1: 0.9835 - TPR: 0.7249 - FPR: 0.0080 - val_loss: 0.0580 - val_binary_accuracy: 0.9781 - val_ACCR: 0.9688 - val_auc1: 0.9761 - val_TPR: 0.6839 - val_FPR: 0.0072\n",
      "\n",
      "Epoch 00019: val_ACCR did not improve from 0.96908\n",
      "Epoch 20/2000\n",
      " - 22920s - loss: 0.0552 - binary_accuracy: 0.9796 - ACCR: 0.9712 - auc1: 0.9840 - TPR: 0.7298 - FPR: 0.0079 - val_loss: 0.0468 - val_binary_accuracy: 0.9783 - val_ACCR: 0.9699 - val_auc1: 0.9760 - val_TPR: 0.6980 - val_FPR: 0.0077\n",
      "\n",
      "Epoch 00020: val_ACCR improved from 0.96908 to 0.96995, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 21/2000\n",
      " - 23233s - loss: 0.0545 - binary_accuracy: 0.9799 - ACCR: 0.9715 - auc1: 0.9843 - TPR: 0.7341 - FPR: 0.0079 - val_loss: 0.0391 - val_binary_accuracy: 0.9785 - val_ACCR: 0.9698 - val_auc1: 0.9760 - val_TPR: 0.6942 - val_FPR: 0.0074\n",
      "\n",
      "Epoch 00021: val_ACCR did not improve from 0.96995\n",
      "Epoch 22/2000\n",
      " - 23177s - loss: 0.0537 - binary_accuracy: 0.9802 - ACCR: 0.9719 - auc1: 0.9847 - TPR: 0.7390 - FPR: 0.0078 - val_loss: 0.0461 - val_binary_accuracy: 0.9786 - val_ACCR: 0.9704 - val_auc1: 0.9757 - val_TPR: 0.7009 - val_FPR: 0.0076\n",
      "\n",
      "Epoch 00022: val_ACCR improved from 0.96995 to 0.97041, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 23/2000\n",
      " - 23221s - loss: 0.0532 - binary_accuracy: 0.9804 - ACCR: 0.9722 - auc1: 0.9849 - TPR: 0.7424 - FPR: 0.0077 - val_loss: 0.0708 - val_binary_accuracy: 0.9786 - val_ACCR: 0.9707 - val_auc1: 0.9759 - val_TPR: 0.7079 - val_FPR: 0.0080\n",
      "\n",
      "Epoch 00023: val_ACCR improved from 0.97041 to 0.97066, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 24/2000\n",
      " - 22865s - loss: 0.0525 - binary_accuracy: 0.9806 - ACCR: 0.9724 - auc1: 0.9853 - TPR: 0.7460 - FPR: 0.0077 - val_loss: 0.1018 - val_binary_accuracy: 0.9787 - val_ACCR: 0.9705 - val_auc1: 0.9744 - val_TPR: 0.6963 - val_FPR: 0.0072\n",
      "\n",
      "Epoch 00024: val_ACCR did not improve from 0.97066\n",
      "Epoch 25/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    epochs = 2000\n",
    "    #epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0.1\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_ACCR', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_ACCR', patience=6, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf})\n",
    "    #model.compile(loss='binary_crossentropy',\n",
    "    #              optimizer=opt,\n",
    "    #              metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=2,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=False, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 12, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [11:03:04] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           highway_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           dropout_6[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 22572s - loss: 0.1401 - binary_accuracy: 0.9514 - ACCR: 0.9479 - auc1: 0.8823 - TPR: 0.1235 - FPR: 0.0073 - val_loss: 0.1406 - val_binary_accuracy: 0.9573 - val_ACCR: 0.9577 - val_auc1: 0.9341 - val_TPR: 0.1896 - val_FPR: 0.0045\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.95773, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 22958s - loss: 0.1125 - binary_accuracy: 0.9579 - ACCR: 0.9573 - auc1: 0.9337 - TPR: 0.2632 - FPR: 0.0075 - val_loss: 0.0777 - val_binary_accuracy: 0.9610 - val_ACCR: 0.9619 - val_auc1: 0.9502 - val_TPR: 0.2847 - val_FPR: 0.0054\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.95773 to 0.96188, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 22933s - loss: 0.1023 - binary_accuracy: 0.9611 - ACCR: 0.9607 - auc1: 0.9472 - TPR: 0.3474 - FPR: 0.0083 - val_loss: 0.1141 - val_binary_accuracy: 0.9639 - val_ACCR: 0.9645 - val_auc1: 0.9578 - val_TPR: 0.3665 - val_FPR: 0.0065\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.96188 to 0.96446, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 23045s - loss: 0.0958 - binary_accuracy: 0.9635 - ACCR: 0.9631 - auc1: 0.9544 - TPR: 0.4039 - FPR: 0.0087 - val_loss: 0.0955 - val_binary_accuracy: 0.9658 - val_ACCR: 0.9663 - val_auc1: 0.9618 - val_TPR: 0.4151 - val_FPR: 0.0068\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.96446 to 0.96628, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 22354s - loss: 0.0912 - binary_accuracy: 0.9652 - ACCR: 0.9648 - auc1: 0.9591 - TPR: 0.4431 - FPR: 0.0088 - val_loss: 0.1107 - val_binary_accuracy: 0.9667 - val_ACCR: 0.9676 - val_auc1: 0.9644 - val_TPR: 0.4241 - val_FPR: 0.0063\n",
      "\n",
      "Epoch 00005: val_ACCR improved from 0.96628 to 0.96762, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/2000\n",
      " - 22585s - loss: 0.0876 - binary_accuracy: 0.9666 - ACCR: 0.9662 - auc1: 0.9624 - TPR: 0.4743 - FPR: 0.0089 - val_loss: 0.0774 - val_binary_accuracy: 0.9679 - val_ACCR: 0.9686 - val_auc1: 0.9666 - val_TPR: 0.4590 - val_FPR: 0.0068\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.96762 to 0.96856, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 22859s - loss: 0.0846 - binary_accuracy: 0.9677 - ACCR: 0.9674 - auc1: 0.9651 - TPR: 0.4984 - FPR: 0.0089 - val_loss: 0.0946 - val_binary_accuracy: 0.9690 - val_ACCR: 0.9694 - val_auc1: 0.9680 - val_TPR: 0.4939 - val_FPR: 0.0073\n",
      "\n",
      "Epoch 00007: val_ACCR improved from 0.96856 to 0.96940, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    epochs = 2000\n",
    "    #epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0.1\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "        hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.00001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_ACCR', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_ACCR', patience=6, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf})\n",
    "    #model.compile(loss='binary_crossentropy',\n",
    "    #              optimizer=opt,\n",
    "    #              metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    \n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "                    max_queue_size = 3, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:19:31] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 22594s - loss: 0.1166 - binary_accuracy: 0.9572 - ACCR: 0.9556 - auc1: 0.9254 - TPR: 0.2232 - FPR: 0.0063 - val_loss: 0.1202 - val_binary_accuracy: 0.9625 - val_ACCR: 0.9632 - val_auc1: 0.9528 - val_TPR: 0.3319 - val_FPR: 0.0062\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.96322, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 22964s - loss: 0.0902 - binary_accuracy: 0.9654 - ACCR: 0.9656 - auc1: 0.9604 - TPR: 0.4233 - FPR: 0.0075 - val_loss: 0.0905 - val_binary_accuracy: 0.9674 - val_ACCR: 0.9674 - val_auc1: 0.9638 - val_TPR: 0.4624 - val_FPR: 0.0075\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.96322 to 0.96744, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 22344s - loss: 0.0801 - binary_accuracy: 0.9696 - ACCR: 0.9696 - auc1: 0.9691 - TPR: 0.5154 - FPR: 0.0078 - val_loss: 0.0891 - val_binary_accuracy: 0.9702 - val_ACCR: 0.9700 - val_auc1: 0.9690 - val_TPR: 0.5338 - val_FPR: 0.0081\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.96744 to 0.96995, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 22916s - loss: 0.0734 - binary_accuracy: 0.9723 - ACCR: 0.9723 - auc1: 0.9741 - TPR: 0.5715 - FPR: 0.0077 - val_loss: 0.1026 - val_binary_accuracy: 0.9717 - val_ACCR: 0.9718 - val_auc1: 0.9712 - val_TPR: 0.5555 - val_FPR: 0.0076\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.96995 to 0.97182, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 22579s - loss: 0.0683 - binary_accuracy: 0.9744 - ACCR: 0.9744 - auc1: 0.9775 - TPR: 0.6112 - FPR: 0.0075 - val_loss: 0.0689 - val_binary_accuracy: 0.9730 - val_ACCR: 0.9729 - val_auc1: 0.9731 - val_TPR: 0.5900 - val_FPR: 0.0079\n",
      "\n",
      "Epoch 00005: val_ACCR improved from 0.97182 to 0.97291, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/2000\n",
      " - 22434s - loss: 0.0642 - binary_accuracy: 0.9761 - ACCR: 0.9760 - auc1: 0.9801 - TPR: 0.6433 - FPR: 0.0073 - val_loss: 0.0824 - val_binary_accuracy: 0.9741 - val_ACCR: 0.9735 - val_auc1: 0.9747 - val_TPR: 0.6327 - val_FPR: 0.0090\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.97291 to 0.97354, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 22603s - loss: 0.0605 - binary_accuracy: 0.9775 - ACCR: 0.9774 - auc1: 0.9822 - TPR: 0.6694 - FPR: 0.0071 - val_loss: 0.0671 - val_binary_accuracy: 0.9748 - val_ACCR: 0.9743 - val_auc1: 0.9753 - val_TPR: 0.6430 - val_FPR: 0.0087\n",
      "\n",
      "Epoch 00007: val_ACCR improved from 0.97354 to 0.97429, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/2000\n",
      " - 22933s - loss: 0.0573 - binary_accuracy: 0.9788 - ACCR: 0.9787 - auc1: 0.9840 - TPR: 0.6916 - FPR: 0.0069 - val_loss: 0.0786 - val_binary_accuracy: 0.9755 - val_ACCR: 0.9750 - val_auc1: 0.9757 - val_TPR: 0.6560 - val_FPR: 0.0086\n",
      "\n",
      "Epoch 00008: val_ACCR improved from 0.97429 to 0.97502, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/2000\n",
      " - 22592s - loss: 0.0545 - binary_accuracy: 0.9799 - ACCR: 0.9797 - auc1: 0.9855 - TPR: 0.7112 - FPR: 0.0067 - val_loss: 0.0615 - val_binary_accuracy: 0.9759 - val_ACCR: 0.9754 - val_auc1: 0.9758 - val_TPR: 0.6598 - val_FPR: 0.0084\n",
      "\n",
      "Epoch 00009: val_ACCR improved from 0.97502 to 0.97543, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 10/2000\n",
      " - 22436s - loss: 0.0520 - binary_accuracy: 0.9809 - ACCR: 0.9807 - auc1: 0.9866 - TPR: 0.7279 - FPR: 0.0065 - val_loss: 0.0770 - val_binary_accuracy: 0.9763 - val_ACCR: 0.9757 - val_auc1: 0.9760 - val_TPR: 0.6789 - val_FPR: 0.0090\n",
      "\n",
      "Epoch 00010: val_ACCR improved from 0.97543 to 0.97568, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 11/2000\n",
      " - 22642s - loss: 0.0496 - binary_accuracy: 0.9818 - ACCR: 0.9816 - auc1: 0.9878 - TPR: 0.7433 - FPR: 0.0063 - val_loss: 0.0691 - val_binary_accuracy: 0.9765 - val_ACCR: 0.9760 - val_auc1: 0.9757 - val_TPR: 0.6843 - val_FPR: 0.0089\n",
      "\n",
      "Epoch 00011: val_ACCR improved from 0.97568 to 0.97600, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 12/2000\n",
      " - 22995s - loss: 0.0474 - binary_accuracy: 0.9826 - ACCR: 0.9824 - auc1: 0.9887 - TPR: 0.7569 - FPR: 0.0062 - val_loss: 0.0784 - val_binary_accuracy: 0.9767 - val_ACCR: 0.9763 - val_auc1: 0.9750 - val_TPR: 0.6811 - val_FPR: 0.0086\n",
      "\n",
      "Epoch 00012: val_ACCR improved from 0.97600 to 0.97633, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 13/2000\n",
      " - 22586s - loss: 0.0454 - binary_accuracy: 0.9834 - ACCR: 0.9832 - auc1: 0.9896 - TPR: 0.7697 - FPR: 0.0060 - val_loss: 0.0881 - val_binary_accuracy: 0.9771 - val_ACCR: 0.9767 - val_auc1: 0.9742 - val_TPR: 0.6915 - val_FPR: 0.0087\n",
      "\n",
      "Epoch 00013: val_ACCR improved from 0.97633 to 0.97667, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 14/2000\n",
      " - 22500s - loss: 0.0435 - binary_accuracy: 0.9841 - ACCR: 0.9839 - auc1: 0.9905 - TPR: 0.7806 - FPR: 0.0058 - val_loss: 0.0378 - val_binary_accuracy: 0.9772 - val_ACCR: 0.9768 - val_auc1: 0.9733 - val_TPR: 0.6929 - val_FPR: 0.0087\n",
      "\n",
      "Epoch 00014: val_ACCR improved from 0.97667 to 0.97676, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 15/2000\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    epochs = 2000\n",
    "    #epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0.1\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.00001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_ACCR', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_ACCR', patience=6, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf})\n",
    "    #model.compile(loss='binary_crossentropy',\n",
    "    #              optimizer=opt,\n",
    "    #              metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "#                    class_weight = 'auto',\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "                    max_queue_size = 3, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:55:55] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "inscopedata: 1534410it [00:02, 519593.77it/s]\n",
      "inscopedata: 1789651it [00:04, 421425.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total samples: 3317345\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 1024)         0           highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 1024)         0           highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     dropout_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 1024)         0           highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     dropout_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 1024)         0           highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 1024)         0           highway_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           dropout_6[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:526: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\metrics_impl.py:788: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/2000\n",
      " - 1619s - loss: 0.0297 - binary_accuracy: 0.9906 - ACCR: 0.9859 - auc2: 0.9987 - auc1: 0.9986 - TPR: 0.9652 - FPR: 0.0031 - val_loss: 0.2175 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9494 - val_auc2: 0.9974 - val_auc1: 0.9677 - val_TPR: 0.9128 - val_FPR: 0.0311\n",
      "\n",
      "Epoch 00001: val_ACCR improved from -inf to 0.94940, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/2000\n",
      " - 1494s - loss: 0.0298 - binary_accuracy: 0.9905 - ACCR: 0.9859 - auc2: 0.9970 - auc1: 0.9986 - TPR: 0.9654 - FPR: 0.0031 - val_loss: 0.3252 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9494 - val_auc2: 0.9968 - val_auc1: 0.9678 - val_TPR: 0.9135 - val_FPR: 0.0314\n",
      "\n",
      "Epoch 00002: val_ACCR improved from 0.94940 to 0.94943, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/2000\n",
      " - 1511s - loss: 0.0292 - binary_accuracy: 0.9907 - ACCR: 0.9861 - auc2: 0.9968 - auc1: 0.9986 - TPR: 0.9656 - FPR: 0.0030 - val_loss: 0.3829 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9494 - val_auc2: 0.9967 - val_auc1: 0.9670 - val_TPR: 0.9116 - val_FPR: 0.0304\n",
      "\n",
      "Epoch 00003: val_ACCR improved from 0.94943 to 0.94943, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/2000\n",
      " - 1534s - loss: 0.0292 - binary_accuracy: 0.9907 - ACCR: 0.9861 - auc2: 0.9966 - auc1: 0.9986 - TPR: 0.9657 - FPR: 0.0030 - val_loss: 0.2577 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9499 - val_auc2: 0.9966 - val_auc1: 0.9676 - val_TPR: 0.9152 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00004: val_ACCR improved from 0.94943 to 0.94987, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/2000\n",
      " - 1501s - loss: 0.0292 - binary_accuracy: 0.9908 - ACCR: 0.9863 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9663 - FPR: 0.0030 - val_loss: 0.2736 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9496 - val_auc2: 0.9965 - val_auc1: 0.9673 - val_TPR: 0.9141 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00005: val_ACCR did not improve from 0.94987\n",
      "Epoch 6/2000\n",
      " - 1507s - loss: 0.0288 - binary_accuracy: 0.9909 - ACCR: 0.9864 - auc2: 0.9965 - auc1: 0.9987 - TPR: 0.9666 - FPR: 0.0030 - val_loss: 0.2290 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9499 - val_auc2: 0.9965 - val_auc1: 0.9674 - val_TPR: 0.9155 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00006: val_ACCR improved from 0.94987 to 0.94988, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/2000\n",
      " - 1508s - loss: 0.0292 - binary_accuracy: 0.9908 - ACCR: 0.9863 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9662 - FPR: 0.0030 - val_loss: 0.2289 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9493 - val_auc2: 0.9965 - val_auc1: 0.9672 - val_TPR: 0.9141 - val_FPR: 0.0319\n",
      "\n",
      "Epoch 00007: val_ACCR did not improve from 0.94988\n",
      "Epoch 8/2000\n",
      " - 1497s - loss: 0.0287 - binary_accuracy: 0.9909 - ACCR: 0.9865 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9666 - FPR: 0.0029 - val_loss: 0.2584 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9501 - val_auc2: 0.9965 - val_auc1: 0.9675 - val_TPR: 0.9171 - val_FPR: 0.0323\n",
      "\n",
      "Epoch 00008: val_ACCR improved from 0.94988 to 0.95011, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/2000\n",
      " - 1503s - loss: 0.0289 - binary_accuracy: 0.9908 - ACCR: 0.9865 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9667 - FPR: 0.0030 - val_loss: 0.3492 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9498 - val_auc2: 0.9965 - val_auc1: 0.9678 - val_TPR: 0.9162 - val_FPR: 0.0323\n",
      "\n",
      "Epoch 00009: val_ACCR did not improve from 0.95011\n",
      "Epoch 10/2000\n",
      " - 1504s - loss: 0.0285 - binary_accuracy: 0.9910 - ACCR: 0.9866 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9669 - FPR: 0.0029 - val_loss: 0.3947 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9494 - val_auc2: 0.9964 - val_auc1: 0.9669 - val_TPR: 0.9127 - val_FPR: 0.0310\n",
      "\n",
      "Epoch 00010: val_ACCR did not improve from 0.95011\n",
      "Epoch 11/2000\n",
      " - 1505s - loss: 0.0288 - binary_accuracy: 0.9909 - ACCR: 0.9866 - auc2: 0.9965 - auc1: 0.9986 - TPR: 0.9672 - FPR: 0.0030 - val_loss: 0.2928 - val_binary_accuracy: 0.9520 - val_ACCR: 0.9496 - val_auc2: 0.9964 - val_auc1: 0.9670 - val_TPR: 0.9163 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00011: val_ACCR did not improve from 0.95011\n",
      "Epoch 12/2000\n",
      " - 1517s - loss: 0.0285 - binary_accuracy: 0.9910 - ACCR: 0.9867 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9671 - FPR: 0.0029 - val_loss: 0.2833 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9492 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9126 - val_FPR: 0.0313\n",
      "\n",
      "Epoch 00012: val_ACCR did not improve from 0.95011\n",
      "Epoch 13/2000\n",
      " - 1507s - loss: 0.0284 - binary_accuracy: 0.9911 - ACCR: 0.9868 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9675 - FPR: 0.0029 - val_loss: 0.3295 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9495 - val_auc2: 0.9964 - val_auc1: 0.9669 - val_TPR: 0.9147 - val_FPR: 0.0319\n",
      "\n",
      "Epoch 00013: val_ACCR did not improve from 0.95011\n",
      "Epoch 14/2000\n",
      " - 1522s - loss: 0.0281 - binary_accuracy: 0.9911 - ACCR: 0.9868 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9674 - FPR: 0.0029 - val_loss: 0.2168 - val_binary_accuracy: 0.9520 - val_ACCR: 0.9491 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9127 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00014: val_ACCR did not improve from 0.95011\n",
      "Epoch 15/2000\n",
      " - 1507s - loss: 0.0282 - binary_accuracy: 0.9912 - ACCR: 0.9870 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9679 - FPR: 0.0029 - val_loss: 0.3462 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9157 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00015: val_ACCR did not improve from 0.95011\n",
      "Epoch 16/2000\n",
      " - 1503s - loss: 0.0283 - binary_accuracy: 0.9912 - ACCR: 0.9870 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9682 - FPR: 0.0029 - val_loss: 0.3216 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9498 - val_auc2: 0.9964 - val_auc1: 0.9665 - val_TPR: 0.9138 - val_FPR: 0.0310\n",
      "\n",
      "Epoch 00016: val_ACCR did not improve from 0.95011\n",
      "Epoch 17/2000\n",
      " - 1509s - loss: 0.0281 - binary_accuracy: 0.9912 - ACCR: 0.9869 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9679 - FPR: 0.0029 - val_loss: 0.3370 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9496 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9146 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00017: val_ACCR did not improve from 0.95011\n",
      "Epoch 18/2000\n",
      " - 1506s - loss: 0.0276 - binary_accuracy: 0.9913 - ACCR: 0.9872 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9685 - FPR: 0.0028 - val_loss: 0.2889 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9497 - val_auc2: 0.9964 - val_auc1: 0.9664 - val_TPR: 0.9138 - val_FPR: 0.0312\n",
      "\n",
      "Epoch 00018: val_ACCR did not improve from 0.95011\n",
      "Epoch 19/2000\n",
      " - 1497s - loss: 0.0278 - binary_accuracy: 0.9913 - ACCR: 0.9872 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9685 - FPR: 0.0028 - val_loss: 0.2105 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9498 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9154 - val_FPR: 0.0319\n",
      "\n",
      "Epoch 00019: val_ACCR did not improve from 0.95011\n",
      "Epoch 20/2000\n",
      " - 1503s - loss: 0.0278 - binary_accuracy: 0.9913 - ACCR: 0.9872 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9687 - FPR: 0.0029 - val_loss: 0.2570 - val_binary_accuracy: 0.9520 - val_ACCR: 0.9495 - val_auc2: 0.9964 - val_auc1: 0.9665 - val_TPR: 0.9141 - val_FPR: 0.0316\n",
      "\n",
      "Epoch 00020: val_ACCR did not improve from 0.95011\n",
      "Epoch 21/2000\n",
      " - 1488s - loss: 0.0280 - binary_accuracy: 0.9913 - ACCR: 0.9873 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9688 - FPR: 0.0029 - val_loss: 0.4030 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9155 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00021: val_ACCR did not improve from 0.95011\n",
      "Epoch 22/2000\n",
      " - 1488s - loss: 0.0277 - binary_accuracy: 0.9914 - ACCR: 0.9874 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9691 - FPR: 0.0029 - val_loss: 0.3428 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9495 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9143 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00022: val_ACCR did not improve from 0.95011\n",
      "Epoch 23/2000\n",
      " - 1502s - loss: 0.0279 - binary_accuracy: 0.9914 - ACCR: 0.9874 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9690 - FPR: 0.0028 - val_loss: 0.2698 - val_binary_accuracy: 0.9516 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9668 - val_TPR: 0.9174 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00023: val_ACCR did not improve from 0.95011\n",
      "Epoch 24/2000\n",
      " - 1512s - loss: 0.0277 - binary_accuracy: 0.9913 - ACCR: 0.9874 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9691 - FPR: 0.0029 - val_loss: 0.2875 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9669 - val_TPR: 0.9174 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00024: val_ACCR did not improve from 0.95011\n",
      "Epoch 25/2000\n",
      " - 1504s - loss: 0.0273 - binary_accuracy: 0.9915 - ACCR: 0.9876 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9695 - FPR: 0.0028 - val_loss: 0.2754 - val_binary_accuracy: 0.9527 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9661 - val_TPR: 0.9167 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00025: val_ACCR improved from 0.95011 to 0.95037, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 26/2000\n",
      " - 1529s - loss: 0.0273 - binary_accuracy: 0.9915 - ACCR: 0.9875 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9695 - FPR: 0.0028 - val_loss: 0.4317 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9660 - val_TPR: 0.9172 - val_FPR: 0.0320\n",
      "\n",
      "Epoch 00026: val_ACCR did not improve from 0.95037\n",
      "Epoch 27/2000\n",
      " - 1512s - loss: 0.0272 - binary_accuracy: 0.9916 - ACCR: 0.9876 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9696 - FPR: 0.0028 - val_loss: 0.2681 - val_binary_accuracy: 0.9522 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9667 - val_TPR: 0.9179 - val_FPR: 0.0324\n",
      "\n",
      "Epoch 00027: val_ACCR did not improve from 0.95037\n",
      "Epoch 28/2000\n",
      " - 1501s - loss: 0.0274 - binary_accuracy: 0.9915 - ACCR: 0.9875 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9695 - FPR: 0.0029 - val_loss: 0.3566 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9664 - val_TPR: 0.9157 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00028: val_ACCR did not improve from 0.95037\n",
      "Epoch 29/2000\n",
      " - 1510s - loss: 0.0273 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9698 - FPR: 0.0028 - val_loss: 0.3408 - val_binary_accuracy: 0.9527 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9658 - val_TPR: 0.9157 - val_FPR: 0.0313\n",
      "\n",
      "Epoch 00029: val_ACCR did not improve from 0.95037\n",
      "Epoch 30/2000\n",
      " - 1511s - loss: 0.0272 - binary_accuracy: 0.9915 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9698 - FPR: 0.0028 - val_loss: 0.2747 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9666 - val_TPR: 0.9183 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00030: val_ACCR improved from 0.95037 to 0.95042, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 31/2000\n",
      " - 1495s - loss: 0.0273 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9699 - FPR: 0.0028 - val_loss: 0.2884 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9509 - val_auc2: 0.9964 - val_auc1: 0.9667 - val_TPR: 0.9199 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00031: val_ACCR improved from 0.95042 to 0.95091, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 32/2000\n",
      " - 1513s - loss: 0.0270 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9699 - FPR: 0.0028 - val_loss: 0.2848 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9662 - val_TPR: 0.9169 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00032: val_ACCR did not improve from 0.95091\n",
      "Epoch 33/2000\n",
      " - 1500s - loss: 0.0269 - binary_accuracy: 0.9917 - ACCR: 0.9879 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9705 - FPR: 0.0028 - val_loss: 0.3061 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9499 - val_auc2: 0.9964 - val_auc1: 0.9661 - val_TPR: 0.9151 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00033: val_ACCR did not improve from 0.95091\n",
      "Epoch 34/2000\n",
      " - 1497s - loss: 0.0269 - binary_accuracy: 0.9917 - ACCR: 0.9878 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9703 - FPR: 0.0028 - val_loss: 0.2738 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9509 - val_auc2: 0.9964 - val_auc1: 0.9664 - val_TPR: 0.9203 - val_FPR: 0.0329\n",
      "\n",
      "Epoch 00034: val_ACCR did not improve from 0.95091\n",
      "Epoch 35/2000\n",
      " - 1507s - loss: 0.0273 - binary_accuracy: 0.9916 - ACCR: 0.9877 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9700 - FPR: 0.0028 - val_loss: 0.2818 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9658 - val_TPR: 0.9155 - val_FPR: 0.0315\n",
      "\n",
      "Epoch 00035: val_ACCR did not improve from 0.95091\n",
      "Epoch 36/2000\n",
      " - 1517s - loss: 0.0270 - binary_accuracy: 0.9917 - ACCR: 0.9879 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9704 - FPR: 0.0028 - val_loss: 0.2688 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9503 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9177 - val_FPR: 0.0323\n",
      "\n",
      "Epoch 00036: val_ACCR did not improve from 0.95091\n",
      "Epoch 37/2000\n",
      " - 1499s - loss: 0.0268 - binary_accuracy: 0.9918 - ACCR: 0.9881 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9708 - FPR: 0.0027 - val_loss: 0.2949 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9502 - val_auc2: 0.9964 - val_auc1: 0.9660 - val_TPR: 0.9169 - val_FPR: 0.0321\n",
      "\n",
      "Epoch 00037: val_ACCR did not improve from 0.95091\n",
      "Epoch 38/2000\n",
      " - 1513s - loss: 0.0271 - binary_accuracy: 0.9917 - ACCR: 0.9880 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9707 - FPR: 0.0028 - val_loss: 0.2737 - val_binary_accuracy: 0.9526 - val_ACCR: 0.9506 - val_auc2: 0.9964 - val_auc1: 0.9662 - val_TPR: 0.9187 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00038: val_ACCR did not improve from 0.95091\n",
      "Epoch 39/2000\n",
      " - 1491s - loss: 0.0270 - binary_accuracy: 0.9918 - ACCR: 0.9881 - auc2: 0.9964 - auc1: 0.9986 - TPR: 0.9710 - FPR: 0.0028 - val_loss: 0.3109 - val_binary_accuracy: 0.9530 - val_ACCR: 0.9505 - val_auc2: 0.9964 - val_auc1: 0.9659 - val_TPR: 0.9159 - val_FPR: 0.0311\n",
      "\n",
      "Epoch 00039: val_ACCR did not improve from 0.95091\n",
      "Epoch 40/2000\n",
      " - 1514s - loss: 0.0268 - binary_accuracy: 0.9918 - ACCR: 0.9880 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9708 - FPR: 0.0028 - val_loss: 0.2341 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9502 - val_auc2: 0.9964 - val_auc1: 0.9661 - val_TPR: 0.9166 - val_FPR: 0.0318\n",
      "\n",
      "Epoch 00040: val_ACCR did not improve from 0.95091\n",
      "Epoch 41/2000\n",
      " - 1504s - loss: 0.0266 - binary_accuracy: 0.9918 - ACCR: 0.9882 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9710 - FPR: 0.0027 - val_loss: 0.2302 - val_binary_accuracy: 0.9524 - val_ACCR: 0.9504 - val_auc2: 0.9964 - val_auc1: 0.9658 - val_TPR: 0.9176 - val_FPR: 0.0322\n",
      "\n",
      "Epoch 00041: val_ACCR did not improve from 0.95091\n",
      "Epoch 42/2000\n",
      " - 1489s - loss: 0.0267 - binary_accuracy: 0.9918 - ACCR: 0.9881 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9711 - FPR: 0.0028 - val_loss: 0.3438 - val_binary_accuracy: 0.9526 - val_ACCR: 0.9506 - val_auc2: 0.9964 - val_auc1: 0.9654 - val_TPR: 0.9174 - val_FPR: 0.0317\n",
      "\n",
      "Epoch 00042: val_ACCR did not improve from 0.95091\n",
      "Epoch 43/2000\n",
      " - 1500s - loss: 0.0265 - binary_accuracy: 0.9918 - ACCR: 0.9882 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9711 - FPR: 0.0028 - val_loss: 0.2689 - val_binary_accuracy: 0.9525 - val_ACCR: 0.9502 - val_auc2: 0.9964 - val_auc1: 0.9657 - val_TPR: 0.9154 - val_FPR: 0.0313\n",
      "\n",
      "Epoch 00043: val_ACCR did not improve from 0.95091\n",
      "Epoch 44/2000\n",
      " - 1545s - loss: 0.0264 - binary_accuracy: 0.9919 - ACCR: 0.9883 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9714 - FPR: 0.0027 - val_loss: 0.3232 - val_binary_accuracy: 0.9528 - val_ACCR: 0.9506 - val_auc2: 0.9964 - val_auc1: 0.9656 - val_TPR: 0.9190 - val_FPR: 0.0325\n",
      "\n",
      "Epoch 00044: val_ACCR did not improve from 0.95091\n",
      "Epoch 45/2000\n",
      " - 1499s - loss: 0.0263 - binary_accuracy: 0.9920 - ACCR: 0.9884 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9716 - FPR: 0.0027 - val_loss: 0.3446 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9501 - val_auc2: 0.9964 - val_auc1: 0.9654 - val_TPR: 0.9170 - val_FPR: 0.0322\n",
      "\n",
      "Epoch 00045: val_ACCR did not improve from 0.95091\n",
      "Epoch 46/2000\n",
      " - 1507s - loss: 0.0263 - binary_accuracy: 0.9919 - ACCR: 0.9884 - auc2: 0.9964 - auc1: 0.9987 - TPR: 0.9717 - FPR: 0.0028 - val_loss: 0.1883 - val_binary_accuracy: 0.9526 - val_ACCR: 0.9512 - val_auc2: 0.9964 - val_auc1: 0.9663 - val_TPR: 0.9208 - val_FPR: 0.0327\n",
      "\n",
      "Epoch 00046: val_ACCR improved from 0.95091 to 0.95119, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 47/2000\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [10:48:32] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         16778240    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 44,052,480\n",
      "Trainable params: 44,052,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 32083s - loss: 0.3805 - binary_accuracy: 0.9101 - ACCR: 0.9668 - auc1: 0.9661 - TPR: 0.9171 - FPR: 0.0901 - binary_crossentropy: 0.2151 - val_loss: 0.1685 - val_binary_accuracy: 0.9287 - val_ACCR: 0.9721 - val_auc1: 0.9789 - val_TPR: 0.9414 - val_FPR: 0.0718 - val_binary_crossentropy: 0.1784\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.17841, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 34664s - loss: 0.2499 - binary_accuracy: 0.9433 - ACCR: 0.9760 - auc1: 0.9850 - TPR: 0.9517 - FPR: 0.0570 - binary_crossentropy: 0.1454 - val_loss: 0.1280 - val_binary_accuracy: 0.9433 - val_ACCR: 0.9756 - val_auc1: 0.9830 - val_TPR: 0.9387 - val_FPR: 0.0565 - val_binary_crossentropy: 0.1467\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.17841 to 0.14672, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 34682s - loss: 0.1927 - binary_accuracy: 0.9567 - ACCR: 0.9804 - auc1: 0.9904 - TPR: 0.9658 - FPR: 0.0436 - binary_crossentropy: 0.1154 - val_loss: 0.1234 - val_binary_accuracy: 0.9521 - val_ACCR: 0.9772 - val_auc1: 0.9837 - val_TPR: 0.9302 - val_FPR: 0.0470 - val_binary_crossentropy: 0.1290\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.14672 to 0.12897, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 34584s - loss: 0.1554 - binary_accuracy: 0.9654 - ACCR: 0.9834 - auc1: 0.9931 - TPR: 0.9743 - FPR: 0.0350 - binary_crossentropy: 0.0958 - val_loss: 0.1548 - val_binary_accuracy: 0.9603 - val_ACCR: 0.9786 - val_auc1: 0.9825 - val_TPR: 0.9144 - val_FPR: 0.0379 - val_binary_crossentropy: 0.1119\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.12897 to 0.11192, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 34658s - loss: 0.1288 - binary_accuracy: 0.9716 - ACCR: 0.9857 - auc1: 0.9948 - TPR: 0.9802 - FPR: 0.0287 - binary_crossentropy: 0.0813 - val_loss: 0.1025 - val_binary_accuracy: 0.9634 - val_ACCR: 0.9787 - val_auc1: 0.9804 - val_TPR: 0.9061 - val_FPR: 0.0344 - val_binary_crossentropy: 0.1103\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.11192 to 0.11025, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/100\n"
     ]
    }
   ],
   "source": [
    "#for all rules all data, optimize recfp_dim\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0.1\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    #recfp_dim=2048\n",
    "    recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_trainall2.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_testall2.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_trainall2.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_testall2.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_trainall2.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_testall2.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    \n",
    "    data_spilt= round(len(x_train)*(1-spilt))\n",
    "    x_test = x_train[data_spilt:]\n",
    "    x_train = x_train[:data_spilt]\n",
    "    y_test = y_train[data_spilt:]\n",
    "    y_train = y_train[:data_spilt]\n",
    "    z_test = z_train[data_spilt:]\n",
    "    z_train =z_train[:data_spilt]\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.00005)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_binary_crossentropy', save_best_only=True, verbose=1, mode='min')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_binary_crossentropy', patience=6, verbose=1, mode='min')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    class_weight = {1:20., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "                    max_queue_size = 3, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [17:25:14] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 22655s - loss: 0.4774 - binary_accuracy: 0.8830 - ACCR: 0.9576 - auc1: 0.9577 - TPR: 0.9222 - FPR: 0.1189 - binary_crossentropy: 0.2728 - val_loss: 0.2463 - val_binary_accuracy: 0.9091 - val_ACCR: 0.9643 - val_auc1: 0.9734 - val_TPR: 0.9423 - val_FPR: 0.0926 - val_binary_crossentropy: 0.2230\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.22297, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 22997s - loss: 0.3242 - binary_accuracy: 0.9243 - ACCR: 0.9682 - auc1: 0.9801 - TPR: 0.9531 - FPR: 0.0772 - binary_crossentropy: 0.1911 - val_loss: 0.1637 - val_binary_accuracy: 0.9286 - val_ACCR: 0.9694 - val_auc1: 0.9790 - val_TPR: 0.9408 - val_FPR: 0.0720 - val_binary_crossentropy: 0.1810\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.22297 to 0.18096, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 22767s - loss: 0.2598 - binary_accuracy: 0.9399 - ACCR: 0.9733 - auc1: 0.9864 - TPR: 0.9652 - FPR: 0.0614 - binary_crossentropy: 0.1570 - val_loss: 0.1511 - val_binary_accuracy: 0.9394 - val_ACCR: 0.9716 - val_auc1: 0.9810 - val_TPR: 0.9346 - val_FPR: 0.0604 - val_binary_crossentropy: 0.1581\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.18096 to 0.15814, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 22975s - loss: 0.2167 - binary_accuracy: 0.9502 - ACCR: 0.9767 - auc1: 0.9898 - TPR: 0.9730 - FPR: 0.0510 - binary_crossentropy: 0.1341 - val_loss: 0.1211 - val_binary_accuracy: 0.9450 - val_ACCR: 0.9725 - val_auc1: 0.9814 - val_TPR: 0.9303 - val_FPR: 0.0543 - val_binary_crossentropy: 0.1496\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.15814 to 0.14958, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 23577s - loss: 0.1855 - binary_accuracy: 0.9576 - ACCR: 0.9794 - auc1: 0.9920 - TPR: 0.9787 - FPR: 0.0434 - binary_crossentropy: 0.1172 - val_loss: 0.1116 - val_binary_accuracy: 0.9523 - val_ACCR: 0.9740 - val_auc1: 0.9812 - val_TPR: 0.9183 - val_FPR: 0.0460 - val_binary_crossentropy: 0.1333\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy improved from 0.14958 to 0.13335, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/100\n",
      " - 23205s - loss: 0.1616 - binary_accuracy: 0.9634 - ACCR: 0.9816 - auc1: 0.9935 - TPR: 0.9825 - FPR: 0.0375 - binary_crossentropy: 0.1039 - val_loss: 0.1724 - val_binary_accuracy: 0.9551 - val_ACCR: 0.9743 - val_auc1: 0.9806 - val_TPR: 0.9147 - val_FPR: 0.0429 - val_binary_crossentropy: 0.1309\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy improved from 0.13335 to 0.13088, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/100\n",
      " - 23509s - loss: 0.1431 - binary_accuracy: 0.9679 - ACCR: 0.9834 - auc1: 0.9945 - TPR: 0.9853 - FPR: 0.0330 - binary_crossentropy: 0.0933 - val_loss: 0.1400 - val_binary_accuracy: 0.9596 - val_ACCR: 0.9751 - val_auc1: 0.9793 - val_TPR: 0.9045 - val_FPR: 0.0376 - val_binary_crossentropy: 0.1226\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy improved from 0.13088 to 0.12264, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/100\n",
      " - 23601s - loss: 0.1285 - binary_accuracy: 0.9715 - ACCR: 0.9850 - auc1: 0.9953 - TPR: 0.9872 - FPR: 0.0293 - binary_crossentropy: 0.0846 - val_loss: 0.1510 - val_binary_accuracy: 0.9613 - val_ACCR: 0.9752 - val_auc1: 0.9777 - val_TPR: 0.8972 - val_FPR: 0.0354 - val_binary_crossentropy: 0.1207\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy improved from 0.12264 to 0.12068, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/100\n",
      " - 23051s - loss: 0.1166 - binary_accuracy: 0.9744 - ACCR: 0.9863 - auc1: 0.9959 - TPR: 0.9886 - FPR: 0.0263 - binary_crossentropy: 0.0773 - val_loss: 0.1316 - val_binary_accuracy: 0.9632 - val_ACCR: 0.9756 - val_auc1: 0.9756 - val_TPR: 0.8913 - val_FPR: 0.0332 - val_binary_crossentropy: 0.1202\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy improved from 0.12068 to 0.12020, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 10/100\n",
      " - 22535s - loss: 0.1068 - binary_accuracy: 0.9768 - ACCR: 0.9875 - auc1: 0.9964 - TPR: 0.9897 - FPR: 0.0238 - binary_crossentropy: 0.0713 - val_loss: 0.1033 - val_binary_accuracy: 0.9631 - val_ACCR: 0.9754 - val_auc1: 0.9742 - val_TPR: 0.8911 - val_FPR: 0.0334 - val_binary_crossentropy: 0.1238\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.12020\n",
      "Epoch 11/100\n",
      " - 22673s - loss: 0.0986 - binary_accuracy: 0.9788 - ACCR: 0.9884 - auc1: 0.9968 - TPR: 0.9906 - FPR: 0.0218 - binary_crossentropy: 0.0660 - val_loss: 0.1777 - val_binary_accuracy: 0.9645 - val_ACCR: 0.9754 - val_auc1: 0.9719 - val_TPR: 0.8865 - val_FPR: 0.0316 - val_binary_crossentropy: 0.1243\n",
      "\n",
      "Epoch 00011: val_binary_crossentropy did not improve from 0.12020\n",
      "Epoch 12/100\n"
     ]
    }
   ],
   "source": [
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0.1\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "\n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.00005)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_binary_crossentropy', save_best_only=True, verbose=1, mode='min')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_binary_crossentropy', patience=6, verbose=1, mode='min')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    class_weight = {1:20., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "                    max_queue_size = 3, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [09:54:34] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 22287s - loss: 0.1650 - binary_accuracy: 0.9624 - ACCR: 0.9638 - auc1: 0.9605 - TPR: 0.6571 - FPR: 0.0238 - binary_crossentropy: 0.1023 - val_loss: 0.3996 - val_binary_accuracy: 0.8294 - val_ACCR: 0.7262 - val_auc1: 0.8973 - val_TPR: 0.7596 - val_FPR: 0.1285 - val_binary_crossentropy: 0.4321\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.43207, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 22877s - loss: 0.1128 - binary_accuracy: 0.9735 - ACCR: 0.9720 - auc1: 0.9827 - TPR: 0.8039 - FPR: 0.0189 - binary_crossentropy: 0.0719 - val_loss: 0.3690 - val_binary_accuracy: 0.8516 - val_ACCR: 0.7689 - val_auc1: 0.9155 - val_TPR: 0.8060 - val_FPR: 0.1208 - val_binary_crossentropy: 0.3938\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.43207 to 0.39377, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 22569s - loss: 0.0910 - binary_accuracy: 0.9785 - ACCR: 0.9766 - auc1: 0.9887 - TPR: 0.8519 - FPR: 0.0158 - binary_crossentropy: 0.0588 - val_loss: 0.3807 - val_binary_accuracy: 0.8608 - val_ACCR: 0.7931 - val_auc1: 0.9236 - val_TPR: 0.8187 - val_FPR: 0.1137 - val_binary_crossentropy: 0.3826\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.39377 to 0.38262, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 22901s - loss: 0.0763 - binary_accuracy: 0.9818 - ACCR: 0.9798 - auc1: 0.9920 - TPR: 0.8814 - FPR: 0.0136 - binary_crossentropy: 0.0500 - val_loss: 0.3676 - val_binary_accuracy: 0.8661 - val_ACCR: 0.8045 - val_auc1: 0.9273 - val_TPR: 0.8219 - val_FPR: 0.1072 - val_binary_crossentropy: 0.3817\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy improved from 0.38262 to 0.38174, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 22629s - loss: 0.0651 - binary_accuracy: 0.9844 - ACCR: 0.9823 - auc1: 0.9942 - TPR: 0.9029 - FPR: 0.0119 - binary_crossentropy: 0.0433 - val_loss: 0.3996 - val_binary_accuracy: 0.8664 - val_ACCR: 0.8133 - val_auc1: 0.9266 - val_TPR: 0.8195 - val_FPR: 0.1052 - val_binary_crossentropy: 0.3996\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy did not improve from 0.38174\n",
      "Epoch 6/100\n",
      " - 22638s - loss: 0.0564 - binary_accuracy: 0.9864 - ACCR: 0.9844 - auc1: 0.9956 - TPR: 0.9190 - FPR: 0.0105 - binary_crossentropy: 0.0379 - val_loss: 0.3932 - val_binary_accuracy: 0.8688 - val_ACCR: 0.8210 - val_auc1: 0.9287 - val_TPR: 0.8098 - val_FPR: 0.0956 - val_binary_crossentropy: 0.4049\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.38174\n",
      "Epoch 7/100\n",
      " - 22616s - loss: 0.0493 - binary_accuracy: 0.9881 - ACCR: 0.9862 - auc1: 0.9966 - TPR: 0.9314 - FPR: 0.0093 - binary_crossentropy: 0.0334 - val_loss: 0.3680 - val_binary_accuracy: 0.8696 - val_ACCR: 0.8293 - val_auc1: 0.9273 - val_TPR: 0.8127 - val_FPR: 0.0960 - val_binary_crossentropy: 0.4270\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.38174\n",
      "Epoch 8/100\n",
      " - 22900s - loss: 0.0435 - binary_accuracy: 0.9895 - ACCR: 0.9878 - auc1: 0.9974 - TPR: 0.9414 - FPR: 0.0083 - binary_crossentropy: 0.0297 - val_loss: 0.4947 - val_binary_accuracy: 0.8697 - val_ACCR: 0.8300 - val_auc1: 0.9251 - val_TPR: 0.8060 - val_FPR: 0.0917 - val_binary_crossentropy: 0.4500\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.38174\n",
      "Epoch 9/100\n",
      " - 22720s - loss: 0.0387 - binary_accuracy: 0.9907 - ACCR: 0.9891 - auc1: 0.9979 - TPR: 0.9493 - FPR: 0.0074 - binary_crossentropy: 0.0266 - val_loss: 0.4543 - val_binary_accuracy: 0.8687 - val_ACCR: 0.8337 - val_auc1: 0.9220 - val_TPR: 0.8031 - val_FPR: 0.0917 - val_binary_crossentropy: 0.4772\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.38174\n",
      "Epoch 10/100\n",
      " - 22483s - loss: 0.0347 - binary_accuracy: 0.9917 - ACCR: 0.9902 - auc1: 0.9983 - TPR: 0.9554 - FPR: 0.0067 - binary_crossentropy: 0.0240 - val_loss: 0.4194 - val_binary_accuracy: 0.8682 - val_ACCR: 0.8380 - val_auc1: 0.9188 - val_TPR: 0.8016 - val_FPR: 0.0914 - val_binary_crossentropy: 0.5047\n",
      "\n",
      "Epoch 00010: val_binary_crossentropy did not improve from 0.38174\n",
      "Epoch 00010: early stopping\n"
     ]
    }
   ],
   "source": [
    "#for test negative enrichment,is it good to get better results?\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    #recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train2.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test2.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train2.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test2.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train2.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test2.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.00005)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_binary_crossentropy', save_best_only=True, verbose=1, mode='min')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_binary_crossentropy', patience=6, verbose=1, mode='min')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    class_weight = {1:3., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 3, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [09:16:31] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         16778240    input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 44,052,480\n",
      "Trainable params: 44,052,480\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 24587s - loss: 0.0825 - binary_accuracy: 0.9693 - ACCR: 0.9613 - auc1: 0.9604 - TPR: 0.4547 - FPR: 0.0075 - binary_crossentropy: 0.0825 - val_loss: 0.3805 - val_binary_accuracy: 0.8087 - val_ACCR: 0.6842 - val_auc1: 0.9090 - val_TPR: 0.5955 - val_FPR: 0.0624 - val_binary_crossentropy: 0.4561\n",
      "\n",
      "Epoch 00001: val_binary_crossentropy improved from inf to 0.45609, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 27907s - loss: 0.0560 - binary_accuracy: 0.9793 - ACCR: 0.9684 - auc1: 0.9828 - TPR: 0.6716 - FPR: 0.0068 - binary_crossentropy: 0.0560 - val_loss: 0.3883 - val_binary_accuracy: 0.8379 - val_ACCR: 0.7280 - val_auc1: 0.9238 - val_TPR: 0.6695 - val_FPR: 0.0602 - val_binary_crossentropy: 0.4175\n",
      "\n",
      "Epoch 00002: val_binary_crossentropy improved from 0.45609 to 0.41754, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 27940s - loss: 0.0442 - binary_accuracy: 0.9838 - ACCR: 0.9737 - auc1: 0.9889 - TPR: 0.7554 - FPR: 0.0058 - binary_crossentropy: 0.0442 - val_loss: 0.3345 - val_binary_accuracy: 0.8513 - val_ACCR: 0.7556 - val_auc1: 0.9277 - val_TPR: 0.7114 - val_FPR: 0.0640 - val_binary_crossentropy: 0.4027\n",
      "\n",
      "Epoch 00003: val_binary_crossentropy improved from 0.41754 to 0.40274, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 27837s - loss: 0.0361 - binary_accuracy: 0.9869 - ACCR: 0.9778 - auc1: 0.9923 - TPR: 0.8085 - FPR: 0.0050 - binary_crossentropy: 0.0361 - val_loss: 0.3860 - val_binary_accuracy: 0.8562 - val_ACCR: 0.7745 - val_auc1: 0.9284 - val_TPR: 0.7238 - val_FPR: 0.0638 - val_binary_crossentropy: 0.4155\n",
      "\n",
      "Epoch 00004: val_binary_crossentropy did not improve from 0.40274\n",
      "Epoch 5/100\n",
      " - 28097s - loss: 0.0299 - binary_accuracy: 0.9893 - ACCR: 0.9812 - auc1: 0.9945 - TPR: 0.8470 - FPR: 0.0043 - binary_crossentropy: 0.0299 - val_loss: 0.4687 - val_binary_accuracy: 0.8591 - val_ACCR: 0.7904 - val_auc1: 0.9272 - val_TPR: 0.7334 - val_FPR: 0.0648 - val_binary_crossentropy: 0.4348\n",
      "\n",
      "Epoch 00005: val_binary_crossentropy did not improve from 0.40274\n",
      "Epoch 6/100\n",
      " - 27631s - loss: 0.0251 - binary_accuracy: 0.9911 - ACCR: 0.9840 - auc1: 0.9960 - TPR: 0.8761 - FPR: 0.0037 - binary_crossentropy: 0.0251 - val_loss: 0.4112 - val_binary_accuracy: 0.8594 - val_ACCR: 0.7996 - val_auc1: 0.9245 - val_TPR: 0.7286 - val_FPR: 0.0615 - val_binary_crossentropy: 0.4694\n",
      "\n",
      "Epoch 00006: val_binary_crossentropy did not improve from 0.40274\n",
      "Epoch 7/100\n",
      " - 27814s - loss: 0.0213 - binary_accuracy: 0.9925 - ACCR: 0.9864 - auc1: 0.9969 - TPR: 0.8979 - FPR: 0.0032 - binary_crossentropy: 0.0213 - val_loss: 0.5300 - val_binary_accuracy: 0.8598 - val_ACCR: 0.8082 - val_auc1: 0.9204 - val_TPR: 0.7379 - val_FPR: 0.0666 - val_binary_crossentropy: 0.4935\n",
      "\n",
      "Epoch 00007: val_binary_crossentropy did not improve from 0.40274\n",
      "Epoch 8/100\n",
      " - 27893s - loss: 0.0184 - binary_accuracy: 0.9936 - ACCR: 0.9882 - auc1: 0.9976 - TPR: 0.9148 - FPR: 0.0028 - binary_crossentropy: 0.0184 - val_loss: 0.6976 - val_binary_accuracy: 0.8595 - val_ACCR: 0.8140 - val_auc1: 0.9155 - val_TPR: 0.7381 - val_FPR: 0.0669 - val_binary_crossentropy: 0.5326\n",
      "\n",
      "Epoch 00008: val_binary_crossentropy did not improve from 0.40274\n",
      "Epoch 9/100\n",
      " - 27572s - loss: 0.0162 - binary_accuracy: 0.9945 - ACCR: 0.9898 - auc1: 0.9979 - TPR: 0.9276 - FPR: 0.0025 - binary_crossentropy: 0.0162 - val_loss: 0.5156 - val_binary_accuracy: 0.8615 - val_ACCR: 0.8210 - val_auc1: 0.9124 - val_TPR: 0.7407 - val_FPR: 0.0653 - val_binary_crossentropy: 0.5536\n",
      "\n",
      "Epoch 00009: val_binary_crossentropy did not improve from 0.40274\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "#for test negative enrichment,is it good to get better results?\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    #recfp_dim=2048\n",
    "    recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train2.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test2.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train2.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test2.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train2.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test2.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.00005)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_binary_crossentropy', save_best_only=True, verbose=1, mode='min')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_binary_crossentropy', patience=6, verbose=1, mode='min')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "                    class_weight = {1:1., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=3, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 3, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [12:27:24] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 942s - loss: 0.2597 - binary_accuracy: 0.3923 - ACCR: 0.7958 - auc1: 0.9566 - TPR: 0.8999 - FPR: 0.1239 - binary_crossentropy: 0.2597 - val_loss: 0.5818 - val_binary_accuracy: 0.8752 - val_ACCR: 0.9173 - val_auc1: nan - val_TPR: nan - val_FPR: nan - val_binary_crossentropy: 0.3213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:820: RuntimeWarning: invalid value encountered in greater\n",
      "  if self.monitor_op(current - self.min_delta, self.best):\n",
      "C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\callbacks\\callbacks.py:709: RuntimeWarning: invalid value encountered in greater\n",
      "  if self.monitor_op(current, self.best):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: val_auc1 did not improve from -inf\n",
      "Epoch 2/100\n",
      " - 909s - loss: 0.1974 - binary_accuracy: 0.4039 - ACCR: 0.8593 - auc1: 0.9759 - TPR: 0.9223 - FPR: 0.0900 - binary_crossentropy: 0.1974 - val_loss: 0.3658 - val_binary_accuracy: 0.8849 - val_ACCR: 0.9246 - val_auc1: 0.9720 - val_TPR: 0.9757 - val_FPR: 0.1701 - val_binary_crossentropy: 0.3126\n",
      "\n",
      "Epoch 00002: val_auc1 improved from -inf to 0.97200, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 913s - loss: 0.1851 - binary_accuracy: 0.4074 - ACCR: 0.8703 - auc1: 0.9787 - TPR: 0.9262 - FPR: 0.0826 - binary_crossentropy: 0.1851 - val_loss: 0.3274 - val_binary_accuracy: 0.8908 - val_ACCR: 0.9296 - val_auc1: 0.9740 - val_TPR: 0.9762 - val_FPR: 0.1608 - val_binary_crossentropy: 0.3028\n",
      "\n",
      "Epoch 00003: val_auc1 improved from 0.97200 to 0.97403, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 909s - loss: 0.1780 - binary_accuracy: 0.4096 - ACCR: 0.8764 - auc1: 0.9803 - TPR: 0.9283 - FPR: 0.0783 - binary_crossentropy: 0.1780 - val_loss: 0.2828 - val_binary_accuracy: 0.8951 - val_ACCR: 0.9306 - val_auc1: 0.9740 - val_TPR: 0.9767 - val_FPR: 0.1542 - val_binary_crossentropy: 0.3023\n",
      "\n",
      "Epoch 00004: val_auc1 improved from 0.97403 to 0.97403, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 906s - loss: 0.1731 - binary_accuracy: 0.4113 - ACCR: 0.8804 - auc1: 0.9813 - TPR: 0.9298 - FPR: 0.0755 - binary_crossentropy: 0.1731 - val_loss: 0.3582 - val_binary_accuracy: 0.9009 - val_ACCR: 0.9323 - val_auc1: 0.9748 - val_TPR: 0.9754 - val_FPR: 0.1441 - val_binary_crossentropy: 0.2891\n",
      "\n",
      "Epoch 00005: val_auc1 improved from 0.97403 to 0.97480, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/100\n",
      " - 904s - loss: 0.1693 - binary_accuracy: 0.4127 - ACCR: 0.8836 - auc1: 0.9821 - TPR: 0.9309 - FPR: 0.0731 - binary_crossentropy: 0.1693 - val_loss: 0.2767 - val_binary_accuracy: 0.8973 - val_ACCR: 0.9328 - val_auc1: 0.9742 - val_TPR: 0.9775 - val_FPR: 0.1512 - val_binary_crossentropy: 0.3074\n",
      "\n",
      "Epoch 00006: val_auc1 did not improve from 0.97480\n",
      "Epoch 7/100\n",
      " - 917s - loss: 0.1664 - binary_accuracy: 0.4136 - ACCR: 0.8861 - auc1: 0.9827 - TPR: 0.9318 - FPR: 0.0717 - binary_crossentropy: 0.1664 - val_loss: 0.2629 - val_binary_accuracy: 0.8980 - val_ACCR: 0.9325 - val_auc1: 0.9741 - val_TPR: 0.9777 - val_FPR: 0.1501 - val_binary_crossentropy: 0.3123\n",
      "\n",
      "Epoch 00007: val_auc1 did not improve from 0.97480\n",
      "Epoch 8/100\n",
      " - 910s - loss: 0.1641 - binary_accuracy: 0.4144 - ACCR: 0.8881 - auc1: 0.9831 - TPR: 0.9325 - FPR: 0.0704 - binary_crossentropy: 0.1641 - val_loss: 0.3706 - val_binary_accuracy: 0.9024 - val_ACCR: 0.9337 - val_auc1: 0.9742 - val_TPR: 0.9763 - val_FPR: 0.1423 - val_binary_crossentropy: 0.3026\n",
      "\n",
      "Epoch 00008: val_auc1 did not improve from 0.97480\n",
      "Epoch 9/100\n",
      " - 914s - loss: 0.1622 - binary_accuracy: 0.4149 - ACCR: 0.8897 - auc1: 0.9835 - TPR: 0.9330 - FPR: 0.0695 - binary_crossentropy: 0.1622 - val_loss: 0.2620 - val_binary_accuracy: 0.9019 - val_ACCR: 0.9328 - val_auc1: 0.9732 - val_TPR: 0.9770 - val_FPR: 0.1436 - val_binary_crossentropy: 0.3126\n",
      "\n",
      "Epoch 00009: val_auc1 did not improve from 0.97480\n",
      "Epoch 10/100\n",
      " - 903s - loss: 0.1606 - binary_accuracy: 0.4154 - ACCR: 0.8912 - auc1: 0.9838 - TPR: 0.9333 - FPR: 0.0686 - binary_crossentropy: 0.1606 - val_loss: 0.2801 - val_binary_accuracy: 0.9040 - val_ACCR: 0.9343 - val_auc1: 0.9738 - val_TPR: 0.9769 - val_FPR: 0.1400 - val_binary_crossentropy: 0.3070\n",
      "\n",
      "Epoch 00010: val_auc1 did not improve from 0.97480\n",
      "Epoch 11/100\n",
      " - 914s - loss: 0.1593 - binary_accuracy: 0.4158 - ACCR: 0.8923 - auc1: 0.9840 - TPR: 0.9336 - FPR: 0.0681 - binary_crossentropy: 0.1593 - val_loss: 0.3702 - val_binary_accuracy: 0.9008 - val_ACCR: 0.9334 - val_auc1: 0.9728 - val_TPR: 0.9780 - val_FPR: 0.1461 - val_binary_crossentropy: 0.3241\n",
      "\n",
      "Epoch 00011: val_auc1 did not improve from 0.97480\n",
      "Epoch 12/100\n",
      " - 908s - loss: 0.1582 - binary_accuracy: 0.4160 - ACCR: 0.8932 - auc1: 0.9843 - TPR: 0.9339 - FPR: 0.0676 - binary_crossentropy: 0.1582 - val_loss: 0.3082 - val_binary_accuracy: 0.9022 - val_ACCR: 0.9332 - val_auc1: 0.9721 - val_TPR: 0.9777 - val_FPR: 0.1435 - val_binary_crossentropy: 0.3282\n",
      "\n",
      "Epoch 00012: val_auc1 did not improve from 0.97480\n",
      "Epoch 13/100\n",
      " - 907s - loss: 0.1572 - binary_accuracy: 0.4163 - ACCR: 0.8938 - auc1: 0.9844 - TPR: 0.9341 - FPR: 0.0672 - binary_crossentropy: 0.1572 - val_loss: 0.3229 - val_binary_accuracy: 0.9013 - val_ACCR: 0.9335 - val_auc1: 0.9724 - val_TPR: 0.9781 - val_FPR: 0.1451 - val_binary_crossentropy: 0.3260\n",
      "\n",
      "Epoch 00013: val_auc1 did not improve from 0.97480\n",
      "Epoch 14/100\n",
      " - 909s - loss: 0.1564 - binary_accuracy: 0.4164 - ACCR: 0.8946 - auc1: 0.9846 - TPR: 0.9342 - FPR: 0.0669 - binary_crossentropy: 0.1564 - val_loss: 0.2729 - val_binary_accuracy: 0.9019 - val_ACCR: 0.9334 - val_auc1: 0.9717 - val_TPR: 0.9780 - val_FPR: 0.1440 - val_binary_crossentropy: 0.3340\n",
      "\n",
      "Epoch 00014: val_auc1 did not improve from 0.97480\n",
      "Epoch 15/100\n"
     ]
    }
   ],
   "source": [
    "#for test negative enrichment,is it good to get better results?\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    #recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train1-n.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test1-n.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train1-n.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test1-n.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train1-n.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test1-n.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)   \n",
    "    \n",
    "    print('shuffle is over...')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_auc1', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_auc1', patience=14, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "#                    class_weight = {1:2., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=6, \n",
    "                    use_multiprocessing=1, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 8, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [16:18:59] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 24406s - loss: 0.2712 - binary_accuracy: 0.0999 - ACCR: 0.7909 - auc1: 0.9537 - TPR: 0.8789 - FPR: 0.1177 - binary_crossentropy: 0.2712 - val_loss: 0.2724 - val_binary_accuracy: 0.9044 - val_ACCR: 0.9221 - val_auc1: 0.9729 - val_TPR: 0.9656 - val_FPR: 0.1326 - val_binary_crossentropy: 0.2634\n",
      "\n",
      "Epoch 00001: val_auc1 improved from -inf to 0.97285, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 24510s - loss: 0.2575 - binary_accuracy: 0.1011 - ACCR: 0.8040 - auc1: 0.9586 - TPR: 0.8852 - FPR: 0.1107 - binary_crossentropy: 0.2575 - val_loss: 0.2537 - val_binary_accuracy: 0.9102 - val_ACCR: 0.9236 - val_auc1: 0.9746 - val_TPR: 0.9650 - val_FPR: 0.1229 - val_binary_crossentropy: 0.2469\n",
      "\n",
      "Epoch 00002: val_auc1 improved from 0.97285 to 0.97464, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 24889s - loss: 0.2554 - binary_accuracy: 0.1015 - ACCR: 0.8056 - auc1: 0.9593 - TPR: 0.8861 - FPR: 0.1095 - binary_crossentropy: 0.2554 - val_loss: 0.2257 - val_binary_accuracy: 0.9111 - val_ACCR: 0.9253 - val_auc1: 0.9751 - val_TPR: 0.9664 - val_FPR: 0.1223 - val_binary_crossentropy: 0.2465\n",
      "\n",
      "Epoch 00003: val_auc1 improved from 0.97464 to 0.97507, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 24760s - loss: 0.2542 - binary_accuracy: 0.1017 - ACCR: 0.8066 - auc1: 0.9597 - TPR: 0.8865 - FPR: 0.1088 - binary_crossentropy: 0.2542 - val_loss: 0.2068 - val_binary_accuracy: 0.9129 - val_ACCR: 0.9267 - val_auc1: 0.9758 - val_TPR: 0.9662 - val_FPR: 0.1194 - val_binary_crossentropy: 0.2428\n",
      "\n",
      "Epoch 00004: val_auc1 improved from 0.97507 to 0.97579, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 24729s - loss: 0.2532 - binary_accuracy: 0.1019 - ACCR: 0.8072 - auc1: 0.9600 - TPR: 0.8869 - FPR: 0.1083 - binary_crossentropy: 0.2532 - val_loss: 0.2590 - val_binary_accuracy: 0.9114 - val_ACCR: 0.9277 - val_auc1: 0.9758 - val_TPR: 0.9675 - val_FPR: 0.1226 - val_binary_crossentropy: 0.2472\n",
      "\n",
      "Epoch 00005: val_auc1 did not improve from 0.97579\n",
      "Epoch 6/100\n",
      " - 24856s - loss: 0.2524 - binary_accuracy: 0.1021 - ACCR: 0.8078 - auc1: 0.9602 - TPR: 0.8872 - FPR: 0.1079 - binary_crossentropy: 0.2524 - val_loss: 0.1436 - val_binary_accuracy: 0.9127 - val_ACCR: 0.9288 - val_auc1: 0.9759 - val_TPR: 0.9677 - val_FPR: 0.1206 - val_binary_crossentropy: 0.2459\n",
      "\n",
      "Epoch 00006: val_auc1 improved from 0.97579 to 0.97593, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/100\n",
      " - 24897s - loss: 0.2517 - binary_accuracy: 0.1023 - ACCR: 0.8083 - auc1: 0.9605 - TPR: 0.8875 - FPR: 0.1076 - binary_crossentropy: 0.2517 - val_loss: 0.2111 - val_binary_accuracy: 0.9125 - val_ACCR: 0.9295 - val_auc1: 0.9761 - val_TPR: 0.9681 - val_FPR: 0.1211 - val_binary_crossentropy: 0.2458\n",
      "\n",
      "Epoch 00007: val_auc1 improved from 0.97593 to 0.97614, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/100\n",
      " - 24936s - loss: 0.2512 - binary_accuracy: 0.1024 - ACCR: 0.8088 - auc1: 0.9606 - TPR: 0.8876 - FPR: 0.1072 - binary_crossentropy: 0.2512 - val_loss: 0.1955 - val_binary_accuracy: 0.9113 - val_ACCR: 0.9297 - val_auc1: 0.9759 - val_TPR: 0.9693 - val_FPR: 0.1239 - val_binary_crossentropy: 0.2500\n",
      "\n",
      "Epoch 00008: val_auc1 did not improve from 0.97614\n",
      "Epoch 9/100\n",
      " - 24791s - loss: 0.2507 - binary_accuracy: 0.1025 - ACCR: 0.8092 - auc1: 0.9608 - TPR: 0.8879 - FPR: 0.1070 - binary_crossentropy: 0.2507 - val_loss: 0.2680 - val_binary_accuracy: 0.9118 - val_ACCR: 0.9290 - val_auc1: 0.9755 - val_TPR: 0.9687 - val_FPR: 0.1225 - val_binary_crossentropy: 0.2510\n",
      "\n",
      "Epoch 00009: val_auc1 did not improve from 0.97614\n",
      "Epoch 10/100\n",
      " - 25010s - loss: 0.2502 - binary_accuracy: 0.1026 - ACCR: 0.8095 - auc1: 0.9609 - TPR: 0.8880 - FPR: 0.1068 - binary_crossentropy: 0.2502 - val_loss: 0.2464 - val_binary_accuracy: 0.9117 - val_ACCR: 0.9303 - val_auc1: 0.9758 - val_TPR: 0.9702 - val_FPR: 0.1237 - val_binary_crossentropy: 0.2525\n",
      "\n",
      "Epoch 00010: val_auc1 did not improve from 0.97614\n",
      "Epoch 11/100\n",
      " - 24835s - loss: 0.2498 - binary_accuracy: 0.1027 - ACCR: 0.8099 - auc1: 0.9610 - TPR: 0.8882 - FPR: 0.1066 - binary_crossentropy: 0.2498 - val_loss: 0.2033 - val_binary_accuracy: 0.9119 - val_ACCR: 0.9301 - val_auc1: 0.9757 - val_TPR: 0.9701 - val_FPR: 0.1233 - val_binary_crossentropy: 0.2524\n",
      "\n",
      "Epoch 00011: val_auc1 did not improve from 0.97614\n",
      "Epoch 12/100\n",
      " - 24765s - loss: 0.2495 - binary_accuracy: 0.1028 - ACCR: 0.8101 - auc1: 0.9612 - TPR: 0.8883 - FPR: 0.1064 - binary_crossentropy: 0.2495 - val_loss: 0.3094 - val_binary_accuracy: 0.9131 - val_ACCR: 0.9302 - val_auc1: 0.9758 - val_TPR: 0.9696 - val_FPR: 0.1210 - val_binary_crossentropy: 0.2492\n",
      "\n",
      "Epoch 00012: val_auc1 did not improve from 0.97614\n",
      "Epoch 13/100\n",
      " - 24664s - loss: 0.2492 - binary_accuracy: 0.1028 - ACCR: 0.8104 - auc1: 0.9612 - TPR: 0.8884 - FPR: 0.1063 - binary_crossentropy: 0.2492 - val_loss: 0.1873 - val_binary_accuracy: 0.9122 - val_ACCR: 0.9306 - val_auc1: 0.9756 - val_TPR: 0.9697 - val_FPR: 0.1226 - val_binary_crossentropy: 0.2515\n",
      "\n",
      "Epoch 00013: val_auc1 did not improve from 0.97614\n",
      "Epoch 14/100\n",
      " - 24895s - loss: 0.2489 - binary_accuracy: 0.1029 - ACCR: 0.8107 - auc1: 0.9613 - TPR: 0.8884 - FPR: 0.1061 - binary_crossentropy: 0.2489 - val_loss: 0.2664 - val_binary_accuracy: 0.9127 - val_ACCR: 0.9302 - val_auc1: 0.9754 - val_TPR: 0.9696 - val_FPR: 0.1218 - val_binary_crossentropy: 0.2515\n",
      "\n",
      "Epoch 00014: val_auc1 did not improve from 0.97614\n",
      "Epoch 15/100\n",
      " - 24969s - loss: 0.2487 - binary_accuracy: 0.1029 - ACCR: 0.8108 - auc1: 0.9614 - TPR: 0.8885 - FPR: 0.1060 - binary_crossentropy: 0.2487 - val_loss: 0.2564 - val_binary_accuracy: 0.9132 - val_ACCR: 0.9305 - val_auc1: 0.9755 - val_TPR: 0.9696 - val_FPR: 0.1209 - val_binary_crossentropy: 0.2501\n",
      "\n",
      "Epoch 00015: val_auc1 did not improve from 0.97614\n",
      "Epoch 16/100\n",
      " - 24954s - loss: 0.2485 - binary_accuracy: 0.1029 - ACCR: 0.8110 - auc1: 0.9615 - TPR: 0.8886 - FPR: 0.1059 - binary_crossentropy: 0.2485 - val_loss: 0.2907 - val_binary_accuracy: 0.9123 - val_ACCR: 0.9297 - val_auc1: 0.9751 - val_TPR: 0.9699 - val_FPR: 0.1225 - val_binary_crossentropy: 0.2528\n",
      "\n",
      "Epoch 00016: val_auc1 did not improve from 0.97614\n",
      "Epoch 17/100\n",
      " - 24850s - loss: 0.2482 - binary_accuracy: 0.1030 - ACCR: 0.8112 - auc1: 0.9615 - TPR: 0.8887 - FPR: 0.1058 - binary_crossentropy: 0.2482 - val_loss: 0.2514 - val_binary_accuracy: 0.9122 - val_ACCR: 0.9303 - val_auc1: 0.9751 - val_TPR: 0.9703 - val_FPR: 0.1230 - val_binary_crossentropy: 0.2550\n",
      "\n",
      "Epoch 00017: val_auc1 did not improve from 0.97614\n",
      "Epoch 18/100\n",
      " - 25055s - loss: 0.2481 - binary_accuracy: 0.1030 - ACCR: 0.8114 - auc1: 0.9616 - TPR: 0.8887 - FPR: 0.1057 - binary_crossentropy: 0.2481 - val_loss: 0.2163 - val_binary_accuracy: 0.9114 - val_ACCR: 0.9295 - val_auc1: 0.9747 - val_TPR: 0.9705 - val_FPR: 0.1243 - val_binary_crossentropy: 0.2569\n",
      "\n",
      "Epoch 00018: val_auc1 did not improve from 0.97614\n",
      "Epoch 19/100\n",
      " - 24845s - loss: 0.2479 - binary_accuracy: 0.1030 - ACCR: 0.8115 - auc1: 0.9617 - TPR: 0.8888 - FPR: 0.1056 - binary_crossentropy: 0.2479 - val_loss: 0.2488 - val_binary_accuracy: 0.9106 - val_ACCR: 0.9297 - val_auc1: 0.9745 - val_TPR: 0.9712 - val_FPR: 0.1260 - val_binary_crossentropy: 0.2598\n",
      "\n",
      "Epoch 00019: val_auc1 did not improve from 0.97614\n",
      "Epoch 20/100\n",
      " - 24757s - loss: 0.2477 - binary_accuracy: 0.1030 - ACCR: 0.8117 - auc1: 0.9617 - TPR: 0.8889 - FPR: 0.1056 - binary_crossentropy: 0.2477 - val_loss: 0.2071 - val_binary_accuracy: 0.9111 - val_ACCR: 0.9297 - val_auc1: 0.9745 - val_TPR: 0.9714 - val_FPR: 0.1254 - val_binary_crossentropy: 0.2586\n",
      "\n",
      "Epoch 00020: val_auc1 did not improve from 0.97614\n",
      "Epoch 21/100\n"
     ]
    }
   ],
   "source": [
    "#for test negative enrichment,is it good to get better results?\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    #recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train2-ni.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test0.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train2-ni.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test0.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train2-ni.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test0.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)  \n",
    "        \n",
    "    with open('data/x_train0.pickle', 'rb') as f:\n",
    "        x_trainM = pickle.load(f) \n",
    "    with open('data/y_train0.pickle', 'rb') as f:\n",
    "        y_trainM = pickle.load(f) \n",
    "    with open('data/z_train0.pickle', 'rb') as f:\n",
    "        z_trainM = pickle.load(f) \n",
    "    \n",
    "    x_train=list(x_train)\n",
    "    y_train=list(y_train)\n",
    "    z_train=list(z_train)\n",
    "    x_trainM=list(x_trainM)\n",
    "    y_trainM=list(y_trainM)\n",
    "    z_trainM=list(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    \n",
    "    x_train.extend(x_trainM)\n",
    "    y_train.extend(y_trainM)\n",
    "    z_train.extend(z_trainM)\n",
    "    \n",
    "    xyz = list(zip(x_train, y_train, z_train))\n",
    "#    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    x_train, y_train, z_train= zip(*xyz)     \n",
    "    print('shuffle is over...')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_auc1', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_auc1', patience=14, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "#                    class_weight = {1:2., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=6, \n",
    "                    use_multiprocessing=0, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 8, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [19:52:39] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 1269s - loss: 0.1734 - binary_accuracy: 0.6327 - ACCR: 0.8545 - auc1: 0.9525 - TPR: 0.9786 - FPR: 0.2602 - binary_crossentropy: 0.1734 - val_loss: 0.3062 - val_binary_accuracy: 0.8917 - val_ACCR: 0.9253 - val_auc1: 0.9737 - val_TPR: 0.9732 - val_FPR: 0.1577 - val_binary_crossentropy: 0.2848\n",
      "\n",
      "Epoch 00001: val_auc1 improved from -inf to 0.97366, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 1223s - loss: 0.1124 - binary_accuracy: 0.6513 - ACCR: 0.9228 - auc1: 0.9798 - TPR: 0.9854 - FPR: 0.1470 - binary_crossentropy: 0.1124 - val_loss: 0.2551 - val_binary_accuracy: 0.8978 - val_ACCR: 0.9324 - val_auc1: 0.9766 - val_TPR: 0.9753 - val_FPR: 0.1491 - val_binary_crossentropy: 0.2785\n",
      "\n",
      "Epoch 00002: val_auc1 improved from 0.97366 to 0.97661, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 1231s - loss: 0.1013 - binary_accuracy: 0.6562 - ACCR: 0.9319 - auc1: 0.9820 - TPR: 0.9877 - FPR: 0.1272 - binary_crossentropy: 0.1013 - val_loss: 0.2289 - val_binary_accuracy: 0.9060 - val_ACCR: 0.9336 - val_auc1: 0.9777 - val_TPR: 0.9742 - val_FPR: 0.1352 - val_binary_crossentropy: 0.2573\n",
      "\n",
      "Epoch 00003: val_auc1 improved from 0.97661 to 0.97771, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 1237s - loss: 0.0964 - binary_accuracy: 0.6586 - ACCR: 0.9360 - auc1: 0.9828 - TPR: 0.9890 - FPR: 0.1202 - binary_crossentropy: 0.0964 - val_loss: 0.2673 - val_binary_accuracy: 0.9071 - val_ACCR: 0.9348 - val_auc1: 0.9785 - val_TPR: 0.9755 - val_FPR: 0.1342 - val_binary_crossentropy: 0.2560\n",
      "\n",
      "Epoch 00004: val_auc1 improved from 0.97771 to 0.97849, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 1233s - loss: 0.0938 - binary_accuracy: 0.6599 - ACCR: 0.9384 - auc1: 0.9833 - TPR: 0.9898 - FPR: 0.1171 - binary_crossentropy: 0.0938 - val_loss: 0.2211 - val_binary_accuracy: 0.9104 - val_ACCR: 0.9357 - val_auc1: 0.9792 - val_TPR: 0.9750 - val_FPR: 0.1287 - val_binary_crossentropy: 0.2454\n",
      "\n",
      "Epoch 00005: val_auc1 improved from 0.97849 to 0.97924, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/100\n",
      " - 1229s - loss: 0.0920 - binary_accuracy: 0.6607 - ACCR: 0.9397 - auc1: 0.9836 - TPR: 0.9904 - FPR: 0.1152 - binary_crossentropy: 0.0920 - val_loss: 0.2138 - val_binary_accuracy: 0.9110 - val_ACCR: 0.9364 - val_auc1: 0.9795 - val_TPR: 0.9757 - val_FPR: 0.1281 - val_binary_crossentropy: 0.2437\n",
      "\n",
      "Epoch 00006: val_auc1 improved from 0.97924 to 0.97947, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/100\n",
      " - 1233s - loss: 0.0907 - binary_accuracy: 0.6614 - ACCR: 0.9407 - auc1: 0.9839 - TPR: 0.9909 - FPR: 0.1144 - binary_crossentropy: 0.0907 - val_loss: 0.2271 - val_binary_accuracy: 0.9122 - val_ACCR: 0.9372 - val_auc1: 0.9796 - val_TPR: 0.9750 - val_FPR: 0.1258 - val_binary_crossentropy: 0.2426\n",
      "\n",
      "Epoch 00007: val_auc1 improved from 0.97947 to 0.97958, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/100\n",
      " - 1265s - loss: 0.0897 - binary_accuracy: 0.6618 - ACCR: 0.9412 - auc1: 0.9841 - TPR: 0.9912 - FPR: 0.1136 - binary_crossentropy: 0.0897 - val_loss: 0.2574 - val_binary_accuracy: 0.9130 - val_ACCR: 0.9377 - val_auc1: 0.9803 - val_TPR: 0.9756 - val_FPR: 0.1249 - val_binary_crossentropy: 0.2388\n",
      "\n",
      "Epoch 00008: val_auc1 improved from 0.97958 to 0.98026, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/100\n",
      " - 1260s - loss: 0.0890 - binary_accuracy: 0.6622 - ACCR: 0.9418 - auc1: 0.9843 - TPR: 0.9915 - FPR: 0.1134 - binary_crossentropy: 0.0890 - val_loss: 0.2437 - val_binary_accuracy: 0.9142 - val_ACCR: 0.9370 - val_auc1: 0.9804 - val_TPR: 0.9754 - val_FPR: 0.1228 - val_binary_crossentropy: 0.2336\n",
      "\n",
      "Epoch 00009: val_auc1 improved from 0.98026 to 0.98042, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 10/100\n",
      " - 1228s - loss: 0.0884 - binary_accuracy: 0.6624 - ACCR: 0.9422 - auc1: 0.9844 - TPR: 0.9917 - FPR: 0.1130 - binary_crossentropy: 0.0884 - val_loss: 0.1884 - val_binary_accuracy: 0.9147 - val_ACCR: 0.9368 - val_auc1: 0.9806 - val_TPR: 0.9752 - val_FPR: 0.1219 - val_binary_crossentropy: 0.2322\n",
      "\n",
      "Epoch 00010: val_auc1 improved from 0.98042 to 0.98057, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 11/100\n",
      " - 1236s - loss: 0.0878 - binary_accuracy: 0.6627 - ACCR: 0.9425 - auc1: 0.9846 - TPR: 0.9919 - FPR: 0.1128 - binary_crossentropy: 0.0878 - val_loss: 0.2479 - val_binary_accuracy: 0.9147 - val_ACCR: 0.9385 - val_auc1: 0.9809 - val_TPR: 0.9755 - val_FPR: 0.1221 - val_binary_crossentropy: 0.2324\n",
      "\n",
      "Epoch 00011: val_auc1 improved from 0.98057 to 0.98092, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 12/100\n",
      " - 1235s - loss: 0.0874 - binary_accuracy: 0.6629 - ACCR: 0.9427 - auc1: 0.9847 - TPR: 0.9920 - FPR: 0.1127 - binary_crossentropy: 0.0874 - val_loss: 0.2558 - val_binary_accuracy: 0.9130 - val_ACCR: 0.9387 - val_auc1: 0.9810 - val_TPR: 0.9765 - val_FPR: 0.1254 - val_binary_crossentropy: 0.2361\n",
      "\n",
      "Epoch 00012: val_auc1 improved from 0.98092 to 0.98097, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 13/100\n",
      " - 1237s - loss: 0.0870 - binary_accuracy: 0.6630 - ACCR: 0.9430 - auc1: 0.9848 - TPR: 0.9922 - FPR: 0.1126 - binary_crossentropy: 0.0870 - val_loss: 0.2758 - val_binary_accuracy: 0.9174 - val_ACCR: 0.9379 - val_auc1: 0.9812 - val_TPR: 0.9742 - val_FPR: 0.1169 - val_binary_crossentropy: 0.2248\n",
      "\n",
      "Epoch 00013: val_auc1 improved from 0.98097 to 0.98122, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 14/100\n",
      " - 1230s - loss: 0.0866 - binary_accuracy: 0.6631 - ACCR: 0.9432 - auc1: 0.9849 - TPR: 0.9923 - FPR: 0.1125 - binary_crossentropy: 0.0866 - val_loss: 0.2149 - val_binary_accuracy: 0.9154 - val_ACCR: 0.9388 - val_auc1: 0.9812 - val_TPR: 0.9755 - val_FPR: 0.1210 - val_binary_crossentropy: 0.2312\n",
      "\n",
      "Epoch 00014: val_auc1 did not improve from 0.98122\n",
      "Epoch 15/100\n",
      " - 1231s - loss: 0.0864 - binary_accuracy: 0.6634 - ACCR: 0.9432 - auc1: 0.9850 - TPR: 0.9925 - FPR: 0.1124 - binary_crossentropy: 0.0864 - val_loss: 0.2074 - val_binary_accuracy: 0.9155 - val_ACCR: 0.9385 - val_auc1: 0.9812 - val_TPR: 0.9758 - val_FPR: 0.1211 - val_binary_crossentropy: 0.2290\n",
      "\n",
      "Epoch 00015: val_auc1 improved from 0.98122 to 0.98125, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 16/100\n",
      " - 1233s - loss: 0.0860 - binary_accuracy: 0.6634 - ACCR: 0.9434 - auc1: 0.9851 - TPR: 0.9926 - FPR: 0.1124 - binary_crossentropy: 0.0860 - val_loss: 0.2061 - val_binary_accuracy: 0.9173 - val_ACCR: 0.9382 - val_auc1: 0.9815 - val_TPR: 0.9743 - val_FPR: 0.1172 - val_binary_crossentropy: 0.2225\n",
      "\n",
      "Epoch 00016: val_auc1 improved from 0.98125 to 0.98153, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 17/100\n",
      " - 1255s - loss: 0.0858 - binary_accuracy: 0.6635 - ACCR: 0.9434 - auc1: 0.9852 - TPR: 0.9926 - FPR: 0.1123 - binary_crossentropy: 0.0858 - val_loss: 0.1841 - val_binary_accuracy: 0.9165 - val_ACCR: 0.9393 - val_auc1: 0.9817 - val_TPR: 0.9756 - val_FPR: 0.1193 - val_binary_crossentropy: 0.2253\n",
      "\n",
      "Epoch 00017: val_auc1 improved from 0.98153 to 0.98171, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 18/100\n",
      " - 1262s - loss: 0.0855 - binary_accuracy: 0.6637 - ACCR: 0.9435 - auc1: 0.9852 - TPR: 0.9928 - FPR: 0.1122 - binary_crossentropy: 0.0855 - val_loss: 0.2134 - val_binary_accuracy: 0.9130 - val_ACCR: 0.9396 - val_auc1: 0.9815 - val_TPR: 0.9772 - val_FPR: 0.1259 - val_binary_crossentropy: 0.2363\n",
      "\n",
      "Epoch 00018: val_auc1 did not improve from 0.98171\n",
      "Epoch 19/100\n",
      " - 1239s - loss: 0.0853 - binary_accuracy: 0.6638 - ACCR: 0.9436 - auc1: 0.9853 - TPR: 0.9929 - FPR: 0.1122 - binary_crossentropy: 0.0853 - val_loss: 0.2302 - val_binary_accuracy: 0.9163 - val_ACCR: 0.9392 - val_auc1: 0.9816 - val_TPR: 0.9752 - val_FPR: 0.1193 - val_binary_crossentropy: 0.2270\n",
      "\n",
      "Epoch 00019: val_auc1 did not improve from 0.98171\n",
      "Epoch 20/100\n",
      " - 1241s - loss: 0.0851 - binary_accuracy: 0.6638 - ACCR: 0.9437 - auc1: 0.9854 - TPR: 0.9929 - FPR: 0.1123 - binary_crossentropy: 0.0851 - val_loss: 0.2309 - val_binary_accuracy: 0.9180 - val_ACCR: 0.9389 - val_auc1: 0.9819 - val_TPR: 0.9749 - val_FPR: 0.1164 - val_binary_crossentropy: 0.2219\n",
      "\n",
      "Epoch 00020: val_auc1 improved from 0.98171 to 0.98187, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 21/100\n",
      " - 1249s - loss: 0.0849 - binary_accuracy: 0.6639 - ACCR: 0.9437 - auc1: 0.9854 - TPR: 0.9930 - FPR: 0.1122 - binary_crossentropy: 0.0849 - val_loss: 0.2095 - val_binary_accuracy: 0.9166 - val_ACCR: 0.9386 - val_auc1: 0.9816 - val_TPR: 0.9757 - val_FPR: 0.1192 - val_binary_crossentropy: 0.2258\n",
      "\n",
      "Epoch 00021: val_auc1 did not improve from 0.98187\n",
      "Epoch 22/100\n",
      " - 1235s - loss: 0.0847 - binary_accuracy: 0.6640 - ACCR: 0.9437 - auc1: 0.9855 - TPR: 0.9931 - FPR: 0.1121 - binary_crossentropy: 0.0847 - val_loss: 0.2511 - val_binary_accuracy: 0.9169 - val_ACCR: 0.9394 - val_auc1: 0.9819 - val_TPR: 0.9759 - val_FPR: 0.1187 - val_binary_crossentropy: 0.2242\n",
      "\n",
      "Epoch 00022: val_auc1 did not improve from 0.98187\n",
      "Epoch 23/100\n",
      " - 1233s - loss: 0.0845 - binary_accuracy: 0.6641 - ACCR: 0.9438 - auc1: 0.9855 - TPR: 0.9932 - FPR: 0.1122 - binary_crossentropy: 0.0845 - val_loss: 0.2115 - val_binary_accuracy: 0.9130 - val_ACCR: 0.9400 - val_auc1: 0.9817 - val_TPR: 0.9775 - val_FPR: 0.1259 - val_binary_crossentropy: 0.2346\n",
      "\n",
      "Epoch 00023: val_auc1 did not improve from 0.98187\n",
      "Epoch 24/100\n",
      " - 1233s - loss: 0.0844 - binary_accuracy: 0.6642 - ACCR: 0.9439 - auc1: 0.9856 - TPR: 0.9932 - FPR: 0.1121 - binary_crossentropy: 0.0844 - val_loss: 0.2003 - val_binary_accuracy: 0.9166 - val_ACCR: 0.9394 - val_auc1: 0.9818 - val_TPR: 0.9756 - val_FPR: 0.1190 - val_binary_crossentropy: 0.2251\n",
      "\n",
      "Epoch 00024: val_auc1 did not improve from 0.98187\n",
      "Epoch 25/100\n",
      " - 1268s - loss: 0.0841 - binary_accuracy: 0.6642 - ACCR: 0.9439 - auc1: 0.9856 - TPR: 0.9933 - FPR: 0.1122 - binary_crossentropy: 0.0841 - val_loss: 0.1878 - val_binary_accuracy: 0.9164 - val_ACCR: 0.9396 - val_auc1: 0.9820 - val_TPR: 0.9762 - val_FPR: 0.1198 - val_binary_crossentropy: 0.2249\n",
      "\n",
      "Epoch 00025: val_auc1 improved from 0.98187 to 0.98196, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 26/100\n",
      " - 1243s - loss: 0.0840 - binary_accuracy: 0.6643 - ACCR: 0.9440 - auc1: 0.9857 - TPR: 0.9934 - FPR: 0.1121 - binary_crossentropy: 0.0840 - val_loss: 0.2121 - val_binary_accuracy: 0.9163 - val_ACCR: 0.9394 - val_auc1: 0.9820 - val_TPR: 0.9765 - val_FPR: 0.1202 - val_binary_crossentropy: 0.2253\n",
      "\n",
      "Epoch 00026: val_auc1 improved from 0.98196 to 0.98202, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 27/100\n",
      " - 1233s - loss: 0.0839 - binary_accuracy: 0.6643 - ACCR: 0.9440 - auc1: 0.9857 - TPR: 0.9934 - FPR: 0.1120 - binary_crossentropy: 0.0839 - val_loss: 0.1935 - val_binary_accuracy: 0.9154 - val_ACCR: 0.9395 - val_auc1: 0.9820 - val_TPR: 0.9765 - val_FPR: 0.1216 - val_binary_crossentropy: 0.2267\n",
      "\n",
      "Epoch 00027: val_auc1 did not improve from 0.98202\n",
      "Epoch 28/100\n",
      " - 1251s - loss: 0.0838 - binary_accuracy: 0.6644 - ACCR: 0.9440 - auc1: 0.9858 - TPR: 0.9934 - FPR: 0.1121 - binary_crossentropy: 0.0838 - val_loss: 0.2112 - val_binary_accuracy: 0.9169 - val_ACCR: 0.9391 - val_auc1: 0.9820 - val_TPR: 0.9762 - val_FPR: 0.1190 - val_binary_crossentropy: 0.2236\n",
      "\n",
      "Epoch 00028: val_auc1 did not improve from 0.98202\n",
      "Epoch 29/100\n",
      " - 1258s - loss: 0.0836 - binary_accuracy: 0.6644 - ACCR: 0.9441 - auc1: 0.9858 - TPR: 0.9935 - FPR: 0.1122 - binary_crossentropy: 0.0836 - val_loss: 0.2020 - val_binary_accuracy: 0.9147 - val_ACCR: 0.9402 - val_auc1: 0.9820 - val_TPR: 0.9767 - val_FPR: 0.1227 - val_binary_crossentropy: 0.2286\n",
      "\n",
      "Epoch 00029: val_auc1 did not improve from 0.98202\n",
      "Epoch 30/100\n",
      " - 1271s - loss: 0.0835 - binary_accuracy: 0.6645 - ACCR: 0.9440 - auc1: 0.9858 - TPR: 0.9936 - FPR: 0.1121 - binary_crossentropy: 0.0835 - val_loss: 0.1715 - val_binary_accuracy: 0.9144 - val_ACCR: 0.9399 - val_auc1: 0.9819 - val_TPR: 0.9766 - val_FPR: 0.1232 - val_binary_crossentropy: 0.2296\n",
      "\n",
      "Epoch 00030: val_auc1 did not improve from 0.98202\n",
      "Epoch 31/100\n",
      " - 1275s - loss: 0.0834 - binary_accuracy: 0.6645 - ACCR: 0.9441 - auc1: 0.9859 - TPR: 0.9936 - FPR: 0.1122 - binary_crossentropy: 0.0834 - val_loss: 0.2522 - val_binary_accuracy: 0.9124 - val_ACCR: 0.9403 - val_auc1: 0.9820 - val_TPR: 0.9780 - val_FPR: 0.1273 - val_binary_crossentropy: 0.2342\n",
      "\n",
      "Epoch 00031: val_auc1 did not improve from 0.98202\n",
      "Epoch 32/100\n",
      " - 1249s - loss: 0.0833 - binary_accuracy: 0.6646 - ACCR: 0.9442 - auc1: 0.9859 - TPR: 0.9937 - FPR: 0.1122 - binary_crossentropy: 0.0833 - val_loss: 0.2240 - val_binary_accuracy: 0.9133 - val_ACCR: 0.9401 - val_auc1: 0.9821 - val_TPR: 0.9776 - val_FPR: 0.1256 - val_binary_crossentropy: 0.2326\n",
      "\n",
      "Epoch 00032: val_auc1 improved from 0.98202 to 0.98207, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 33/100\n",
      " - 1227s - loss: 0.0832 - binary_accuracy: 0.6647 - ACCR: 0.9442 - auc1: 0.9859 - TPR: 0.9938 - FPR: 0.1122 - binary_crossentropy: 0.0832 - val_loss: 0.2481 - val_binary_accuracy: 0.9143 - val_ACCR: 0.9398 - val_auc1: 0.9820 - val_TPR: 0.9773 - val_FPR: 0.1238 - val_binary_crossentropy: 0.2298\n",
      "\n",
      "Epoch 00033: val_auc1 did not improve from 0.98207\n",
      "Epoch 34/100\n",
      " - 1247s - loss: 0.0830 - binary_accuracy: 0.6647 - ACCR: 0.9442 - auc1: 0.9860 - TPR: 0.9938 - FPR: 0.1121 - binary_crossentropy: 0.0830 - val_loss: 0.1857 - val_binary_accuracy: 0.9180 - val_ACCR: 0.9395 - val_auc1: 0.9822 - val_TPR: 0.9761 - val_FPR: 0.1172 - val_binary_crossentropy: 0.2201\n",
      "\n",
      "Epoch 00034: val_auc1 improved from 0.98207 to 0.98221, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 35/100\n",
      " - 1256s - loss: 0.0830 - binary_accuracy: 0.6647 - ACCR: 0.9442 - auc1: 0.9860 - TPR: 0.9939 - FPR: 0.1122 - binary_crossentropy: 0.0830 - val_loss: 0.2340 - val_binary_accuracy: 0.9150 - val_ACCR: 0.9401 - val_auc1: 0.9819 - val_TPR: 0.9772 - val_FPR: 0.1225 - val_binary_crossentropy: 0.2285\n",
      "\n",
      "Epoch 00035: val_auc1 did not improve from 0.98221\n",
      "Epoch 36/100\n",
      " - 1231s - loss: 0.0828 - binary_accuracy: 0.6648 - ACCR: 0.9442 - auc1: 0.9860 - TPR: 0.9939 - FPR: 0.1121 - binary_crossentropy: 0.0828 - val_loss: 0.2448 - val_binary_accuracy: 0.9166 - val_ACCR: 0.9397 - val_auc1: 0.9821 - val_TPR: 0.9762 - val_FPR: 0.1195 - val_binary_crossentropy: 0.2242\n",
      "\n",
      "Epoch 00036: val_auc1 did not improve from 0.98221\n",
      "Epoch 37/100\n",
      " - 1233s - loss: 0.0827 - binary_accuracy: 0.6648 - ACCR: 0.9443 - auc1: 0.9860 - TPR: 0.9939 - FPR: 0.1122 - binary_crossentropy: 0.0827 - val_loss: 0.1922 - val_binary_accuracy: 0.9146 - val_ACCR: 0.9395 - val_auc1: 0.9822 - val_TPR: 0.9771 - val_FPR: 0.1232 - val_binary_crossentropy: 0.2275\n",
      "\n",
      "Epoch 00037: val_auc1 did not improve from 0.98221\n",
      "Epoch 38/100\n",
      " - 1246s - loss: 0.0827 - binary_accuracy: 0.6648 - ACCR: 0.9442 - auc1: 0.9861 - TPR: 0.9939 - FPR: 0.1122 - binary_crossentropy: 0.0827 - val_loss: 0.2024 - val_binary_accuracy: 0.9119 - val_ACCR: 0.9405 - val_auc1: 0.9822 - val_TPR: 0.9788 - val_FPR: 0.1285 - val_binary_crossentropy: 0.2346\n",
      "\n",
      "Epoch 00038: val_auc1 did not improve from 0.98221\n",
      "Epoch 39/100\n",
      " - 1234s - loss: 0.0826 - binary_accuracy: 0.6649 - ACCR: 0.9443 - auc1: 0.9861 - TPR: 0.9940 - FPR: 0.1122 - binary_crossentropy: 0.0826 - val_loss: 0.2542 - val_binary_accuracy: 0.9139 - val_ACCR: 0.9404 - val_auc1: 0.9821 - val_TPR: 0.9776 - val_FPR: 0.1246 - val_binary_crossentropy: 0.2306\n",
      "\n",
      "Epoch 00039: val_auc1 did not improve from 0.98221\n",
      "Epoch 40/100\n",
      " - 1263s - loss: 0.0825 - binary_accuracy: 0.6649 - ACCR: 0.9442 - auc1: 0.9861 - TPR: 0.9941 - FPR: 0.1122 - binary_crossentropy: 0.0825 - val_loss: 0.2548 - val_binary_accuracy: 0.9170 - val_ACCR: 0.9399 - val_auc1: 0.9825 - val_TPR: 0.9764 - val_FPR: 0.1190 - val_binary_crossentropy: 0.2200\n",
      "\n",
      "Epoch 00040: val_auc1 improved from 0.98221 to 0.98253, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 41/100\n",
      " - 1228s - loss: 0.0824 - binary_accuracy: 0.6650 - ACCR: 0.9443 - auc1: 0.9861 - TPR: 0.9941 - FPR: 0.1121 - binary_crossentropy: 0.0824 - val_loss: 0.2211 - val_binary_accuracy: 0.9156 - val_ACCR: 0.9399 - val_auc1: 0.9822 - val_TPR: 0.9765 - val_FPR: 0.1212 - val_binary_crossentropy: 0.2246\n",
      "\n",
      "Epoch 00041: val_auc1 did not improve from 0.98253\n",
      "Epoch 42/100\n",
      " - 1230s - loss: 0.0823 - binary_accuracy: 0.6651 - ACCR: 0.9443 - auc1: 0.9862 - TPR: 0.9942 - FPR: 0.1121 - binary_crossentropy: 0.0823 - val_loss: 0.2211 - val_binary_accuracy: 0.9163 - val_ACCR: 0.9399 - val_auc1: 0.9823 - val_TPR: 0.9766 - val_FPR: 0.1201 - val_binary_crossentropy: 0.2237\n",
      "\n",
      "Epoch 00042: val_auc1 did not improve from 0.98253\n",
      "Epoch 43/100\n",
      " - 1249s - loss: 0.0822 - binary_accuracy: 0.6650 - ACCR: 0.9444 - auc1: 0.9862 - TPR: 0.9942 - FPR: 0.1123 - binary_crossentropy: 0.0822 - val_loss: 0.1755 - val_binary_accuracy: 0.9163 - val_ACCR: 0.9397 - val_auc1: 0.9823 - val_TPR: 0.9766 - val_FPR: 0.1201 - val_binary_crossentropy: 0.2232\n",
      "\n",
      "Epoch 00043: val_auc1 did not improve from 0.98253\n",
      "Epoch 44/100\n",
      " - 1229s - loss: 0.0822 - binary_accuracy: 0.6651 - ACCR: 0.9443 - auc1: 0.9862 - TPR: 0.9943 - FPR: 0.1123 - binary_crossentropy: 0.0822 - val_loss: 0.1879 - val_binary_accuracy: 0.9147 - val_ACCR: 0.9403 - val_auc1: 0.9824 - val_TPR: 0.9778 - val_FPR: 0.1235 - val_binary_crossentropy: 0.2273\n",
      "\n",
      "Epoch 00044: val_auc1 did not improve from 0.98253\n",
      "Epoch 45/100\n",
      " - 1269s - loss: 0.0821 - binary_accuracy: 0.6651 - ACCR: 0.9444 - auc1: 0.9862 - TPR: 0.9943 - FPR: 0.1123 - binary_crossentropy: 0.0821 - val_loss: 0.2188 - val_binary_accuracy: 0.9134 - val_ACCR: 0.9400 - val_auc1: 0.9821 - val_TPR: 0.9782 - val_FPR: 0.1258 - val_binary_crossentropy: 0.2313\n",
      "\n",
      "Epoch 00045: val_auc1 did not improve from 0.98253\n",
      "Epoch 46/100\n",
      " - 1236s - loss: 0.0820 - binary_accuracy: 0.6652 - ACCR: 0.9444 - auc1: 0.9862 - TPR: 0.9943 - FPR: 0.1123 - binary_crossentropy: 0.0820 - val_loss: 0.2603 - val_binary_accuracy: 0.9130 - val_ACCR: 0.9404 - val_auc1: 0.9821 - val_TPR: 0.9785 - val_FPR: 0.1266 - val_binary_crossentropy: 0.2331\n",
      "\n",
      "Epoch 00046: val_auc1 did not improve from 0.98253\n",
      "Epoch 47/100\n",
      " - 1233s - loss: 0.0819 - binary_accuracy: 0.6652 - ACCR: 0.9444 - auc1: 0.9863 - TPR: 0.9944 - FPR: 0.1122 - binary_crossentropy: 0.0819 - val_loss: 0.2267 - val_binary_accuracy: 0.9142 - val_ACCR: 0.9398 - val_auc1: 0.9822 - val_TPR: 0.9777 - val_FPR: 0.1242 - val_binary_crossentropy: 0.2276\n",
      "\n",
      "Epoch 00047: val_auc1 did not improve from 0.98253\n",
      "Epoch 48/100\n",
      " - 1248s - loss: 0.0818 - binary_accuracy: 0.6653 - ACCR: 0.9444 - auc1: 0.9863 - TPR: 0.9944 - FPR: 0.1124 - binary_crossentropy: 0.0818 - val_loss: 0.1805 - val_binary_accuracy: 0.9160 - val_ACCR: 0.9397 - val_auc1: 0.9822 - val_TPR: 0.9770 - val_FPR: 0.1209 - val_binary_crossentropy: 0.2241\n",
      "\n",
      "Epoch 00048: val_auc1 did not improve from 0.98253\n",
      "Epoch 49/100\n",
      " - 1237s - loss: 0.0817 - binary_accuracy: 0.6653 - ACCR: 0.9445 - auc1: 0.9863 - TPR: 0.9944 - FPR: 0.1122 - binary_crossentropy: 0.0817 - val_loss: 0.2287 - val_binary_accuracy: 0.9148 - val_ACCR: 0.9400 - val_auc1: 0.9822 - val_TPR: 0.9777 - val_FPR: 0.1232 - val_binary_crossentropy: 0.2264\n",
      "\n",
      "Epoch 00049: val_auc1 did not improve from 0.98253\n",
      "Epoch 50/100\n",
      " - 1246s - loss: 0.0816 - binary_accuracy: 0.6653 - ACCR: 0.9444 - auc1: 0.9863 - TPR: 0.9945 - FPR: 0.1122 - binary_crossentropy: 0.0816 - val_loss: 0.2912 - val_binary_accuracy: 0.9149 - val_ACCR: 0.9401 - val_auc1: 0.9823 - val_TPR: 0.9777 - val_FPR: 0.1230 - val_binary_crossentropy: 0.2267\n",
      "\n",
      "Epoch 00050: val_auc1 did not improve from 0.98253\n",
      "Epoch 51/100\n"
     ]
    }
   ],
   "source": [
    "#for test negative enrichment,is it good to get better results?\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    #recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train0-ni.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test0.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train0-ni.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test0.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train0-ni.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test0.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)  \n",
    "        \n",
    "    with open('data/x_train0.pickle', 'rb') as f:\n",
    "        x_trainM = pickle.load(f) \n",
    "    with open('data/y_train0.pickle', 'rb') as f:\n",
    "        y_trainM = pickle.load(f) \n",
    "    with open('data/z_train0.pickle', 'rb') as f:\n",
    "        z_trainM = pickle.load(f) \n",
    "    \n",
    "    x_train=list(x_train)\n",
    "    y_train=list(y_train)\n",
    "    z_train=list(z_train)\n",
    "    x_trainM=list(x_trainM)\n",
    "    y_trainM=list(y_trainM)\n",
    "    z_trainM=list(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    \n",
    "    x_train.extend(x_trainM)\n",
    "    y_train.extend(y_trainM)\n",
    "    z_train.extend(z_trainM)\n",
    "    \n",
    "    xyz = list(zip(x_train, y_train, z_train))\n",
    "#    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    x_train, y_train, z_train= zip(*xyz)     \n",
    "    print('shuffle is over...')\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_auc1', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_auc1', patience=14, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "#                    class_weight = {1:2., 0:1.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=4, \n",
    "                    use_multiprocessing=1, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 8, \n",
    "#                    callbacks=[earlystop, checkpoint]\n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [20:31:48] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Loading data...\n",
      "shuffle is over...\n",
      "train length: 4599696\n",
      "test length: 1533232\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 16384)        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 16384)        0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1024)         16778240    lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 1024)         0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "highway_1 (Highway)             (None, 1024)         2099200     dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_2 (Highway)             (None, 1024)         2099200     highway_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_3 (Highway)             (None, 1024)         2099200     highway_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "highway_4 (Highway)             (None, 1024)         2099200     highway_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highway_5 (Highway)             (None, 1024)         2099200     highway_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1024)         2098176     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_7 (Lambda)               (None, 1)            0           highway_5[0][0]                  \n",
      "                                                                 dense_12[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 29,372,416\n",
      "Trainable params: 29,372,416\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      " - 1659s - loss: 0.1790 - binary_accuracy: 0.6292 - ACCR: 0.8535 - auc1: 0.9659 - TPR: 0.9699 - FPR: 0.1657 - binary_crossentropy: 0.1790 - val_loss: 0.1059 - val_binary_accuracy: 0.9721 - val_ACCR: 0.9199 - val_auc1: 0.9938 - val_TPR: 0.9806 - val_FPR: 0.0538 - val_binary_crossentropy: 0.0865\n",
      "\n",
      "Epoch 00001: val_auc1 improved from -inf to 0.99381, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 2/100\n",
      " - 1631s - loss: 0.1104 - binary_accuracy: 0.6506 - ACCR: 0.9264 - auc1: 0.9869 - TPR: 0.9814 - FPR: 0.0877 - binary_crossentropy: 0.1104 - val_loss: 0.0491 - val_binary_accuracy: 0.9836 - val_ACCR: 0.9417 - val_auc1: 0.9977 - val_TPR: 0.9872 - val_FPR: 0.0274 - val_binary_crossentropy: 0.0573\n",
      "\n",
      "Epoch 00002: val_auc1 improved from 0.99381 to 0.99769, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 3/100\n",
      " - 1633s - loss: 0.0974 - binary_accuracy: 0.6561 - ACCR: 0.9374 - auc1: 0.9888 - TPR: 0.9844 - FPR: 0.0738 - binary_crossentropy: 0.0974 - val_loss: 0.0387 - val_binary_accuracy: 0.9879 - val_ACCR: 0.9464 - val_auc1: 0.9988 - val_TPR: 0.9891 - val_FPR: 0.0156 - val_binary_crossentropy: 0.0468\n",
      "\n",
      "Epoch 00003: val_auc1 improved from 0.99769 to 0.99876, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 4/100\n",
      " - 1639s - loss: 0.0919 - binary_accuracy: 0.6587 - ACCR: 0.9423 - auc1: 0.9894 - TPR: 0.9861 - FPR: 0.0688 - binary_crossentropy: 0.0919 - val_loss: 0.0371 - val_binary_accuracy: 0.9904 - val_ACCR: 0.9503 - val_auc1: 0.9992 - val_TPR: 0.9910 - val_FPR: 0.0114 - val_binary_crossentropy: 0.0412\n",
      "\n",
      "Epoch 00004: val_auc1 improved from 0.99876 to 0.99920, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 5/100\n",
      " - 1632s - loss: 0.0889 - binary_accuracy: 0.6602 - ACCR: 0.9450 - auc1: 0.9898 - TPR: 0.9871 - FPR: 0.0660 - binary_crossentropy: 0.0889 - val_loss: 0.0241 - val_binary_accuracy: 0.9924 - val_ACCR: 0.9587 - val_auc1: 0.9994 - val_TPR: 0.9934 - val_FPR: 0.0109 - val_binary_crossentropy: 0.0357\n",
      "\n",
      "Epoch 00005: val_auc1 improved from 0.99920 to 0.99942, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 6/100\n",
      " - 1640s - loss: 0.0871 - binary_accuracy: 0.6612 - ACCR: 0.9468 - auc1: 0.9900 - TPR: 0.9878 - FPR: 0.0645 - binary_crossentropy: 0.0871 - val_loss: 0.0316 - val_binary_accuracy: 0.9930 - val_ACCR: 0.9583 - val_auc1: 0.9996 - val_TPR: 0.9935 - val_FPR: 0.0087 - val_binary_crossentropy: 0.0340\n",
      "\n",
      "Epoch 00006: val_auc1 improved from 0.99942 to 0.99955, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 7/100\n",
      " - 1638s - loss: 0.0857 - binary_accuracy: 0.6619 - ACCR: 0.9480 - auc1: 0.9902 - TPR: 0.9882 - FPR: 0.0637 - binary_crossentropy: 0.0857 - val_loss: 0.0271 - val_binary_accuracy: 0.9938 - val_ACCR: 0.9591 - val_auc1: 0.9996 - val_TPR: 0.9941 - val_FPR: 0.0072 - val_binary_crossentropy: 0.0322\n",
      "\n",
      "Epoch 00007: val_auc1 improved from 0.99955 to 0.99961, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 8/100\n",
      " - 1636s - loss: 0.0846 - binary_accuracy: 0.6624 - ACCR: 0.9489 - auc1: 0.9903 - TPR: 0.9887 - FPR: 0.0630 - binary_crossentropy: 0.0846 - val_loss: 0.0429 - val_binary_accuracy: 0.9943 - val_ACCR: 0.9610 - val_auc1: 0.9997 - val_TPR: 0.9947 - val_FPR: 0.0070 - val_binary_crossentropy: 0.0309\n",
      "\n",
      "Epoch 00008: val_auc1 improved from 0.99961 to 0.99966, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 9/100\n",
      " - 1657s - loss: 0.0839 - binary_accuracy: 0.6628 - ACCR: 0.9494 - auc1: 0.9904 - TPR: 0.9890 - FPR: 0.0628 - binary_crossentropy: 0.0839 - val_loss: 0.0298 - val_binary_accuracy: 0.9946 - val_ACCR: 0.9576 - val_auc1: 0.9997 - val_TPR: 0.9946 - val_FPR: 0.0052 - val_binary_crossentropy: 0.0311\n",
      "\n",
      "Epoch 00009: val_auc1 improved from 0.99966 to 0.99973, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 10/100\n",
      " - 1638s - loss: 0.0833 - binary_accuracy: 0.6631 - ACCR: 0.9500 - auc1: 0.9905 - TPR: 0.9892 - FPR: 0.0623 - binary_crossentropy: 0.0833 - val_loss: 0.0260 - val_binary_accuracy: 0.9948 - val_ACCR: 0.9590 - val_auc1: 0.9998 - val_TPR: 0.9948 - val_FPR: 0.0050 - val_binary_crossentropy: 0.0301\n",
      "\n",
      "Epoch 00010: val_auc1 improved from 0.99973 to 0.99975, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 11/100\n",
      " - 1636s - loss: 0.0827 - binary_accuracy: 0.6633 - ACCR: 0.9504 - auc1: 0.9906 - TPR: 0.9894 - FPR: 0.0620 - binary_crossentropy: 0.0827 - val_loss: 0.0320 - val_binary_accuracy: 0.9953 - val_ACCR: 0.9604 - val_auc1: 0.9998 - val_TPR: 0.9954 - val_FPR: 0.0050 - val_binary_crossentropy: 0.0288\n",
      "\n",
      "Epoch 00011: val_auc1 improved from 0.99975 to 0.99979, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 12/100\n",
      " - 1636s - loss: 0.0822 - binary_accuracy: 0.6635 - ACCR: 0.9507 - auc1: 0.9907 - TPR: 0.9895 - FPR: 0.0620 - binary_crossentropy: 0.0822 - val_loss: 0.0277 - val_binary_accuracy: 0.9956 - val_ACCR: 0.9618 - val_auc1: 0.9998 - val_TPR: 0.9957 - val_FPR: 0.0047 - val_binary_crossentropy: 0.0280\n",
      "\n",
      "Epoch 00012: val_auc1 improved from 0.99979 to 0.99979, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 13/100\n",
      " - 1634s - loss: 0.0818 - binary_accuracy: 0.6637 - ACCR: 0.9510 - auc1: 0.9908 - TPR: 0.9897 - FPR: 0.0617 - binary_crossentropy: 0.0818 - val_loss: 0.0320 - val_binary_accuracy: 0.9956 - val_ACCR: 0.9629 - val_auc1: 0.9998 - val_TPR: 0.9957 - val_FPR: 0.0046 - val_binary_crossentropy: 0.0275\n",
      "\n",
      "Epoch 00013: val_auc1 improved from 0.99979 to 0.99981, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 14/100\n",
      " - 1640s - loss: 0.0814 - binary_accuracy: 0.6639 - ACCR: 0.9511 - auc1: 0.9909 - TPR: 0.9898 - FPR: 0.0617 - binary_crossentropy: 0.0814 - val_loss: 0.0242 - val_binary_accuracy: 0.9960 - val_ACCR: 0.9612 - val_auc1: 0.9998 - val_TPR: 0.9960 - val_FPR: 0.0040 - val_binary_crossentropy: 0.0278\n",
      "\n",
      "Epoch 00014: val_auc1 improved from 0.99981 to 0.99982, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 15/100\n",
      " - 1634s - loss: 0.0811 - binary_accuracy: 0.6640 - ACCR: 0.9513 - auc1: 0.9909 - TPR: 0.9900 - FPR: 0.0615 - binary_crossentropy: 0.0811 - val_loss: 0.0233 - val_binary_accuracy: 0.9962 - val_ACCR: 0.9620 - val_auc1: 0.9998 - val_TPR: 0.9962 - val_FPR: 0.0038 - val_binary_crossentropy: 0.0272\n",
      "\n",
      "Epoch 00015: val_auc1 improved from 0.99982 to 0.99985, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 16/100\n",
      " - 1632s - loss: 0.0808 - binary_accuracy: 0.6642 - ACCR: 0.9515 - auc1: 0.9910 - TPR: 0.9901 - FPR: 0.0614 - binary_crossentropy: 0.0808 - val_loss: 0.0253 - val_binary_accuracy: 0.9965 - val_ACCR: 0.9651 - val_auc1: 0.9999 - val_TPR: 0.9968 - val_FPR: 0.0044 - val_binary_crossentropy: 0.0261\n",
      "\n",
      "Epoch 00016: val_auc1 improved from 0.99985 to 0.99987, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 17/100\n",
      " - 1644s - loss: 0.0805 - binary_accuracy: 0.6642 - ACCR: 0.9516 - auc1: 0.9910 - TPR: 0.9901 - FPR: 0.0614 - binary_crossentropy: 0.0805 - val_loss: 0.0268 - val_binary_accuracy: 0.9967 - val_ACCR: 0.9649 - val_auc1: 0.9999 - val_TPR: 0.9969 - val_FPR: 0.0037 - val_binary_crossentropy: 0.0258\n",
      "\n",
      "Epoch 00017: val_auc1 improved from 0.99987 to 0.99988, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 18/100\n",
      " - 1631s - loss: 0.0803 - binary_accuracy: 0.6643 - ACCR: 0.9518 - auc1: 0.9911 - TPR: 0.9902 - FPR: 0.0613 - binary_crossentropy: 0.0803 - val_loss: 0.0314 - val_binary_accuracy: 0.9966 - val_ACCR: 0.9639 - val_auc1: 0.9999 - val_TPR: 0.9968 - val_FPR: 0.0038 - val_binary_crossentropy: 0.0258\n",
      "\n",
      "Epoch 00018: val_auc1 improved from 0.99988 to 0.99989, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 19/100\n",
      " - 1636s - loss: 0.0800 - binary_accuracy: 0.6645 - ACCR: 0.9519 - auc1: 0.9911 - TPR: 0.9904 - FPR: 0.0611 - binary_crossentropy: 0.0800 - val_loss: 0.0225 - val_binary_accuracy: 0.9966 - val_ACCR: 0.9601 - val_auc1: 0.9999 - val_TPR: 0.9965 - val_FPR: 0.0032 - val_binary_crossentropy: 0.0267\n",
      "\n",
      "Epoch 00019: val_auc1 improved from 0.99989 to 0.99990, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 20/100\n",
      " - 1636s - loss: 0.0799 - binary_accuracy: 0.6646 - ACCR: 0.9519 - auc1: 0.9912 - TPR: 0.9905 - FPR: 0.0612 - binary_crossentropy: 0.0799 - val_loss: 0.0283 - val_binary_accuracy: 0.9965 - val_ACCR: 0.9613 - val_auc1: 0.9999 - val_TPR: 0.9964 - val_FPR: 0.0032 - val_binary_crossentropy: 0.0261\n",
      "\n",
      "Epoch 00020: val_auc1 improved from 0.99990 to 0.99990, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 21/100\n",
      " - 1635s - loss: 0.0796 - binary_accuracy: 0.6646 - ACCR: 0.9520 - auc1: 0.9912 - TPR: 0.9905 - FPR: 0.0611 - binary_crossentropy: 0.0796 - val_loss: 0.0289 - val_binary_accuracy: 0.9969 - val_ACCR: 0.9630 - val_auc1: 0.9999 - val_TPR: 0.9970 - val_FPR: 0.0033 - val_binary_crossentropy: 0.0255\n",
      "\n",
      "Epoch 00021: val_auc1 improved from 0.99990 to 0.99991, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 22/100\n",
      " - 1634s - loss: 0.0794 - binary_accuracy: 0.6647 - ACCR: 0.9521 - auc1: 0.9913 - TPR: 0.9905 - FPR: 0.0610 - binary_crossentropy: 0.0794 - val_loss: 0.0273 - val_binary_accuracy: 0.9966 - val_ACCR: 0.9590 - val_auc1: 0.9999 - val_TPR: 0.9963 - val_FPR: 0.0025 - val_binary_crossentropy: 0.0269\n",
      "\n",
      "Epoch 00022: val_auc1 did not improve from 0.99991\n",
      "Epoch 23/100\n",
      " - 1644s - loss: 0.0793 - binary_accuracy: 0.6648 - ACCR: 0.9522 - auc1: 0.9913 - TPR: 0.9906 - FPR: 0.0610 - binary_crossentropy: 0.0793 - val_loss: 0.0251 - val_binary_accuracy: 0.9970 - val_ACCR: 0.9601 - val_auc1: 0.9999 - val_TPR: 0.9968 - val_FPR: 0.0025 - val_binary_crossentropy: 0.0259\n",
      "\n",
      "Epoch 00023: val_auc1 improved from 0.99991 to 0.99992, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 24/100\n",
      " - 1643s - loss: 0.0791 - binary_accuracy: 0.6648 - ACCR: 0.9522 - auc1: 0.9913 - TPR: 0.9907 - FPR: 0.0610 - binary_crossentropy: 0.0791 - val_loss: 0.0210 - val_binary_accuracy: 0.9970 - val_ACCR: 0.9614 - val_auc1: 0.9999 - val_TPR: 0.9969 - val_FPR: 0.0026 - val_binary_crossentropy: 0.0255\n",
      "\n",
      "Epoch 00024: val_auc1 did not improve from 0.99992\n",
      "Epoch 25/100\n",
      " - 1636s - loss: 0.0789 - binary_accuracy: 0.6649 - ACCR: 0.9523 - auc1: 0.9914 - TPR: 0.9908 - FPR: 0.0609 - binary_crossentropy: 0.0789 - val_loss: 0.0336 - val_binary_accuracy: 0.9973 - val_ACCR: 0.9633 - val_auc1: 0.9999 - val_TPR: 0.9973 - val_FPR: 0.0028 - val_binary_crossentropy: 0.0246\n",
      "\n",
      "Epoch 00025: val_auc1 improved from 0.99992 to 0.99993, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 26/100\n",
      " - 1635s - loss: 0.0787 - binary_accuracy: 0.6650 - ACCR: 0.9524 - auc1: 0.9914 - TPR: 0.9908 - FPR: 0.0609 - binary_crossentropy: 0.0787 - val_loss: 0.0238 - val_binary_accuracy: 0.9973 - val_ACCR: 0.9640 - val_auc1: 0.9999 - val_TPR: 0.9975 - val_FPR: 0.0031 - val_binary_crossentropy: 0.0246\n",
      "\n",
      "Epoch 00026: val_auc1 did not improve from 0.99993\n",
      "Epoch 27/100\n",
      " - 1639s - loss: 0.0786 - binary_accuracy: 0.6650 - ACCR: 0.9525 - auc1: 0.9914 - TPR: 0.9909 - FPR: 0.0609 - binary_crossentropy: 0.0786 - val_loss: 0.0254 - val_binary_accuracy: 0.9972 - val_ACCR: 0.9620 - val_auc1: 0.9999 - val_TPR: 0.9972 - val_FPR: 0.0026 - val_binary_crossentropy: 0.0252\n",
      "\n",
      "Epoch 00027: val_auc1 did not improve from 0.99993\n",
      "Epoch 28/100\n",
      " - 1644s - loss: 0.0785 - binary_accuracy: 0.6651 - ACCR: 0.9525 - auc1: 0.9915 - TPR: 0.9910 - FPR: 0.0609 - binary_crossentropy: 0.0785 - val_loss: 0.0244 - val_binary_accuracy: 0.9973 - val_ACCR: 0.9606 - val_auc1: 0.9999 - val_TPR: 0.9971 - val_FPR: 0.0023 - val_binary_crossentropy: 0.0254\n",
      "\n",
      "Epoch 00028: val_auc1 did not improve from 0.99993\n",
      "Epoch 29/100\n",
      " - 1639s - loss: 0.0783 - binary_accuracy: 0.6651 - ACCR: 0.9525 - auc1: 0.9915 - TPR: 0.9910 - FPR: 0.0609 - binary_crossentropy: 0.0783 - val_loss: 0.0230 - val_binary_accuracy: 0.9975 - val_ACCR: 0.9616 - val_auc1: 0.9999 - val_TPR: 0.9974 - val_FPR: 0.0023 - val_binary_crossentropy: 0.0247\n",
      "\n",
      "Epoch 00029: val_auc1 improved from 0.99993 to 0.99995, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 30/100\n",
      " - 1658s - loss: 0.0782 - binary_accuracy: 0.6652 - ACCR: 0.9526 - auc1: 0.9915 - TPR: 0.9911 - FPR: 0.0608 - binary_crossentropy: 0.0782 - val_loss: 0.0241 - val_binary_accuracy: 0.9978 - val_ACCR: 0.9665 - val_auc1: 0.9999 - val_TPR: 0.9980 - val_FPR: 0.0031 - val_binary_crossentropy: 0.0237\n",
      "\n",
      "Epoch 00030: val_auc1 did not improve from 0.99995\n",
      "Epoch 31/100\n",
      " - 1640s - loss: 0.0781 - binary_accuracy: 0.6652 - ACCR: 0.9525 - auc1: 0.9915 - TPR: 0.9911 - FPR: 0.0608 - binary_crossentropy: 0.0781 - val_loss: 0.0248 - val_binary_accuracy: 0.9977 - val_ACCR: 0.9645 - val_auc1: 0.9999 - val_TPR: 0.9978 - val_FPR: 0.0027 - val_binary_crossentropy: 0.0244\n",
      "\n",
      "Epoch 00031: val_auc1 did not improve from 0.99995\n",
      "Epoch 32/100\n",
      " - 1642s - loss: 0.0780 - binary_accuracy: 0.6653 - ACCR: 0.9527 - auc1: 0.9916 - TPR: 0.9912 - FPR: 0.0607 - binary_crossentropy: 0.0780 - val_loss: 0.0236 - val_binary_accuracy: 0.9976 - val_ACCR: 0.9633 - val_auc1: 0.9999 - val_TPR: 0.9976 - val_FPR: 0.0024 - val_binary_crossentropy: 0.0242\n",
      "\n",
      "Epoch 00032: val_auc1 did not improve from 0.99995\n",
      "Epoch 33/100\n",
      " - 1637s - loss: 0.0779 - binary_accuracy: 0.6653 - ACCR: 0.9526 - auc1: 0.9916 - TPR: 0.9912 - FPR: 0.0607 - binary_crossentropy: 0.0779 - val_loss: 0.0207 - val_binary_accuracy: 0.9977 - val_ACCR: 0.9642 - val_auc1: 0.9999 - val_TPR: 0.9978 - val_FPR: 0.0025 - val_binary_crossentropy: 0.0238\n",
      "\n",
      "Epoch 00033: val_auc1 did not improve from 0.99995\n",
      "Epoch 34/100\n",
      " - 1635s - loss: 0.0778 - binary_accuracy: 0.6654 - ACCR: 0.9527 - auc1: 0.9916 - TPR: 0.9912 - FPR: 0.0606 - binary_crossentropy: 0.0778 - val_loss: 0.0217 - val_binary_accuracy: 0.9978 - val_ACCR: 0.9642 - val_auc1: 1.0000 - val_TPR: 0.9979 - val_FPR: 0.0024 - val_binary_crossentropy: 0.0239\n",
      "\n",
      "Epoch 00034: val_auc1 improved from 0.99995 to 0.99995, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 35/100\n",
      " - 1642s - loss: 0.0777 - binary_accuracy: 0.6654 - ACCR: 0.9527 - auc1: 0.9916 - TPR: 0.9913 - FPR: 0.0607 - binary_crossentropy: 0.0777 - val_loss: 0.0277 - val_binary_accuracy: 0.9980 - val_ACCR: 0.9660 - val_auc1: 1.0000 - val_TPR: 0.9981 - val_FPR: 0.0026 - val_binary_crossentropy: 0.0232\n",
      "\n",
      "Epoch 00035: val_auc1 did not improve from 0.99995\n",
      "Epoch 36/100\n",
      " - 1644s - loss: 0.0776 - binary_accuracy: 0.6655 - ACCR: 0.9529 - auc1: 0.9916 - TPR: 0.9913 - FPR: 0.0607 - binary_crossentropy: 0.0776 - val_loss: 0.0267 - val_binary_accuracy: 0.9975 - val_ACCR: 0.9589 - val_auc1: 1.0000 - val_TPR: 0.9972 - val_FPR: 0.0018 - val_binary_crossentropy: 0.0251\n",
      "\n",
      "Epoch 00036: val_auc1 improved from 0.99995 to 0.99996, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 37/100\n",
      " - 1649s - loss: 0.0775 - binary_accuracy: 0.6655 - ACCR: 0.9528 - auc1: 0.9916 - TPR: 0.9913 - FPR: 0.0607 - binary_crossentropy: 0.0775 - val_loss: 0.0277 - val_binary_accuracy: 0.9976 - val_ACCR: 0.9616 - val_auc1: 1.0000 - val_TPR: 0.9975 - val_FPR: 0.0023 - val_binary_crossentropy: 0.0247\n",
      "\n",
      "Epoch 00037: val_auc1 did not improve from 0.99996\n",
      "Epoch 38/100\n",
      " - 1645s - loss: 0.0774 - binary_accuracy: 0.6655 - ACCR: 0.9527 - auc1: 0.9917 - TPR: 0.9914 - FPR: 0.0607 - binary_crossentropy: 0.0774 - val_loss: 0.0180 - val_binary_accuracy: 0.9980 - val_ACCR: 0.9639 - val_auc1: 1.0000 - val_TPR: 0.9981 - val_FPR: 0.0021 - val_binary_crossentropy: 0.0236\n",
      "\n",
      "Epoch 00038: val_auc1 improved from 0.99996 to 0.99996, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 39/100\n",
      " - 1643s - loss: 0.0773 - binary_accuracy: 0.6656 - ACCR: 0.9528 - auc1: 0.9917 - TPR: 0.9914 - FPR: 0.0606 - binary_crossentropy: 0.0773 - val_loss: 0.0266 - val_binary_accuracy: 0.9980 - val_ACCR: 0.9636 - val_auc1: 1.0000 - val_TPR: 0.9981 - val_FPR: 0.0021 - val_binary_crossentropy: 0.0236\n",
      "\n",
      "Epoch 00039: val_auc1 did not improve from 0.99996\n",
      "Epoch 40/100\n",
      " - 1656s - loss: 0.0773 - binary_accuracy: 0.6656 - ACCR: 0.9529 - auc1: 0.9917 - TPR: 0.9914 - FPR: 0.0605 - binary_crossentropy: 0.0773 - val_loss: 0.0290 - val_binary_accuracy: 0.9980 - val_ACCR: 0.9621 - val_auc1: 1.0000 - val_TPR: 0.9980 - val_FPR: 0.0021 - val_binary_crossentropy: 0.0242\n",
      "\n",
      "Epoch 00040: val_auc1 improved from 0.99996 to 0.99996, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 41/100\n",
      " - 1636s - loss: 0.0772 - binary_accuracy: 0.6656 - ACCR: 0.9528 - auc1: 0.9917 - TPR: 0.9915 - FPR: 0.0607 - binary_crossentropy: 0.0772 - val_loss: 0.0316 - val_binary_accuracy: 0.9978 - val_ACCR: 0.9601 - val_auc1: 1.0000 - val_TPR: 0.9976 - val_FPR: 0.0019 - val_binary_crossentropy: 0.0248\n",
      "\n",
      "Epoch 00041: val_auc1 did not improve from 0.99996\n",
      "Epoch 42/100\n",
      " - 1646s - loss: 0.0771 - binary_accuracy: 0.6656 - ACCR: 0.9529 - auc1: 0.9917 - TPR: 0.9915 - FPR: 0.0606 - binary_crossentropy: 0.0771 - val_loss: 0.0221 - val_binary_accuracy: 0.9978 - val_ACCR: 0.9594 - val_auc1: 1.0000 - val_TPR: 0.9978 - val_FPR: 0.0019 - val_binary_crossentropy: 0.0249\n",
      "\n",
      "Epoch 00042: val_auc1 improved from 0.99996 to 0.99996, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 43/100\n",
      " - 1642s - loss: 0.0770 - binary_accuracy: 0.6657 - ACCR: 0.9529 - auc1: 0.9917 - TPR: 0.9916 - FPR: 0.0605 - binary_crossentropy: 0.0770 - val_loss: 0.0215 - val_binary_accuracy: 0.9982 - val_ACCR: 0.9622 - val_auc1: 1.0000 - val_TPR: 0.9983 - val_FPR: 0.0021 - val_binary_crossentropy: 0.0240\n",
      "\n",
      "Epoch 00043: val_auc1 improved from 0.99996 to 0.99997, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 44/100\n",
      " - 1645s - loss: 0.0769 - binary_accuracy: 0.6657 - ACCR: 0.9529 - auc1: 0.9918 - TPR: 0.9916 - FPR: 0.0606 - binary_crossentropy: 0.0769 - val_loss: 0.0242 - val_binary_accuracy: 0.9982 - val_ACCR: 0.9630 - val_auc1: 1.0000 - val_TPR: 0.9982 - val_FPR: 0.0020 - val_binary_crossentropy: 0.0235\n",
      "\n",
      "Epoch 00044: val_auc1 did not improve from 0.99997\n",
      "Epoch 45/100\n",
      " - 1640s - loss: 0.0768 - binary_accuracy: 0.6658 - ACCR: 0.9529 - auc1: 0.9918 - TPR: 0.9916 - FPR: 0.0605 - binary_crossentropy: 0.0768 - val_loss: 0.0261 - val_binary_accuracy: 0.9982 - val_ACCR: 0.9623 - val_auc1: 1.0000 - val_TPR: 0.9982 - val_FPR: 0.0018 - val_binary_crossentropy: 0.0238\n",
      "\n",
      "Epoch 00045: val_auc1 did not improve from 0.99997\n",
      "Epoch 46/100\n",
      " - 1641s - loss: 0.0767 - binary_accuracy: 0.6658 - ACCR: 0.9529 - auc1: 0.9918 - TPR: 0.9917 - FPR: 0.0605 - binary_crossentropy: 0.0767 - val_loss: 0.0221 - val_binary_accuracy: 0.9983 - val_ACCR: 0.9640 - val_auc1: 1.0000 - val_TPR: 0.9984 - val_FPR: 0.0019 - val_binary_crossentropy: 0.0232\n",
      "\n",
      "Epoch 00046: val_auc1 improved from 0.99997 to 0.99997, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 47/100\n",
      " - 1645s - loss: 0.0766 - binary_accuracy: 0.6658 - ACCR: 0.9530 - auc1: 0.9918 - TPR: 0.9917 - FPR: 0.0605 - binary_crossentropy: 0.0766 - val_loss: 0.0233 - val_binary_accuracy: 0.9982 - val_ACCR: 0.9624 - val_auc1: 1.0000 - val_TPR: 0.9983 - val_FPR: 0.0020 - val_binary_crossentropy: 0.0234\n",
      "\n",
      "Epoch 00047: val_auc1 improved from 0.99997 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 48/100\n",
      " - 1650s - loss: 0.0765 - binary_accuracy: 0.6659 - ACCR: 0.9530 - auc1: 0.9918 - TPR: 0.9918 - FPR: 0.0605 - binary_crossentropy: 0.0765 - val_loss: 0.0232 - val_binary_accuracy: 0.9982 - val_ACCR: 0.9624 - val_auc1: 1.0000 - val_TPR: 0.9983 - val_FPR: 0.0020 - val_binary_crossentropy: 0.0235\n",
      "\n",
      "Epoch 00048: val_auc1 did not improve from 0.99998\n",
      "Epoch 49/100\n",
      " - 1638s - loss: 0.0765 - binary_accuracy: 0.6659 - ACCR: 0.9530 - auc1: 0.9918 - TPR: 0.9918 - FPR: 0.0605 - binary_crossentropy: 0.0765 - val_loss: 0.0275 - val_binary_accuracy: 0.9982 - val_ACCR: 0.9605 - val_auc1: 1.0000 - val_TPR: 0.9982 - val_FPR: 0.0017 - val_binary_crossentropy: 0.0241\n",
      "\n",
      "Epoch 00049: val_auc1 did not improve from 0.99998\n",
      "Epoch 50/100\n",
      " - 1652s - loss: 0.0764 - binary_accuracy: 0.6659 - ACCR: 0.9531 - auc1: 0.9919 - TPR: 0.9918 - FPR: 0.0605 - binary_crossentropy: 0.0764 - val_loss: 0.0229 - val_binary_accuracy: 0.9985 - val_ACCR: 0.9654 - val_auc1: 1.0000 - val_TPR: 0.9987 - val_FPR: 0.0022 - val_binary_crossentropy: 0.0227\n",
      "\n",
      "Epoch 00050: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 51/100\n",
      " - 1639s - loss: 0.0764 - binary_accuracy: 0.6659 - ACCR: 0.9532 - auc1: 0.9919 - TPR: 0.9918 - FPR: 0.0605 - binary_crossentropy: 0.0764 - val_loss: 0.0221 - val_binary_accuracy: 0.9983 - val_ACCR: 0.9616 - val_auc1: 1.0000 - val_TPR: 0.9984 - val_FPR: 0.0019 - val_binary_crossentropy: 0.0240\n",
      "\n",
      "Epoch 00051: val_auc1 did not improve from 0.99998\n",
      "Epoch 52/100\n",
      " - 1639s - loss: 0.0763 - binary_accuracy: 0.6660 - ACCR: 0.9531 - auc1: 0.9919 - TPR: 0.9919 - FPR: 0.0605 - binary_crossentropy: 0.0763 - val_loss: 0.0206 - val_binary_accuracy: 0.9985 - val_ACCR: 0.9656 - val_auc1: 1.0000 - val_TPR: 0.9988 - val_FPR: 0.0022 - val_binary_crossentropy: 0.0224\n",
      "\n",
      "Epoch 00052: val_auc1 did not improve from 0.99998\n",
      "Epoch 53/100\n",
      " - 1644s - loss: 0.0762 - binary_accuracy: 0.6660 - ACCR: 0.9530 - auc1: 0.9919 - TPR: 0.9919 - FPR: 0.0605 - binary_crossentropy: 0.0762 - val_loss: 0.0208 - val_binary_accuracy: 0.9986 - val_ACCR: 0.9650 - val_auc1: 1.0000 - val_TPR: 0.9987 - val_FPR: 0.0020 - val_binary_crossentropy: 0.0226\n",
      "\n",
      "Epoch 00053: val_auc1 did not improve from 0.99998\n",
      "Epoch 54/100\n",
      " - 1647s - loss: 0.0762 - binary_accuracy: 0.6660 - ACCR: 0.9531 - auc1: 0.9919 - TPR: 0.9919 - FPR: 0.0605 - binary_crossentropy: 0.0762 - val_loss: 0.0190 - val_binary_accuracy: 0.9984 - val_ACCR: 0.9595 - val_auc1: 1.0000 - val_TPR: 0.9983 - val_FPR: 0.0015 - val_binary_crossentropy: 0.0243\n",
      "\n",
      "Epoch 00054: val_auc1 did not improve from 0.99998\n",
      "Epoch 55/100\n",
      " - 1640s - loss: 0.0761 - binary_accuracy: 0.6660 - ACCR: 0.9532 - auc1: 0.9919 - TPR: 0.9919 - FPR: 0.0604 - binary_crossentropy: 0.0761 - val_loss: 0.0196 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9650 - val_auc1: 1.0000 - val_TPR: 0.9988 - val_FPR: 0.0019 - val_binary_crossentropy: 0.0224\n",
      "\n",
      "Epoch 00055: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 56/100\n",
      " - 1652s - loss: 0.0761 - binary_accuracy: 0.6661 - ACCR: 0.9531 - auc1: 0.9919 - TPR: 0.9920 - FPR: 0.0605 - binary_crossentropy: 0.0761 - val_loss: 0.0239 - val_binary_accuracy: 0.9984 - val_ACCR: 0.9608 - val_auc1: 1.0000 - val_TPR: 0.9984 - val_FPR: 0.0014 - val_binary_crossentropy: 0.0238\n",
      "\n",
      "Epoch 00056: val_auc1 did not improve from 0.99998\n",
      "Epoch 57/100\n",
      " - 1643s - loss: 0.0760 - binary_accuracy: 0.6661 - ACCR: 0.9532 - auc1: 0.9919 - TPR: 0.9920 - FPR: 0.0604 - binary_crossentropy: 0.0760 - val_loss: 0.0234 - val_binary_accuracy: 0.9985 - val_ACCR: 0.9605 - val_auc1: 1.0000 - val_TPR: 0.9985 - val_FPR: 0.0015 - val_binary_crossentropy: 0.0236\n",
      "\n",
      "Epoch 00057: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 58/100\n",
      " - 1642s - loss: 0.0760 - binary_accuracy: 0.6662 - ACCR: 0.9531 - auc1: 0.9919 - TPR: 0.9921 - FPR: 0.0604 - binary_crossentropy: 0.0760 - val_loss: 0.0192 - val_binary_accuracy: 0.9985 - val_ACCR: 0.9624 - val_auc1: 1.0000 - val_TPR: 0.9985 - val_FPR: 0.0016 - val_binary_crossentropy: 0.0231\n",
      "\n",
      "Epoch 00058: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 59/100\n",
      " - 1640s - loss: 0.0759 - binary_accuracy: 0.6662 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9921 - FPR: 0.0604 - binary_crossentropy: 0.0759 - val_loss: 0.0167 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9676 - val_auc1: 1.0000 - val_TPR: 0.9990 - val_FPR: 0.0023 - val_binary_crossentropy: 0.0217\n",
      "\n",
      "Epoch 00059: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 60/100\n",
      " - 1641s - loss: 0.0758 - binary_accuracy: 0.6662 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9921 - FPR: 0.0604 - binary_crossentropy: 0.0758 - val_loss: 0.0238 - val_binary_accuracy: 0.9986 - val_ACCR: 0.9626 - val_auc1: 1.0000 - val_TPR: 0.9986 - val_FPR: 0.0015 - val_binary_crossentropy: 0.0229\n",
      "\n",
      "Epoch 00060: val_auc1 did not improve from 0.99998\n",
      "Epoch 61/100\n",
      " - 1643s - loss: 0.0758 - binary_accuracy: 0.6662 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9921 - FPR: 0.0604 - binary_crossentropy: 0.0758 - val_loss: 0.0224 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9619 - val_auc1: 1.0000 - val_TPR: 0.9988 - val_FPR: 0.0016 - val_binary_crossentropy: 0.0230\n",
      "\n",
      "Epoch 00061: val_auc1 did not improve from 0.99998\n",
      "Epoch 62/100\n",
      " - 1636s - loss: 0.0757 - binary_accuracy: 0.6662 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9922 - FPR: 0.0604 - binary_crossentropy: 0.0757 - val_loss: 0.0226 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9611 - val_auc1: 1.0000 - val_TPR: 0.9987 - val_FPR: 0.0014 - val_binary_crossentropy: 0.0232\n",
      "\n",
      "Epoch 00062: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 63/100\n",
      " - 1656s - loss: 0.0756 - binary_accuracy: 0.6663 - ACCR: 0.9533 - auc1: 0.9920 - TPR: 0.9922 - FPR: 0.0604 - binary_crossentropy: 0.0756 - val_loss: 0.0229 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9628 - val_auc1: 1.0000 - val_TPR: 0.9987 - val_FPR: 0.0016 - val_binary_crossentropy: 0.0228\n",
      "\n",
      "Epoch 00063: val_auc1 did not improve from 0.99998\n",
      "Epoch 64/100\n",
      " - 1650s - loss: 0.0756 - binary_accuracy: 0.6663 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9922 - FPR: 0.0604 - binary_crossentropy: 0.0756 - val_loss: 0.0203 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9601 - val_auc1: 1.0000 - val_TPR: 0.9987 - val_FPR: 0.0013 - val_binary_crossentropy: 0.0234\n",
      "\n",
      "Epoch 00064: val_auc1 improved from 0.99998 to 0.99998, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 65/100\n",
      " - 1641s - loss: 0.0756 - binary_accuracy: 0.6663 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9923 - FPR: 0.0604 - binary_crossentropy: 0.0756 - val_loss: 0.0157 - val_binary_accuracy: 0.9988 - val_ACCR: 0.9624 - val_auc1: 1.0000 - val_TPR: 0.9989 - val_FPR: 0.0015 - val_binary_crossentropy: 0.0230\n",
      "\n",
      "Epoch 00065: val_auc1 did not improve from 0.99998\n",
      "Epoch 66/100\n",
      " - 1640s - loss: 0.0755 - binary_accuracy: 0.6663 - ACCR: 0.9533 - auc1: 0.9920 - TPR: 0.9923 - FPR: 0.0604 - binary_crossentropy: 0.0755 - val_loss: 0.0260 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9612 - val_auc1: 1.0000 - val_TPR: 0.9988 - val_FPR: 0.0015 - val_binary_crossentropy: 0.0234\n",
      "\n",
      "Epoch 00066: val_auc1 did not improve from 0.99998\n",
      "Epoch 67/100\n",
      " - 1642s - loss: 0.0755 - binary_accuracy: 0.6664 - ACCR: 0.9533 - auc1: 0.9920 - TPR: 0.9923 - FPR: 0.0603 - binary_crossentropy: 0.0755 - val_loss: 0.0218 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9627 - val_auc1: 1.0000 - val_TPR: 0.9989 - val_FPR: 0.0017 - val_binary_crossentropy: 0.0229\n",
      "\n",
      "Epoch 00067: val_auc1 did not improve from 0.99998\n",
      "Epoch 68/100\n",
      " - 1645s - loss: 0.0754 - binary_accuracy: 0.6664 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9923 - FPR: 0.0604 - binary_crossentropy: 0.0754 - val_loss: 0.0211 - val_binary_accuracy: 0.9987 - val_ACCR: 0.9615 - val_auc1: 1.0000 - val_TPR: 0.9988 - val_FPR: 0.0014 - val_binary_crossentropy: 0.0228\n",
      "\n",
      "Epoch 00068: val_auc1 did not improve from 0.99998\n",
      "Epoch 69/100\n",
      " - 1640s - loss: 0.0754 - binary_accuracy: 0.6664 - ACCR: 0.9533 - auc1: 0.9920 - TPR: 0.9924 - FPR: 0.0603 - binary_crossentropy: 0.0754 - val_loss: 0.0234 - val_binary_accuracy: 0.9988 - val_ACCR: 0.9617 - val_auc1: 1.0000 - val_TPR: 0.9989 - val_FPR: 0.0016 - val_binary_crossentropy: 0.0228\n",
      "\n",
      "Epoch 00069: val_auc1 improved from 0.99998 to 0.99999, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 70/100\n",
      " - 1640s - loss: 0.0753 - binary_accuracy: 0.6664 - ACCR: 0.9532 - auc1: 0.9920 - TPR: 0.9924 - FPR: 0.0604 - binary_crossentropy: 0.0753 - val_loss: 0.0216 - val_binary_accuracy: 0.9989 - val_ACCR: 0.9636 - val_auc1: 1.0000 - val_TPR: 0.9990 - val_FPR: 0.0015 - val_binary_crossentropy: 0.0221\n",
      "\n",
      "Epoch 00070: val_auc1 did not improve from 0.99999\n",
      "Epoch 71/100\n",
      " - 1637s - loss: 0.0753 - binary_accuracy: 0.6665 - ACCR: 0.9533 - auc1: 0.9920 - TPR: 0.9924 - FPR: 0.0603 - binary_crossentropy: 0.0753 - val_loss: 0.0239 - val_binary_accuracy: 0.9989 - val_ACCR: 0.9604 - val_auc1: 1.0000 - val_TPR: 0.9989 - val_FPR: 0.0012 - val_binary_crossentropy: 0.0233\n",
      "\n",
      "Epoch 00071: val_auc1 improved from 0.99999 to 0.99999, saving model to C:\\Users\\i0947\\Desktop\\retrosynthesis_planner-master\\saved_models\\trained_model_inscope_0\n",
      "Epoch 72/100\n",
      " - 1652s - loss: 0.0752 - binary_accuracy: 0.6665 - ACCR: 0.9532 - auc1: 0.9921 - TPR: 0.9924 - FPR: 0.0604 - binary_crossentropy: 0.0752 - val_loss: 0.0233 - val_binary_accuracy: 0.9988 - val_ACCR: 0.9626 - val_auc1: 1.0000 - val_TPR: 0.9990 - val_FPR: 0.0016 - val_binary_crossentropy: 0.0227\n",
      "\n",
      "Epoch 00072: val_auc1 did not improve from 0.99999\n",
      "Epoch 73/100\n",
      " - 1641s - loss: 0.0752 - binary_accuracy: 0.6665 - ACCR: 0.9533 - auc1: 0.9921 - TPR: 0.9924 - FPR: 0.0603 - binary_crossentropy: 0.0752 - val_loss: 0.0187 - val_binary_accuracy: 0.9989 - val_ACCR: 0.9655 - val_auc1: 1.0000 - val_TPR: 0.9992 - val_FPR: 0.0018 - val_binary_crossentropy: 0.0220\n",
      "\n",
      "Epoch 00073: val_auc1 did not improve from 0.99999\n",
      "Epoch 74/100\n",
      " - 1640s - loss: 0.0751 - binary_accuracy: 0.6665 - ACCR: 0.9533 - auc1: 0.9921 - TPR: 0.9925 - FPR: 0.0603 - binary_crossentropy: 0.0751 - val_loss: 0.0255 - val_binary_accuracy: 0.9989 - val_ACCR: 0.9653 - val_auc1: 1.0000 - val_TPR: 0.9991 - val_FPR: 0.0017 - val_binary_crossentropy: 0.0220\n",
      "\n",
      "Epoch 00074: val_auc1 did not improve from 0.99999\n",
      "Epoch 75/100\n",
      " - 1642s - loss: 0.0751 - binary_accuracy: 0.6665 - ACCR: 0.9533 - auc1: 0.9921 - TPR: 0.9925 - FPR: 0.0604 - binary_crossentropy: 0.0751 - val_loss: 0.0269 - val_binary_accuracy: 0.9989 - val_ACCR: 0.9614 - val_auc1: 1.0000 - val_TPR: 0.9989 - val_FPR: 0.0014 - val_binary_crossentropy: 0.0227\n",
      "\n",
      "Epoch 00075: val_auc1 did not improve from 0.99999\n",
      "Epoch 76/100\n",
      " - 1646s - loss: 0.0751 - binary_accuracy: 0.6665 - ACCR: 0.9534 - auc1: 0.9921 - TPR: 0.9925 - FPR: 0.0604 - binary_crossentropy: 0.0751 - val_loss: 0.0215 - val_binary_accuracy: 0.9988 - val_ACCR: 0.9597 - val_auc1: 1.0000 - val_TPR: 0.9987 - val_FPR: 0.0012 - val_binary_crossentropy: 0.0233\n",
      "\n",
      "Epoch 00076: val_auc1 did not improve from 0.99999\n",
      "Epoch 77/100\n",
      " - 1643s - loss: 0.0750 - binary_accuracy: 0.6666 - ACCR: 0.9533 - auc1: 0.9921 - TPR: 0.9925 - FPR: 0.0603 - binary_crossentropy: 0.0750 - val_loss: 0.0223 - val_binary_accuracy: 0.9990 - val_ACCR: 0.9608 - val_auc1: 1.0000 - val_TPR: 0.9990 - val_FPR: 0.0012 - val_binary_crossentropy: 0.0227\n",
      "\n",
      "Epoch 00077: val_auc1 did not improve from 0.99999\n",
      "Epoch 00077: early stopping\n"
     ]
    }
   ],
   "source": [
    "#for test negative enrichment,is it good to get better results?\n",
    "from inscopefilter3 import*\n",
    "if __name__ == '__main__':\n",
    "                #設定訓練參數和訓練模型存放路徑\n",
    "    #batch_size = 3\n",
    "    batch_size = 512\n",
    "    #num_classes = 6\n",
    "    #epochs = 2000\n",
    "    epochs = 100\n",
    "    seed=0\n",
    "    #validation spilt\n",
    "    spilt=0\n",
    "    #for variance threshold\n",
    "    #fp_dim=1e6\n",
    "    fp_dim=16384\n",
    "    recfp_dim=2048\n",
    "    #recfp_dim=16384\n",
    "    model_name = 'trained_model_inscope_'+str(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    print('Loading data...')\n",
    "    tem_simp = set()\n",
    "    prods = []\n",
    "    reacs = []\n",
    "    labels = []\n",
    "    '''\n",
    "    with open('data/inscopedata.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip())\n",
    "\n",
    "    with open('data/inscopedata2.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "    #print('check data:', tem_simp)\n",
    "\n",
    "    with open('data/inscopedata4.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "    #print('check samples:', labels[1000000:1000010])\n",
    "    print('total samples:', len(tem_simp))    \n",
    "    # Shuffle\n",
    "    xyz = list(zip(prods, reacs, labels))\n",
    "    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    \n",
    "    prods, reacs, labels = zip(*xyz)\n",
    "    '''\n",
    "    '''\n",
    "    with open('data/inscopedatatest.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='inscopedata'):\n",
    "            tem_simp.add(l.strip()) \n",
    "        \n",
    "    for item in tem_simp:\n",
    "        prod,reac,label = item.split('\\t')\n",
    "        prods.append(prod)\n",
    "        reacs.append(reac)\n",
    "        labels.append(float(label))\n",
    "        \n",
    "    data_spilt= round(len(prods)*(1-spilt))\n",
    "    x_train = prods[:data_spilt]\n",
    "    x_test = prods[data_spilt:]\n",
    "    y_train = reacs[:data_spilt]\n",
    "    y_test = reacs[data_spilt:]\n",
    "    z_train = labels[:data_spilt]\n",
    "    z_test = labels[data_spilt:]\n",
    "    '''\n",
    "    #print('traindata:',x_train[:2],y_train[:2],z_train[:2])\n",
    "    #print('testdata:',x_test[:2],y_test[:2],z_test[:2])\n",
    "    \n",
    "    with open('data/x_train0_rev.pickle', 'rb') as f:\n",
    "        x_train = pickle.load(f)\n",
    "    with open('data/x_test0_rev.pickle', 'rb') as f:\n",
    "        x_test = pickle.load(f)\n",
    "    with open('data/y_train0_rev.pickle', 'rb') as f:\n",
    "        y_train = pickle.load(f)\n",
    "    with open('data/y_test0_rev.pickle', 'rb') as f:\n",
    "        y_test = pickle.load(f)\n",
    "    with open('data/z_train0_rev.pickle', 'rb') as f:\n",
    "        z_train = pickle.load(f)\n",
    "    with open('data/z_test0_rev.pickle', 'rb') as f:\n",
    "        z_test = pickle.load(f)  \n",
    "        \n",
    "    with open('data/x_train0_rev-n.pickle', 'rb') as f:\n",
    "        x_trainM = pickle.load(f) \n",
    "    with open('data/y_train0_rev-n.pickle', 'rb') as f:\n",
    "        y_trainM = pickle.load(f) \n",
    "    with open('data/z_train0_rev-n.pickle', 'rb') as f:\n",
    "        z_trainM = pickle.load(f) \n",
    "    \n",
    "    x_train=list(x_train)\n",
    "    y_train=list(y_train)\n",
    "    z_train=list(z_train)\n",
    "#    x_trainM=list(x_trainM)\n",
    "#    y_trainM=list(y_trainM)\n",
    "#    z_trainM=list(z_trainM)\n",
    "#    x_trainM.extend(x_trainM)\n",
    "#    y_trainM.extend(y_trainM)\n",
    "#    z_trainM.extend(z_trainM)\n",
    "    \n",
    "#    x_trainM=x_trainM[:1228455]\n",
    "#    y_trainM=y_trainM[:1228455]\n",
    "#    z_trainM=z_trainM[:1228455]\n",
    "\n",
    "    '''\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    x_trainM.extend(x_trainM)\n",
    "    y_trainM.extend(y_trainM)\n",
    "    z_trainM.extend(z_trainM)\n",
    "    '''\n",
    "    \n",
    "    x_train.extend(x_test)\n",
    "    y_train.extend(y_test)\n",
    "    z_train.extend(z_test)\n",
    "    \n",
    "    x_test=x_train.copy()\n",
    "    y_test=y_train.copy()\n",
    "    z_test=z_train.copy()\n",
    "    \n",
    "    x_train.extend(x_train)\n",
    "    y_train.extend(y_train)\n",
    "    z_train.extend(z_train)    \n",
    "    x_train.extend(x_trainM)\n",
    "    y_train.extend(y_trainM)\n",
    "    z_train.extend(z_trainM)     \n",
    "    \n",
    "    xyz = list(zip(x_train, y_train, z_train))\n",
    "#    xyz.sort()\n",
    "    random.seed(seed)\n",
    "    random.shuffle(xyz)\n",
    "    x_train, y_train, z_train= zip(*xyz)     \n",
    "    print('shuffle is over...')\n",
    "    print('train length:',len(x_train))\n",
    "    print('test length:',len(x_test))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #build model\n",
    "    visible = Input(shape=(fp_dim,))\n",
    "    hidden = Lambda(lambda x: tf.math.log(x+1))(visible)\n",
    "    hidden = Dense(1024, activation='elu')(hidden)\n",
    "    hidden = Dropout(0.3)(hidden)\n",
    "\n",
    "    # only for expansion rule policynet\n",
    "    for _ in range(5):\n",
    "        hidden = Highway()(hidden)\n",
    "    #    hidden = Dropout(0.4)(hidden)\n",
    "    #another branch\n",
    "    #visible1 = Input(shape=(fp_dim,))\n",
    "    visible2 = Input(shape=(recfp_dim,))\n",
    "    #hidden1 = Lambda(fold)([visible, visible2])\n",
    "    hidden1 = Dense(1024, activation='elu')(visible2)\n",
    "\n",
    "    output = Lambda(cosine)([hidden, hidden1])\n",
    "    #,output_shape=(1,)\n",
    "    \n",
    "    model = Model(inputs=[visible,visible2], outputs=output)\n",
    "    # summarize layers\n",
    "    print(model.summary())\n",
    "    # plot graph\n",
    "    #plot_model(model, to_file='expansionpolicynet_graph.png')\n",
    "    # 初始化Adam optimizer\n",
    "    opt = keras.optimizers.Adam(lr=0.0001)\n",
    "\n",
    "    # 設定訓練方式，包含loss、optimizer..)\n",
    "    loss1=losses.binary_crossentropy\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer=opt,\n",
    "                  metrics=[metrics.binary_accuracy, ACCR, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # early stop存放模型設置\n",
    "\n",
    "\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    model_path = os.path.join(save_dir, model_name)\n",
    "    checkpoint = ModelCheckpoint(model_path, monitor='val_auc1', save_best_only=True, verbose=1, mode='max')\n",
    "\n",
    "    # early stop參數設定\n",
    "    earlystop = EarlyStopping(monitor='val_auc1', patience=6, verbose=1, mode='max')\n",
    "\n",
    "    #continue training\n",
    "\n",
    "    #K.clear_session()\n",
    "    #gc.collect()\n",
    "    #del model  # 删掉存在的模型\n",
    "\n",
    "    #返回一个编译好的模型\n",
    "    #与删掉的模型相同\n",
    "    #model = load_model(model_path, custom_objects={'ACCR': ACCR,'auc2': auc2,'auc1': auc1,'TPR': TPR, 'FPR': FPR,'Highway': Highway,'fold': fold,'cosine': cosine, 'tf': tf, 'loss1': loss1})\n",
    "   # model.compile(loss='binary_crossentropy',\n",
    "   #               optimizer=opt,\n",
    "   #               metrics=[metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR, loss1])\n",
    "    #metrics.binary_accuracy, ACCR, auc2, auc1, TPR, FPR\n",
    "    # 開始訓練\n",
    "    training_generator = DataGenerator(X=x_train, y=y_train, z=z_train, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)\n",
    "    validation_gen = DataGenerator(X=x_test, y=y_test, z=z_test, batch_size=batch_size, shuffle=True, fp_dim=fp_dim, recfp_dim=recfp_dim)    \n",
    "\n",
    "    model_history = model.fit_generator( \n",
    "                    generator=training_generator,\n",
    "                    epochs=epochs,\n",
    "#                    class_weight = {1:1., 0:3.},\n",
    "                    validation_data=validation_gen,\n",
    "                    verbose=2,\n",
    "                    initial_epoch=0,\n",
    "                    workers=5, \n",
    "                    use_multiprocessing=1, \n",
    "#                    shuffle=False,\n",
    "#                    max_queue_size = 12, \n",
    "                    callbacks=[earlystop, checkpoint]\n",
    "#                    callbacks=[checkpoint]\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
