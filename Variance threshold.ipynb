{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "products: 3143138it [00:08, 386495.83it/s]\n",
      "expansion: 55608it [00:00, 723812.06it/s]\n",
      "  0%|          | 46/9875 [01:21<2:10:13,  1.26it/s] "
     ]
    }
   ],
   "source": [
    "from expansion_policy_fn import *\n",
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from functools import reduce\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Loading data...')\n",
    "    prod_to_rules = defaultdict(set)\n",
    "    with open('data/templates_expansion.dat', 'r') as f:\n",
    "        for l in tqdm(f, desc='products'):\n",
    "            rule, prod = l.strip().split('\\t')\n",
    "            prod_to_rules[prod].add(rule)\n",
    "\n",
    "\n",
    "\n",
    "    expansion_rules = {}\n",
    "    with open('data/expansion_expansion.dat', 'r') as f:\n",
    "        for i, l in tqdm(enumerate(f), desc='expansion'):\n",
    "            rule = l.strip()\n",
    "            expansion_rules[rule] = i\n",
    "\n",
    "    \n",
    "    \n",
    "    save_path = 'saved_models'\n",
    "    if not os.path.exists(save_path):\n",
    "        os.makedirs(save_path)\n",
    "    \n",
    "    # Variance threshold\n",
    "    # No specific threshold is mentioned in the paper,\n",
    "    # just that it's used to \"remove rare features\"\n",
    "    # idx = np.load(os.path.join(save_path, 'expansion.idx.npy'))\n",
    "    chunk_size = 100\n",
    "    prods = []\n",
    "    for prod, rules in prod_to_rules.items():\n",
    "        if any(r in expansion_rules for r in rules):\n",
    "            prods.append(prod)\n",
    "    # prods = random.sample(prods, 200000)    \n",
    "    with Pool() as p:\n",
    "        _, _, var = reduce(reducefn, tqdm(p.imap(mapfn, chunker(prods, chunk_size)), total=len(prods)//chunk_size))\n",
    "    idx = np.where(var > 0)[0]\n",
    "    print(len(idx))\n",
    "    np.save(os.path.join(save_path, 'expansion.idx'), idx, allow_pickle=False)\n",
    "    \n",
    "    np.save(os.path.join(save_path, 'expansion.var'), var, allow_pickle=False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23086\n"
     ]
    }
   ],
   "source": [
    "idx1 = np.where(var > 5e-5)[0]\n",
    "print(len(idx1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(save_path, 'expansion.var'), var, allow_pickle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(os.path.join(save_path, 'expansion5e-5.idx'), idx1, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
