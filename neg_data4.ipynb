{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [19:46:04] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n",
      "expansion: 176756it [00:00, 726352.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1157756it [5:24:00, 59.55it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total positive Expansion rules examples: 430665\n",
      "total negative Expansion rules examples: 22857611\n"
     ]
    }
   ],
   "source": [
    "from neg_data4 import *\n",
    "if __name__ == '__main__':\n",
    "    print('Loading data...')\n",
    "    prod_to_reacs = defaultdict(set)\n",
    "    prod_to_noreacs = defaultdict(set)\n",
    "    Tolri=0\n",
    "    Tolpos=0\n",
    "    Tolneg=0\n",
    "    batch_size = 1\n",
    "#    reactant = []\n",
    "#    rule_ans = []\n",
    "#    prod_ans = []\n",
    "\n",
    "#    expansion_rules = []\n",
    "    tem_simp = set()\n",
    "#    seed =0\n",
    "#    random.seed(seed)\n",
    "#    with open('data/templates_expansion3.dat', 'r') as f:\n",
    "#        for l in f:\n",
    "#            reactant.append(l.strip().split('\\t')[2])\n",
    "#            rule_ans.append(l.strip().split('\\t')[0])\n",
    "#            prod_ans.append(l.strip().split('\\t')[1])\n",
    "#    batch_datasX = reactant[:10]\n",
    "#    batch_datasY = rule_ans[:10]\n",
    "#    batch_datasZ = prod_ans[:10]\n",
    "#    with open('data/expansion_expansion.dat', 'r') as f:\n",
    "#        for i, l in tqdm(enumerate(f), desc='expansion'):\n",
    "#            rule = l.strip()\n",
    "#            expansion_rules.append(rule)\n",
    "\n",
    "#    with open('data/templates_expansion1.dat', 'r') as f:\n",
    "#        for l in tqdm(f, desc='products'):\n",
    "#                tem_simp.add(l.strip())\n",
    "#    with open('data/templates_expansion3.dat', 'w') as f:\n",
    "#        f.write('\\n'.join(tem_simp))                           \n",
    "\n",
    "    with open('data/templates_expansion3.dat', 'r') as f:\n",
    "    #    for l in tqdm(f, desc='products'):\n",
    "#        seeds=[a for a in range(len(f.readlines()))]\n",
    "#        combo[0]=f\n",
    "#        combo[1]=seeds\n",
    "    \n",
    "\n",
    "    \n",
    "        with Pool() as p:\n",
    "#            for reacs,noreacs in tqdm(p.imap(partial(read, rules=expansion_rules), f)):\n",
    "            for reacs,noreacs in tqdm(p.imap(read, zip(f, seedgen(batch_size)))):  \n",
    "                for reac, values in reacs.items():\n",
    "                    for value in values:\n",
    "                        prod_to_reacs[reac].add(value)\n",
    "                \n",
    "                for reac, values in noreacs.items():\n",
    "                    for value in values:\n",
    "                        prod_to_noreacs[reac].add(value)\n",
    "                    \n",
    "    transforms=[]  \n",
    "    for prod, reacs in prod_to_reacs.items():\n",
    "        for reac in reacs:\n",
    "            transforms.append((prod, reac, '1'))\n",
    "            Tolpos+=1\n",
    "\n",
    "    for prod, noreacs in prod_to_noreacs.items():\n",
    "        for noreac in noreacs:\n",
    "            transforms.append((prod, noreac, '0'))             \n",
    "            Tolneg+=1\n",
    "    with open('data/inscopedata4all.dat', 'w') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(rxn_prod) for rxn_prod in transforms]))\n",
    "\n",
    "    print('total positive Expansion rules examples:',Tolpos) \n",
    "    print('total negative Expansion rules examples:',Tolneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RDKit WARNING: [20:23:29] Enabling RDKit 2019.09.3 jupyter extensions\n",
      "Using TensorFlow backend.\n",
      "expansion: 55608it [00:00, 796212.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "WARNING:tensorflow:From C:\\Users\\i0947\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:02,  1.61s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total positive Expansion rules examples: 1\n",
      "total negative Expansion rules examples: 73\n"
     ]
    }
   ],
   "source": [
    "from neg_data4 import *\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    print('Loading data...')\n",
    "    prod_to_reacs = defaultdict(set)\n",
    "    prod_to_noreacs = defaultdict(set)\n",
    "    Tolri=0\n",
    "    Tolpos=0\n",
    "    Tolneg=0\n",
    "    reactant = []\n",
    "    rule_ans = []\n",
    "    prod_ans = []\n",
    "\n",
    "#    expansion_rules = []\n",
    "    tem_simp = set()\n",
    "#    seed =0\n",
    "#    random.seed(seed)\n",
    "    save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "    if not os.path.isdir(save_dir):\n",
    "        os.makedirs(save_dir)\n",
    "    \n",
    "    model_path_e = os.path.join(save_dir, 'trained_model_negative_1')\n",
    "    fp_dim=23086\n",
    "    idx = np.load(os.path.join(save_dir, 'expansion5e-5.idx.npy'))   \n",
    "\n",
    "    \n",
    "    negative_net = load_model(model_path_e, custom_objects={'acc_top10': acc_top10,'acc_top50': acc_top50, 'Highway': Highway})   \n",
    "    with open('data/templates_expansion3.dat', 'r') as f:\n",
    "        for l in f:\n",
    "            reactant.append(l.strip().split('\\t')[2])\n",
    "            rule_ans.append(l.strip().split('\\t')[0])\n",
    "            prod_ans.append(l.strip().split('\\t')[1])\n",
    "    batch_datasX = reactant[:10]\n",
    "    batch_datasY = rule_ans[:10]\n",
    "    batch_datasZ = prod_ans[:10]\n",
    "#    with open('data/expansion_expansion.dat', 'r') as f:\n",
    "#        for i, l in tqdm(enumerate(f), desc='expansion'):\n",
    "#            rule = l.strip()\n",
    "#            expansion_rules.append(rule)\n",
    "\n",
    "#    with open('data/templates_expansion1.dat', 'r') as f:\n",
    "#        for l in tqdm(f, desc='products'):\n",
    "#                tem_simp.add(l.strip())\n",
    "#    with open('data/templates_expansion3.dat', 'w') as f:\n",
    "#        f.write('\\n'.join(tem_simp))                           \n",
    "\n",
    "#    with open('data/templates_expansion3.dat', 'r') as f:\n",
    "    #    for l in tqdm(f, desc='products'):\n",
    "#        seeds=[a for a in range(len(f.readlines()))]\n",
    "#        combo[0]=f\n",
    "#        combo[1]=seeds\n",
    "    if True:\n",
    "        X = np.zeros((len(batch_datasX),fp_dim)) \n",
    "        for i,a in enumerate(batch_datasX):\n",
    "            n = np.zeros((1,fp_dim))        \n",
    "            for b in smi_list_from_str(a):\n",
    "                n += preprocess([b], fp_dim, idx) \n",
    "            X[i] = n\n",
    "        X = np.log(X+1)\n",
    "        # Predict applicable rules\n",
    "        predict = negative_net.predict_on_batch(X)\n",
    "        # get the rules index from high probability to low probability\n",
    "        preds =np.argsort(-predict, axis=1)[:,:50]\n",
    "    \n",
    "        with Pool(processes = 2) as p:\n",
    "#            for reacs,noreacs in tqdm(p.imap(partial(read, rules=expansion_rules), f)):\n",
    "            for reacs,noreacs in tqdm(p.imap(read, zip(batch_datasY, batch_datasZ, batch_datasX, preds))):  \n",
    "                for reac, values in reacs.items():\n",
    "                    for value in values:\n",
    "                        prod_to_reacs[reac].add(value)\n",
    "                \n",
    "                for reac, values in noreacs.items():\n",
    "                    for value in values:\n",
    "                        prod_to_noreacs[reac].add(value)\n",
    "                    \n",
    "    transforms=[]  \n",
    "    for prod, reacs in prod_to_reacs.items():\n",
    "        for reac in reacs:\n",
    "            transforms.append((prod, reac, '1'))\n",
    "            Tolpos+=1\n",
    "\n",
    "    for prod, noreacs in prod_to_noreacs.items():\n",
    "        for noreac in noreacs:\n",
    "            transforms.append((prod, noreac, '0'))             \n",
    "            Tolneg+=1\n",
    "    with open('data/inscopedata4.dat', 'w') as f:\n",
    "        f.write('\\n'.join(['\\t'.join(rxn_prod) for rxn_prod in transforms]))\n",
    "\n",
    "    print('total positive Expansion rules examples:',Tolpos) \n",
    "    print('total negative Expansion rules examples:',Tolneg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tolpos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
